{"text": "<fim_prefix>/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage org.apache.drill.exec.work.batch;\nimport io.netty.buffer.ByteBuf;\nimport io.netty.buffer.DrillBuf;\nimport java.io.EOFException;\nimport java.io.IOException;\nimport java.util.List;\nimport java.util.concurrent.CountDownLatch;\nimport java.util.concurrent.LinkedBlockingDeque;\nimport java.util.concurrent.ThreadLocalRandom;\nimport java.util.concurrent.TimeUnit;\nimport org.apache.drill.exec.ExecConstants;\nimport org.apache.drill.exec.memory.BufferAllocator;\nimport org.apache.drill.exec.ops.FragmentContext;\nimport org.apache.drill.exec.proto.BitData;\nimport org.apache.drill.exec.proto.ExecProtos;\nimport org.apache.drill.exec.proto.helper.QueryIdHelper;\nimport org.apache.drill.exec.record.RawFragmentBatch;\nimport org.apache.drill.exec.store.LocalSyncableFileSystem;\nimport org.apache.hadoop.conf.Configuration;\nimport org.apache.hadoop.fs.FSDataInputStream;\nimport org.apache.hadoop.fs.FSDataOutputStream;\nimport org.apache.hadoop.fs.FileStatus;\nimport org.apache.hadoop.fs.FileSystem;\nimport org.apache.hadoop.fs.Path;\nimport org.apache.drill.shaded.guava.com.google.common.base.Joiner;\nimport org.apache.drill.shaded.guava.com.google.common.base.Preconditions;\nimport org.apache.drill.shaded.guava.com.google.common.base.Stopwatch;\nimport org.apache.drill.shaded.guava.com.google.common.collect.Queues;\n/**\n * This implementation of RawBatchBuffer starts writing incoming batches to disk once the buffer size reaches a threshold.\n * The order of the incoming buffers is maintained.\n */\npublic class SpoolingRawBatchBuffer extends BaseRawBatchBuffer<SpoolingRawBatchBuffer.RawFragmentBatchWrapper> {\n  static final org.slf4j.Logger logger = org.slf4j.LoggerFactory.getLogger(SpoolingRawBatchBuffer.class);\n  private static String DRILL_LOCAL_IMPL_STRING = \"fs.drill-local.impl\";\n  private static final float STOP_SPOOLING_FRACTION = (float) 0.5;\n  public static final long ALLOCATOR_INITIAL_RESERVATION = 1*1024*1024;\n  public static final long ALLOCATOR_MAX_RESERVATION = 20L*1000*1000*1000;\n  private enum SpoolingState {\n    NOT_SPOOLING,\n    SPOOLING,\n    PAUSE_SPOOLING,\n    STOP_SPOOLING\n  }\n  private final BufferAllocator allocator;\n  private final long threshold;\n  private final int oppositeId;\n  private final int bufferIndex;\n  private volatile SpoolingState spoolingState;\n  private volatile long currentSizeInMemory = 0;\n  private volatile Spooler spooler;\n  private FileSystem fs;\n  private Path path;\n  private FSDataOutputStream outputStream;\n  public SpoolingRawBatchBuffer(FragmentContext context, int fragmentCount, int oppositeId, int bufferIndex) {\n    super(context, fragmentCount);\n    this.allocator = context.getNewChildAllocator(\n        \"SpoolingRawBatchBufer\", 100, ALLOCATOR_INITIAL_RESERVATION, ALLOCATOR_MAX_RESERVATION);\n    this.threshold = context.getConfig().getLong(ExecConstants.SPOOLING_BUFFER_MEMORY);\n    this.oppositeId = oppositeId;\n    this.bufferIndex = bufferIndex;\n    this.bufferQueue = new SpoolingBufferQueue();\n  }\n  private class SpoolingBufferQueue implements BufferQueue<RawFragmentBatchWrapper> {\n    private final LinkedBlockingDeque<RawFragmentBatchWrapper> buffer = Queues.newLinkedBlockingDeque();\n    @Override\n    public void addOomBatch(RawFragmentBatch batch) {\n      RawFragmentBatchWrapper batchWrapper = new RawFragmentBatchWrapper(batch, true);\n      batchWrapper.setOutOfMemory(true);\n      buffer.addFirst(batchWrapper);\n    }\n    @Override\n    public RawFragmentBatch poll() throws IOException, InterruptedException {\n      RawFragmentBatchWrapper batchWrapper = buffer.poll();\n      if (batchWrapper != null) {\n        return batchWrapper.get();\n      }\n      return null;\n    }\n    @Override\n    public RawFragmentBatch take() throws IOException, InterruptedException {\n      return buffer.take().get();\n    }\n    @Override\n    public RawFragmentBatch poll(long timeout, TimeUnit timeUnit) throws InterruptedException, IOException {\n      RawFragmentBatchWrapper batchWrapper = buffer.poll(timeout, timeUnit);\n      if (batchWrapper != null) {\n        return batchWrapper.get();\n      }\n      return null;\n    }\n    @Override\n    public boolean checkForOutOfMemory() {\n      return buffer.peek().isOutOfMemory();\n    }\n    @Override\n    public int size() {\n      return buffer.size();\n    }\n    @Override\n    public boolean isEmpty() {\n      return buffer.size() == 0;\n    }\n<fim_suffix>    public void add(RawFragmentBatchWrapper batchWrapper) {\n      buffer.add(batchWrapper);\n    }\n  }\n  private synchronized void setSpoolingState(SpoolingState newState) {\n    SpoolingState currentState = spoolingState;\n    if (newState == SpoolingState.NOT_SPOOLING ||\n        currentState == SpoolingState.STOP_SPOOLING) {\n      return;\n    }\n    spoolingState = newState;\n  }\n  private boolean isCurrentlySpooling() {\n    return spoolingState == SpoolingState.SPOOLING;\n  }\n  private void startSpooling() {\n    setSpoolingState(SpoolingState.SPOOLING);\n  }\n  private void pauseSpooling() {\n    setSpoolingState(SpoolingState.PAUSE_SPOOLING);\n  }\n  private boolean isSpoolingStopped() {\n    return spoolingState == SpoolingState.STOP_SPOOLING;\n  }\n  private void stopSpooling() {\n    setSpoolingState(SpoolingState.STOP_SPOOLING);\n  }\n  public String getDir() {\n    List<String> dirs = context.getConfig().getStringList(ExecConstants.TEMP_DIRECTORIES);\n    return dirs.get(ThreadLocalRandom.current().nextInt(dirs.size()));\n  }\n  private synchronized void initSpooler() throws IOException {\n    if (spooler != null) {\n      return;\n    }\n    Configuration conf = new Configuration();\n    conf.set(FileSystem.FS_DEFAULT_NAME_KEY, context.getConfig().getString(ExecConstants.TEMP_FILESYSTEM));\n    conf.set(DRILL_LOCAL_IMPL_STRING, LocalSyncableFileSystem.class.getName());\n    fs = FileSystem.get(conf);\n    path = getPath();\n    outputStream = fs.create(path);\n    final String spoolingThreadName = QueryIdHelper.getExecutorThreadName(context.getHandle()).concat(\n        \":Spooler-\" + oppositeId + \"-\" + bufferIndex);\n    spooler = new Spooler(spoolingThreadName);\n    spooler.start();\n  }\n  @Override\n  protected void enqueueInner(RawFragmentBatch batch) throws IOException {\n    assert batch.getHeader().getSendingMajorFragmentId() == oppositeId;\n    logger.debug(\"Enqueue batch. Current buffer size: {}. Last batch: {}. Sending fragment: {}\", bufferQueue.size(), batch.getHeader().getIsLastBatch(), batch.getHeader().getSendingMajorFragmentId());\n    RawFragmentBatchWrapper wrapper;\n    boolean spoolCurrentBatch = isCurrentlySpooling();\n    wrapper = new RawFragmentBatchWrapper(batch, !spoolCurrentBatch);\n    currentSizeInMemory += wrapper.getBodySize();\n    if (spoolCurrentBatch) {\n      if (spooler == null) {\n        initSpooler();\n      }\n      spooler.addBatchForSpooling(wrapper);\n    }\n    bufferQueue.add(wrapper);\n    if (!spoolCurrentBatch && currentSizeInMemory > threshold) {\n      logger.debug(\"Buffer size {} greater than threshold {}. Start spooling to disk\", currentSizeInMemory, threshold);\n      startSpooling();<fim_middle>// function below has no smell\n"}