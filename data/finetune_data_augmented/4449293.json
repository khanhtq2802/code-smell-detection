{"text": "<fim_prefix>import org.apache.drill.exec.vector.ValueVector;\nimport org.apache.drill.exec.vector.complex.writer.BaseWriter.ComplexWriter;\nimport java.io.IOException;\nimport java.util.HashMap;\nimport java.util.List;\nimport static org.apache.drill.exec.record.RecordBatch.IterOutcome.EMIT;\npublic class ProjectRecordBatch extends AbstractSingleRecordBatch<Project> {\n  private static final org.slf4j.Logger logger = org.slf4j.LoggerFactory.getLogger(ProjectRecordBatch.class);\n  private static final String EMPTY_STRING = \"\";\n  private Projector projector;\n  private List<ValueVector> allocationVectors;\n  private List<ComplexWriter> complexWriters;\n  private List<FieldReference> complexFieldReferencesList;\n  private boolean hasRemainder = false;\n  private int remainderIndex;\n  private int recordCount;\n  private ProjectMemoryManager memoryManager;\n  private boolean first = true;\n  private boolean wasNone = false; // whether a NONE iter outcome was already seen\n  private ColumnExplorer columnExplorer;\n  private class ClassifierResult {\n    public boolean isStar = false;\n    public List<String> outputNames;\n    public String prefix = \"\";\n    public HashMap<String, Integer> prefixMap = Maps.newHashMap();\n    public CaseInsensitiveMap outputMap = new CaseInsensitiveMap();\n    private final CaseInsensitiveMap sequenceMap = new CaseInsensitiveMap();\n    private void clear() {\n      isStar = false;\n      prefix = \"\";\n      if (outputNames != null) {\n        outputNames.clear();\n      }\n      // note:  don't clear the internal maps since they have cumulative data..\n    }\n  }\n  public ProjectRecordBatch(final Project pop, final RecordBatch incoming, final FragmentContext context) throws OutOfMemoryException {\n    super(pop, context, incoming);\n    columnExplorer = new ColumnExplorer(context.getOptions());\n  }\n  @Override\n  public int getRecordCount() {\n    return recordCount;\n  }\n  @Override\n  protected void killIncoming(final boolean sendUpstream) {\n    super.killIncoming(sendUpstream);\n    hasRemainder = false;\n  }\n  @Override\n  public IterOutcome innerNext() {\n    if (wasNone) {\n      return IterOutcome.NONE;\n    }\n    recordCount = 0;\n    if (hasRemainder) {\n      handleRemainder();\n      // Check if we are supposed to return EMIT outcome and have consumed entire batch\n      return getFinalOutcome(hasRemainder);\n    }\n    return super.innerNext();\n  }\n  @Override\n  public VectorContainer getOutgoingContainer() {\n    return container;\n  }\n  @Override\n  protected IterOutcome doWork() {\n    if (wasNone) {\n      return IterOutcome.NONE;\n    }\n    int incomingRecordCount = incoming.getRecordCount();\n    logger.trace(\"doWork(): incoming rc {}, incoming {}, Project {}\", incomingRecordCount, incoming, this);\n    //calculate the output row count\n    memoryManager.update();\n    if (first && incomingRecordCount == 0) {\n      if (complexWriters != null) {\n        IterOutcome next = null;\n        while (incomingRecordCount == 0) {\n          if (getLastKnownOutcome() == EMIT) {\n            throw new UnsupportedOperationException(\"Currently functions producing complex types as output is not \" +\n                    \"supported in project list for subquery between LATERAL and UNNEST. Please re-write the query using this \" +\n                    \"function in the projection list of outermost query.\");\n          }\n          next = next(incoming);\n          setLastKnownOutcome(next);\n          if (next == IterOutcome.OUT_OF_MEMORY) {\n            outOfMemory = true;\n            return next;\n          } else if (next == IterOutcome.NONE) {\n            // since this is first batch and we already got a NONE, need to set up the schema\n            if (!doAlloc(0)) {\n              outOfMemory = true;\n              return IterOutcome.OUT_OF_MEMORY;\n            }\n            setValueCount(0);\n            // Only need to add the schema for the complex exprs because others should already have\n            // been setup during setupNewSchema\n            for (FieldReference fieldReference : complexFieldReferencesList) {\n              MaterializedField field = MaterializedField.create(fieldReference.getAsNamePart().getName(),\n                      UntypedNullHolder.TYPE);\n              container.add(new UntypedNullVector(field, container.getAllocator()));\n            }\n            container.buildSchema(SelectionVectorMode.NONE);\n            wasNone = true;\n            return IterOutcome.OK_NEW_SCHEMA;\n          } else if (next != IterOutcome.OK && next != IterOutcome.OK_NEW_SCHEMA && next != EMIT) {\n            return next;\n          } else if (next == IterOutcome.OK_NEW_SCHEMA) {\n            try {\n              setupNewSchema();\n            } catch (final SchemaChangeException e) {\n              throw new RuntimeException(e);\n            }\n          }\n          incomingRecordCount = incoming.getRecordCount();\n          memoryManager.update();\n          logger.trace(\"doWork():[1] memMgr RC {}, incoming rc {}, incoming {}, Project {}\",\n                       memoryManager.getOutputRowCount(), incomingRecordCount, incoming, this);\n        }\n      }\n    }\n    if (complexWriters != null && getLastKnownOutcome() == EMIT) {\n      throw new UnsupportedOperationException(\"Currently functions producing complex types as output are not \" +\n        \"supported in project list for subquery between LATERAL and UNNEST. Please re-write the query using this \" +\n        \"function in the projection list of outermost query.\");\n    }\n    first = false;\n    container.zeroVectors();\n    int maxOuputRecordCount = memoryManager.getOutputRowCount();\n    logger.trace(\"doWork():[2] memMgr RC {}, incoming rc {}, incoming {}, project {}\",\n                 memoryManager.getOutputRowCount(), incomingRecordCount, incoming, this);\n    if (!doAlloc(maxOuputRecordCount)) {\n      outOfMemory = true;\n      return IterOutcome.OUT_OF_MEMORY;\n    }\n    long projectStartTime = System.currentTimeMillis();\n    final int outputRecords = projector.projectRecords(this.incoming,0, maxOuputRecordCount, 0);\n    long projectEndTime = System.currentTimeMillis();\n    logger.trace(\"doWork(): projection: records {}, time {} ms\", outputRecords, (projectEndTime - projectStartTime));\n    if (outputRecords < incomingRecordCount) {\n      setValueCount(outputRecords);\n      hasRemainder = true;\n      remainderIndex = outputRecords;\n      this.recordCount = remainderIndex;\n    } else {\n      setValueCount(incomingRecordCount);\n      for (final VectorWrapper<?> v: incoming) {\n        v.clear();\n      }\n      this.recordCount = outputRecords;\n    }\n    // In case of complex writer expression, vectors would be added to batch run-time.\n    // We have to re-build the schema.\n    if (complexWriters != null) {\n      container.buildSchema(SelectionVectorMode.NONE);\n    }\n    memoryManager.updateOutgoingStats(outputRecords);\n    RecordBatchStats.logRecordBatchStats(RecordBatchIOType.OUTPUT, this, getRecordBatchStatsContext());\n    // Get the final outcome based on hasRemainder since that will determine if all the incoming records were\n    // consumed in current output batch or not\n    return getFinalOutcome(hasRemainder);\n  }\n<fim_suffix>  private void handleRemainder() {\n    final int remainingRecordCount = incoming.getRecordCount() - remainderIndex;\n    assert this.memoryManager.incomingBatch == incoming;\n    final int recordsToProcess = Math.min(remainingRecordCount, memoryManager.getOutputRowCount());\n    if (!doAlloc(recordsToProcess)) {\n      outOfMemory = true;\n      return;\n    }\n    logger.trace(\"handleRemainder: remaining RC {}, toProcess {}, remainder index {}, incoming {}, Project {}\",\n                 remainingRecordCount, recordsToProcess, remainderIndex, incoming, this);\n    long projectStartTime = System.currentTimeMillis();\n    final int projRecords = projector.projectRecords(this.incoming, remainderIndex, recordsToProcess, 0);\n    long projectEndTime = System.currentTimeMillis();\n    logger.trace(\"handleRemainder: projection: records {}, time {} ms\", projRecords,(projectEndTime - projectStartTime));\n    if (projRecords < remainingRecordCount) {\n      setValueCount(projRecords);\n      this.recordCount = projRecords;\n      remainderIndex += projRecords;\n    } else {\n      setValueCount(remainingRecordCount);\n      hasRemainder = false;\n      remainderIndex = 0;\n      for (final VectorWrapper<?> v : incoming) {\n        v.clear();\n      }\n      this.recordCount = remainingRecordCount;\n    }\n    // In case of complex writer expression, vectors would be added to batch run-time.\n    // We have to re-build the schema.\n    if (complexWriters != null) {\n      container.buildSchema(SelectionVectorMode.NONE);\n    }\n    memoryManager.updateOutgoingStats(projRecords);\n    RecordBatchStats.logRecordBatchStats(RecordBatchIOType.OUTPUT, this, getRecordBatchStatsContext());\n  }<fim_middle>// function below is long method\n"}