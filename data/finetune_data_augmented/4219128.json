{"text": "<fim_prefix>        registerParentRepairSession(parentRepairSession, coordinator, columnFamilyStores, options.getRanges(), options.isIncremental(), repairedAt, options.isGlobal(), options.getPreviewKind());\n        final CountDownLatch prepareLatch = new CountDownLatch(endpoints.size());\n        final AtomicBoolean status = new AtomicBoolean(true);\n        final Set<String> failedNodes = Collections.synchronizedSet(new HashSet<String>());\n        IAsyncCallbackWithFailure callback = new IAsyncCallbackWithFailure()\n        {\n            public void response(MessageIn msg)\n            {\n                prepareLatch.countDown();\n            }\n            public boolean isLatencyForSnitch()\n            {\n                return false;\n            }\n            public void onFailure(InetAddressAndPort from, RequestFailureReason failureReason)\n            {\n                status.set(false);\n                failedNodes.add(from.toString());\n                prepareLatch.countDown();\n            }\n        };\n        List<TableId> tableIds = new ArrayList<>(columnFamilyStores.size());\n        for (ColumnFamilyStore cfs : columnFamilyStores)\n            tableIds.add(cfs.metadata.id);\n        for (InetAddressAndPort neighbour : endpoints)\n        {\n            if (FailureDetector.instance.isAlive(neighbour))\n            {\n                PrepareMessage message = new PrepareMessage(parentRepairSession, tableIds, options.getRanges(), options.isIncremental(), repairedAt, options.isGlobal(), options.getPreviewKind());\n                MessageOut<RepairMessage> msg = message.createMessage();\n                MessagingService.instance().sendRR(msg, neighbour, callback, DatabaseDescriptor.getRpcTimeout(), true);\n            }\n            else\n            {\n                // we pre-filter the endpoints we want to repair for forced incremental repairs. So if any of the\n                // remaining ones go down, we still want to fail so we don't create repair sessions that can't complete\n                if (isForcedRepair && !options.isIncremental())\n                {\n                    prepareLatch.countDown();\n                }\n                else\n                {\n                    // bailout early to avoid potentially waiting for a long time.\n                    failRepair(parentRepairSession, \"Endpoint not alive: \" + neighbour);\n                }\n            }\n        }\n        try\n        {\n            // Failed repair is expensive so we wait for longer time.\n            if (!prepareLatch.await(1, TimeUnit.HOURS)) {\n                failRepair(parentRepairSession, \"Did not get replies from all endpoints.\");\n            }\n        }\n        catch (InterruptedException e)\n        {\n            failRepair(parentRepairSession, \"Interrupted while waiting for prepare repair response.\");\n        }\n        if (!status.get())\n        {\n            failRepair(parentRepairSession, \"Got negative replies from endpoints \" + failedNodes);\n        }\n        return parentRepairSession;\n    }\n    private void failRepair(UUID parentRepairSession, String errorMsg) {\n        removeParentRepairSession(parentRepairSession);\n        throw new RuntimeException(errorMsg);\n    }\n    public synchronized void registerParentRepairSession(UUID parentRepairSession, InetAddressAndPort coordinator, List<ColumnFamilyStore> columnFamilyStores, Collection<Range<Token>> ranges, boolean isIncremental, long repairedAt, boolean isGlobal, PreviewKind previewKind)\n    {\n        assert isIncremental || repairedAt == ActiveRepairService.UNREPAIRED_SSTABLE;\n        if (!registeredForEndpointChanges)\n        {\n            Gossiper.instance.register(this);\n            FailureDetector.instance.registerFailureDetectionEventListener(this);\n            registeredForEndpointChanges = true;\n        }\n        if (!parentRepairSessions.containsKey(parentRepairSession))\n        {\n            parentRepairSessions.put(parentRepairSession, new ParentRepairSession(coordinator, columnFamilyStores, ranges, isIncremental, repairedAt, isGlobal, previewKind));\n        }\n    }\n    public ParentRepairSession getParentRepairSession(UUID parentSessionId)\n    {\n        ParentRepairSession session = parentRepairSessions.get(parentSessionId);\n        // this can happen if a node thinks that the coordinator was down, but that coordinator got back before noticing\n        // that it was down itself.\n        if (session == null)\n            throw new RuntimeException(\"Parent repair session with id = \" + parentSessionId + \" has failed.\");\n        return session;\n    }\n    /**\n     * called when the repair session is done - either failed or anticompaction has completed\n     *\n     * clears out any snapshots created by this repair\n     *\n     * @param parentSessionId\n     * @return\n     */\n    public synchronized ParentRepairSession removeParentRepairSession(UUID parentSessionId)\n    {\n        String snapshotName = parentSessionId.toString();\n        for (ColumnFamilyStore cfs : getParentRepairSession(parentSessionId).columnFamilyStores.values())\n        {\n            if (cfs.snapshotExists(snapshotName))\n                cfs.clearSnapshot(snapshotName);\n        }\n        return parentRepairSessions.remove(parentSessionId);\n    }\n    public void handleMessage(InetAddressAndPort endpoint, RepairMessage message)\n    {\n        RepairJobDesc desc = message.desc;\n        RepairSession session = sessions.get(desc.sessionId);\n        if (session == null)\n            return;\n        switch (message.messageType)\n        {\n            case VALIDATION_COMPLETE:\n                ValidationComplete validation = (ValidationComplete) message;\n                session.validationComplete(desc, endpoint, validation.trees);\n                break;\n            case SYNC_COMPLETE:\n                // one of replica is synced.\n                SyncComplete sync = (SyncComplete) message;\n                session.syncComplete(desc, sync.nodes, sync.success, sync.summaries);\n                break;\n            default:\n                break;\n        }\n    }\n    /**\n     * We keep a ParentRepairSession around for the duration of the entire repair, for example, on a 256 token vnode rf=3 cluster\n     * we would have 768 RepairSession but only one ParentRepairSession. We use the PRS to avoid anticompacting the sstables\n     * 768 times, instead we take all repaired ranges at the end of the repair and anticompact once.\n     */\n    public static class ParentRepairSession\n    {\n        private final Keyspace keyspace;\n        private final Map<TableId, ColumnFamilyStore> columnFamilyStores = new HashMap<>();\n        private final Collection<Range<Token>> ranges;\n        public final boolean isIncremental;\n        public final boolean isGlobal;\n        public final long repairedAt;\n        public final InetAddressAndPort coordinator;\n        public final PreviewKind previewKind;\n        public ParentRepairSession(InetAddressAndPort coordinator, List<ColumnFamilyStore> columnFamilyStores, Collection<Range<Token>> ranges, boolean isIncremental, long repairedAt, boolean isGlobal, PreviewKind previewKind)\n        {\n            this.coordinator = coordinator;\n            Set<Keyspace> keyspaces = new HashSet<>();\n            for (ColumnFamilyStore cfs : columnFamilyStores)\n            {\n                keyspaces.add(cfs.keyspace);\n                this.columnFamilyStores.put(cfs.metadata.id, cfs);\n            }\n            Preconditions.checkArgument(keyspaces.size() == 1, \"repair sessions cannot operate on multiple keyspaces\");\n            this.keyspace = Iterables.getOnlyElement(keyspaces);\n            this.ranges = ranges;\n            this.repairedAt = repairedAt;\n            this.isIncremental = isIncremental;\n            this.isGlobal = isGlobal;\n            this.previewKind = previewKind;\n        }\n        public boolean isPreview()\n        {\n            return previewKind != PreviewKind.NONE;\n        }\n        public Collection<ColumnFamilyStore> getColumnFamilyStores()\n        {\n            return ImmutableSet.<ColumnFamilyStore>builder().addAll(columnFamilyStores.values()).build();\n        }\n        public Keyspace getKeyspace()\n        {\n            return keyspace;\n        }\n        public Set<TableId> getTableIds()\n        {\n            return ImmutableSet.copyOf(transform(getColumnFamilyStores(), cfs -> cfs.metadata.id));\n        }\n        public Set<Range<Token>> getRanges()\n        {\n            return ImmutableSet.copyOf(ranges);\n        }\n        @Override\n        public String toString()\n        {\n            return \"ParentRepairSession{\" +\n                    \"columnFamilyStores=\" + columnFamilyStores +\n                    \", ranges=\" + ranges +\n                    \", repairedAt=\" + repairedAt +\n                    '}';\n        }\n    }\n    /*\n    If the coordinator node dies we should remove the parent repair session from the other nodes.\n    This uses the same notifications as we get in RepairSession\n     */\n    public void onJoin(InetAddressAndPort endpoint, EndpointState epState) {}\n    public void beforeChange(InetAddressAndPort endpoint, EndpointState currentState, ApplicationState newStateKey, VersionedValue newValue) {}\n    public void onChange(InetAddressAndPort endpoint, ApplicationState state, VersionedValue value) {}\n    public void onAlive(InetAddressAndPort endpoint, EndpointState state) {}\n    public void onDead(InetAddressAndPort endpoint, EndpointState state) {}\n<fim_suffix>    public void onRemove(InetAddressAndPort endpoint)\n    {\n        convict(endpoint, Double.MAX_VALUE);\n    }<fim_middle>// function below has no smell\n"}