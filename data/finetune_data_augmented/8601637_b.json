{"text": "<fim_prefix>/*\n * Licensed to the Apache Software Foundation (ASF) under one or more\n * contributor license agreements. See the NOTICE file distributed with this\n * work for additional information regarding copyright ownership. The ASF\n * licenses this file to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n * License for the specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.hadoop.hbase.io.encoding;\n\nimport static org.apache.hadoop.hbase.io.compress.Compression.Algorithm.NONE;\n\nimport java.io.ByteArrayInputStream;\nimport java.io.DataOutputStream;\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.security.SecureRandom;\n\nimport org.apache.hadoop.hbase.io.ByteArrayOutputStream;\nimport org.apache.hadoop.hbase.io.TagCompressionContext;\nimport org.apache.hadoop.hbase.io.compress.Compression;\nimport org.apache.hadoop.hbase.io.crypto.Cipher;\nimport org.apache.hadoop.hbase.io.crypto.Encryption;\nimport org.apache.hadoop.hbase.io.crypto.Encryptor;\nimport org.apache.hadoop.hbase.io.hfile.BlockType;\nimport org.apache.hadoop.hbase.io.hfile.HFileContext;\nimport org.apache.hadoop.hbase.util.Bytes;\nimport org.apache.hadoop.io.compress.CompressionOutputStream;\nimport org.apache.hadoop.io.compress.Compressor;\nimport org.apache.yetus.audience.InterfaceAudience;\n\nimport org.apache.hbase.thirdparty.com.google.common.base.Preconditions;\n\n/**\n * A default implementation of {@link HFileBlockEncodingContext}. It will\n * compress the data section as one continuous buffer.\n *\n * @see HFileBlockDefaultDecodingContext for the decompression part\n *\n */\n<fim_suffix>@InterfaceAudience.Private\npublic class HFileBlockDefaultEncodingContext implements\n    HFileBlockEncodingContext {\n  private BlockType blockType;\n  private final DataBlockEncoding encodingAlgo;\n\n  private byte[] dummyHeader;\n\n  // Compression state\n\n  /** Compressor, which is also reused between consecutive blocks. */\n  private Compressor compressor;\n  /** Compression output stream */\n  private CompressionOutputStream compressionStream;\n  /** Underlying stream to write compressed bytes to */\n  private ByteArrayOutputStream compressedByteStream;\n\n  private HFileContext fileContext;\n  private TagCompressionContext tagCompressionContext;\n\n  // Encryption state\n\n  /** Underlying stream to write encrypted bytes to */\n  private ByteArrayOutputStream cryptoByteStream;\n  /** Initialization vector */\n  private byte[] iv;\n\n  private EncodingState encoderState;\n\n  /**\n   * @param encoding encoding used\n   * @param headerBytes dummy header bytes\n   * @param fileContext HFile meta data\n   */\n  public HFileBlockDefaultEncodingContext(DataBlockEncoding encoding, byte[] headerBytes,\n      HFileContext fileContext) {\n    this.encodingAlgo = encoding;\n    this.fileContext = fileContext;\n    Compression.Algorithm compressionAlgorithm =\n        fileContext.getCompression() == null ? NONE : fileContext.getCompression();\n    if (compressionAlgorithm != NONE) {\n      compressor = compressionAlgorithm.getCompressor();\n      compressedByteStream = new ByteArrayOutputStream();\n      try {\n        compressionStream =\n            compressionAlgorithm.createPlainCompressionStream(\n                compressedByteStream, compressor);\n      } catch (IOException e) {\n        throw new RuntimeException(\n            \"Could not create compression stream for algorithm \"\n                + compressionAlgorithm, e);\n      }\n    }\n\n    Encryption.Context cryptoContext = fileContext.getEncryptionContext();\n    if (cryptoContext != Encryption.Context.NONE) {\n      cryptoByteStream = new ByteArrayOutputStream();\n      iv = new byte[cryptoContext.getCipher().getIvLength()];\n      new SecureRandom().nextBytes(iv);\n    }\n\n    dummyHeader = Preconditions.checkNotNull(headerBytes,\n      \"Please pass HConstants.HFILEBLOCK_DUMMY_HEADER instead of null for param headerBytes\");\n  }\n\n  /**\n   * prepare to start a new encoding.\n   * @throws IOException\n   */\n  public void prepareEncoding(DataOutputStream out) throws IOException {\n    if (encodingAlgo != null && encodingAlgo != DataBlockEncoding.NONE) {\n      encodingAlgo.writeIdInBytes(out);\n    }\n  }\n\n  @Override\n  public void postEncoding(BlockType blockType)\n      throws IOException {\n    this.blockType = blockType;\n  }\n\n  @Override\n  public Bytes compressAndEncrypt(byte[] data, int offset, int length) throws IOException {\n    return compressAfterEncoding(data, offset, length, dummyHeader);\n  }\n\n  private Bytes compressAfterEncoding(byte[] uncompressedBytesWithHeaderBuffer,\n        int uncompressedBytesWithHeaderOffset, int uncompressedBytesWithHeaderLength, byte[] headerBytes)\n      throws IOException {\n    Encryption.Context cryptoContext = fileContext.getEncryptionContext();\n    if (cryptoContext != Encryption.Context.NONE) {\n\n      // Encrypted block format:\n      // +--------------------------+\n      // | byte iv length           |\n      // +--------------------------+\n      // | iv data ...              |\n      // +--------------------------+\n      // | encrypted block data ... |\n      // +--------------------------+\n\n      cryptoByteStream.reset();\n      // Write the block header (plaintext)\n      cryptoByteStream.write(headerBytes);\n\n      InputStream in;\n      int plaintextLength;\n      // Run any compression before encryption\n      if (fileContext.getCompression() != Compression.Algorithm.NONE) {\n        compressedByteStream.reset();\n        compressionStream.resetState();\n        compressionStream.write(uncompressedBytesWithHeaderBuffer,\n            headerBytes.length + uncompressedBytesWithHeaderOffset, uncompressedBytesWithHeaderLength - headerBytes.length);\n        compressionStream.flush();\n        compressionStream.finish();\n        byte[] plaintext = compressedByteStream.toByteArray();\n        plaintextLength = plaintext.length;\n        in = new ByteArrayInputStream(plaintext);\n      } else {\n        plaintextLength = uncompressedBytesWithHeaderLength - headerBytes.length;\n        in = new ByteArrayInputStream(uncompressedBytesWithHeaderBuffer,\n          headerBytes.length + uncompressedBytesWithHeaderOffset, plaintextLength);\n      }\n\n      if (plaintextLength > 0) {\n\n        // Set up the cipher\n        Cipher cipher = cryptoContext.getCipher();\n        Encryptor encryptor = cipher.getEncryptor();\n        encryptor.setKey(cryptoContext.getKey());\n\n        // Set up the IV\n        int ivLength = iv.length;\n        Preconditions.checkState(ivLength <= Byte.MAX_VALUE, \"IV length out of range\");\n        cryptoByteStream.write(ivLength);\n        if (ivLength > 0) {\n          encryptor.setIv(iv);\n          cryptoByteStream.write(iv);\n        }\n\n        // Encrypt the data\n        Encryption.encrypt(cryptoByteStream, in, encryptor);\n\n        // Increment the IV given the final block size\n        Encryption.incrementIv(iv, 1 + (cryptoByteStream.size() / encryptor.getBlockSize()));\n        return new Bytes(cryptoByteStream.getBuffer(), 0, cryptoByteStream.size());\n      } else {\n\n        cryptoByteStream.write(0);\n        return new Bytes(cryptoByteStream.getBuffer(), 0, cryptoByteStream.size());\n      }\n\n    } else {\n\n      if (this.fileContext.getCompression() != NONE) {\n        compressedByteStream.reset();\n        compressedByteStream.write(headerBytes);\n        compressionStream.resetState();\n        compressionStream.write(uncompressedBytesWithHeaderBuffer,\n          headerBytes.length + uncompressedBytesWithHeaderOffset, uncompressedBytesWithHeaderLength\n              - headerBytes.length);\n        compressionStream.flush();\n        compressionStream.finish();\n        return new Bytes(compressedByteStream.getBuffer(), 0, compressedByteStream.size());\n      } else {\n        return null;\n      }\n    }\n  }\n\n  @Override\n  public BlockType getBlockType() {\n    return blockType;\n  }\n\n  /**\n   * Releases the compressor this writer uses to compress blocks into the\n   * compressor pool.\n   */\n  @Override\n  public void close() {\n    if (compressor != null) {\n      this.fileContext.getCompression().returnCompressor(compressor);\n      compressor = null;\n    }\n  }\n\n  @Override\n  public DataBlockEncoding getDataBlockEncoding() {\n    return this.encodingAlgo;\n  }\n\n  @Override\n  public HFileContext getHFileContext() {\n    return this.fileContext;\n  }\n\n  public TagCompressionContext getTagCompressionContext() {\n    return tagCompressionContext;\n  }\n\n  public void setTagCompressionContext(TagCompressionContext tagCompressionContext) {\n    this.tagCompressionContext = tagCompressionContext;\n  }\n\n  @Override\n  public EncodingState getEncodingState() {\n    return this.encoderState;\n  }\n\n  @Override\n  public void setEncodingState(EncodingState state) {\n    this.encoderState = state;\n  }\n}<fim_middle>// class below is data class and blob\n"}