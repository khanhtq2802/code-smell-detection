{"text": "<fim_prefix>    static {\n        final List<PropertyDescriptor> _properties = new ArrayList<>();\n        _properties.add(RECORD_READER);\n        _properties.add(RECORD_WRITER);\n        _properties.add(JOLT_TRANSFORM);\n        _properties.add(CUSTOM_CLASS);\n        _properties.add(MODULES);\n        _properties.add(JOLT_SPEC);\n        _properties.add(TRANSFORM_CACHE_SIZE);\n        properties = Collections.unmodifiableList(_properties);\n        final Set<Relationship> _relationships = new HashSet<>();\n        _relationships.add(REL_SUCCESS);\n        _relationships.add(REL_FAILURE);\n        _relationships.add(REL_ORIGINAL);\n        relationships = Collections.unmodifiableSet(_relationships);\n    }\n    @Override\n    public Set<Relationship> getRelationships() {\n        return relationships;\n    }\n    @Override\n    protected List<PropertyDescriptor> getSupportedPropertyDescriptors() {\n        return properties;\n    }\n    @Override\n    protected Collection<ValidationResult> customValidate(ValidationContext validationContext) {\n        final List<ValidationResult> results = new ArrayList<>(super.customValidate(validationContext));\n        final String transform = validationContext.getProperty(JOLT_TRANSFORM).getValue();\n        final String customTransform = validationContext.getProperty(CUSTOM_CLASS).getValue();\n        if (!validationContext.getProperty(JOLT_SPEC).isSet() || StringUtils.isEmpty(validationContext.getProperty(JOLT_SPEC).getValue())) {\n            if (!SORTR.getValue().equals(transform)) {\n                final String message = \"A specification is required for this transformation\";\n                results.add(new ValidationResult.Builder().valid(false)\n                        .explanation(message)\n                        .build());\n            }\n        } else {\n            try {\n                final String specValue = validationContext.getProperty(JOLT_SPEC).getValue();\n                if (validationContext.isExpressionLanguagePresent(specValue)) {\n                    final String invalidExpressionMsg = validationContext.newExpressionLanguageCompiler().validateExpression(specValue, true);\n                    if (!StringUtils.isEmpty(invalidExpressionMsg)) {\n                        results.add(new ValidationResult.Builder().valid(false)\n                                .subject(JOLT_SPEC.getDisplayName())\n                                .explanation(\"Invalid Expression Language: \" + invalidExpressionMsg)\n                                .build());\n                    }\n                } else {\n                    //for validation we want to be able to ensure the spec is syntactically correct and not try to resolve variables since they may not exist yet\n                    Object specJson = SORTR.getValue().equals(transform) ? null : JsonUtils.jsonToObject(specValue.replaceAll(\"\\\\$\\\\{\", \"\\\\\\\\\\\\\\\\\\\\$\\\\{\"), DEFAULT_CHARSET);\n                    if (CUSTOMR.getValue().equals(transform)) {\n                        if (StringUtils.isEmpty(customTransform)) {\n                            final String customMessage = \"A custom transformation class should be provided. \";\n                            results.add(new ValidationResult.Builder().valid(false)\n                                    .explanation(customMessage)\n                                    .build());\n                        } else {\n                            TransformFactory.getCustomTransform(Thread.currentThread().getContextClassLoader(), customTransform, specJson);\n                        }\n                    } else {\n                        TransformFactory.getTransform(Thread.currentThread().getContextClassLoader(), transform, specJson);\n                    }\n                }\n            } catch (final Exception e) {\n                getLogger().info(\"Processor is not valid - \" + e.toString());\n                String message = \"Specification not valid for the selected transformation.\";\n                results.add(new ValidationResult.Builder().valid(false)\n                        .explanation(message)\n                        .build());\n            }\n        }\n        return results;\n    }\n    @SuppressWarnings(\"unchecked\")\n    @Override\n    public void onTrigger(final ProcessContext context, ProcessSession session) throws ProcessException {\n        final FlowFile original = session.get();\n        if (original == null) {\n            return;\n        }\n        final ComponentLog logger = getLogger();\n        final StopWatch stopWatch = new StopWatch(true);\n        final RecordReaderFactory readerFactory = context.getProperty(RECORD_READER).asControllerService(RecordReaderFactory.class);\n        final RecordSetWriterFactory writerFactory = context.getProperty(RECORD_WRITER).asControllerService(RecordSetWriterFactory.class);\n        final RecordSchema schema;\n        try (final InputStream in = session.read(original);\n             final RecordReader reader = readerFactory.createRecordReader(original, in, getLogger())) {\n            schema = writerFactory.getSchema(original.getAttributes(), reader.getSchema());\n            FlowFile transformed = session.create(original);\n            final Map<String, String> attributes = new HashMap<>();\n            final WriteResult writeResult;\n            try {\n                // We want to transform the first record before creating the Record Writer. We do this because the Record will likely end up with a different structure\n                // and therefore a difference Schema after being transformed. As a result, we want to transform the Record and then provide the transformed schema to the\n                // Record Writer so that if the Record Writer chooses to inherit the Record Schema from the Record itself, it will inherit the transformed schema, not the\n                // schema determined by the Record Reader.\n                final Record firstRecord = reader.nextRecord();\n                if (firstRecord == null) {\n                    try (final OutputStream out = session.write(transformed);\n                         final RecordSetWriter writer = writerFactory.createWriter(getLogger(), schema, out)) {\n                        writer.beginRecordSet();\n                        writeResult = writer.finishRecordSet();\n                        attributes.put(\"record.count\", String.valueOf(writeResult.getRecordCount()));\n                        attributes.put(CoreAttributes.MIME_TYPE.key(), writer.getMimeType());\n                        attributes.putAll(writeResult.getAttributes());\n                    }\n                    transformed = session.putAllAttributes(transformed, attributes);\n                    session.transfer(transformed, REL_SUCCESS);\n                    session.transfer(original, REL_ORIGINAL);\n                    logger.info(\"{} had no Records to transform\", new Object[]{original});\n                    return;\n                }\n                final JoltTransform transform = getTransform(context, original);\n                final Record transformedFirstRecord = transform(firstRecord, transform);\n                final RecordSchema writeSchema = writerFactory.getSchema(original.getAttributes(), transformedFirstRecord.getSchema());\n                // TODO: Is it possible that two Records with the same input schema could have different schemas after transformation?\n                // If so, then we need to avoid this pattern of writing all Records from the input FlowFile to the same output FlowFile\n                // and instead use a Map<RecordSchema, RecordSetWriter>. This way, even if many different output schemas are possible,\n                // the output FlowFiles will each only contain records that have the same schema.\n                try (final OutputStream out = session.write(transformed);\n                     final RecordSetWriter writer = writerFactory.createWriter(getLogger(), writeSchema, out)) {\n                    writer.beginRecordSet();\n                    writer.write(transformedFirstRecord);\n                    Record record;\n                    while ((record = reader.nextRecord()) != null) {\n                        final Record transformedRecord = transform(record, transform);\n                        writer.write(transformedRecord);\n                    }\n                    writeResult = writer.finishRecordSet();\n                    attributes.put(\"record.count\", String.valueOf(writeResult.getRecordCount()));\n                    attributes.put(CoreAttributes.MIME_TYPE.key(), writer.getMimeType());\n                    attributes.putAll(writeResult.getAttributes());\n                }\n            } catch (Exception e) {\n                logger.error(\"Unable to write transformed records {} due to {}\", new Object[]{original, e.toString(), e});\n                session.remove(transformed);\n                session.transfer(original, REL_FAILURE);\n                return;\n            }\n            final String transformType = context.getProperty(JOLT_TRANSFORM).getValue();\n            transformed = session.putAllAttributes(transformed, attributes);\n            session.transfer(transformed, REL_SUCCESS);\n            session.getProvenanceReporter().modifyContent(transformed, \"Modified With \" + transformType, stopWatch.getElapsed(TimeUnit.MILLISECONDS));\n            session.transfer(original, REL_ORIGINAL);\n            logger.debug(\"Transformed {}\", new Object[]{original});\n        } catch (final Exception ex) {\n            logger.error(\"Unable to transform {} due to {}\", new Object[]{original, ex.toString(), ex});\n            session.transfer(original, REL_FAILURE);\n        }\n    }\n<fim_suffix>    private Record transform(final Record record, final JoltTransform transform) {\n        Map<String, Object> recordMap = (Map<String, Object>) DataTypeUtils.convertRecordFieldtoObject(record, RecordFieldType.RECORD.getRecordDataType(record.getSchema()));\n        // JOLT expects arrays to be of type List where our Record code uses Object[].\n        // Make another pass of the transformed objects to change Object[] to List.\n        recordMap = (Map<String, Object>) normalizeJoltObjects(recordMap);\n        final Object transformedObject = transform(transform, recordMap);\n        // JOLT expects arrays to be of type List where our Record code uses Object[].\n        // Make another pass of the transformed objects to change List to Object[].\n        final Object normalizedRecordValues = normalizeRecordObjects(transformedObject);\n        final Record updatedRecord = DataTypeUtils.toRecord(normalizedRecordValues, \"r\");\n        return updatedRecord;\n    }<fim_middle>// function below has no smell\n"}