{"text": "<fim_prefix> * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage hivemall.sketch.hll;\nimport hivemall.UDAFEvaluatorWithOptions;\nimport hivemall.utils.hadoop.HiveUtils;\nimport hivemall.utils.lang.Preconditions;\nimport hivemall.utils.lang.Primitives;\nimport java.io.IOException;\nimport javax.annotation.Nonnegative;\nimport javax.annotation.Nonnull;\nimport javax.annotation.Nullable;\nimport org.apache.commons.cli.CommandLine;\nimport org.apache.commons.cli.Options;\nimport org.apache.hadoop.hive.ql.exec.Description;\nimport org.apache.hadoop.hive.ql.exec.UDFArgumentException;\nimport org.apache.hadoop.hive.ql.exec.UDFArgumentTypeException;\nimport org.apache.hadoop.hive.ql.metadata.HiveException;\nimport org.apache.hadoop.hive.ql.parse.SemanticException;\nimport org.apache.hadoop.hive.ql.udf.generic.AbstractGenericUDAFResolver;\nimport org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator;\nimport org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator.AbstractAggregationBuffer;\nimport org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator.AggregationType;\nimport org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;\nimport org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorUtils;\nimport org.apache.hadoop.hive.serde2.objectinspector.primitive.BinaryObjectInspector;\nimport org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorFactory;\nimport org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\nimport org.apache.hadoop.io.LongWritable;\nimport com.clearspring.analytics.stream.cardinality.CardinalityMergeException;\nimport com.clearspring.analytics.stream.cardinality.HyperLogLogPlus;\n@Description(name = \"approx_count_distinct\", value = \"_FUNC_(expr x [, const string options])\"\n        + \" - Returns an approximation of count(DISTINCT x) using HyperLogLogPlus algorithm\")\npublic final class ApproxCountDistinctUDAF extends AbstractGenericUDAFResolver {\n    @Override\n    public GenericUDAFEvaluator getEvaluator(@Nonnull TypeInfo[] typeInfo)\n            throws SemanticException {\n        if (typeInfo.length != 1 && typeInfo.length != 2) {\n            throw new UDFArgumentTypeException(typeInfo.length - 1,\n                \"_FUNC_ takes one or two arguments\");\n        }\n        if (typeInfo.length == 2 && !HiveUtils.isStringTypeInfo(typeInfo[1])) {\n            throw new UDFArgumentTypeException(1,\n                \"The second argument type expected to be const string: \" + typeInfo[1]);\n        }\n        return new HLLEvaluator();\n    }\n    public static final class HLLEvaluator extends UDAFEvaluatorWithOptions {\n        @Nullable\n        private int[] params;\n        private ObjectInspector origInputOI;\n        private BinaryObjectInspector mergeInputOI;\n        @Override\n        protected Options getOptions() {\n            Options opts = new Options();\n            opts.addOption(\"p\", true,\n                \"The size of registers for the normal set. `p` MUST be in the range [4,sp] and 15 by the default\");\n            opts.addOption(\"sp\", true,\n                \"The size of registers for the sparse set. `sp` MUST be in the range [4,32] and 25 by the default\");\n            return opts;\n        }\n        @Override\n        protected CommandLine processOptions(@Nonnull ObjectInspector[] argOIs)\n                throws UDFArgumentException {\n            CommandLine cl = null;\n            int p = 15, sp = 25;\n            if (argOIs.length == 2) {\n                if (!HiveUtils.isConstString(argOIs[1])) {\n                    throw new UDFArgumentException(\n                        \"The second argument type expected to be const string: \" + argOIs[1]);\n                }\n                cl = parseOptions(HiveUtils.getConstString(argOIs[1]));\n                p = Primitives.parseInt(cl.getOptionValue(\"p\"), p);\n                sp = Primitives.parseInt(cl.getOptionValue(\"sp\"), sp);\n                validateArguments(p, sp);\n            }\n            this.params = new int[] {p, sp};\n            return cl;\n        }\n        @Override\n        public ObjectInspector init(@Nonnull Mode mode, @Nonnull ObjectInspector[] parameters)\n                throws HiveException {\n            assert (parameters.length == 1 || parameters.length == 2) : parameters.length;\n            super.init(mode, parameters);\n            // initialize input\n            if (mode == Mode.PARTIAL1 || mode == Mode.COMPLETE) {// from original data\n                processOptions(parameters);\n                this.origInputOI = parameters[0];\n            } else {// from partial aggregation\n                this.mergeInputOI = HiveUtils.asBinaryOI(parameters[0]);\n            }\n            // initialize output\n            final ObjectInspector outputOI;\n            if (mode == Mode.PARTIAL1 || mode == Mode.PARTIAL2) {// terminatePartial\n                outputOI = PrimitiveObjectInspectorFactory.javaByteArrayObjectInspector;\n            } else {// terminate\n                outputOI = PrimitiveObjectInspectorFactory.writableLongObjectInspector;\n            }\n            return outputOI;\n        }\n        @Override\n        public HLLBuffer getNewAggregationBuffer() throws HiveException {\n            HLLBuffer buf = new HLLBuffer();\n            if (params != null) {\n                buf.reset(params[0], params[1]);\n            }\n            return buf;\n        }\n        @SuppressWarnings(\"deprecation\")\n        @Override\n        public void reset(@Nonnull AggregationBuffer agg) throws HiveException {\n            HLLBuffer buf = (HLLBuffer) agg;\n            if (params != null) {\n                buf.reset(params[0], params[1]);\n            } else {\n                buf.hll = null;\n            }\n        }\n        @SuppressWarnings(\"deprecation\")\n        @Override\n        public void iterate(@Nonnull AggregationBuffer agg, @Nonnull Object[] parameters)\n                throws HiveException {\n            if (parameters[0] == null) {\n                return;\n            }\n            HLLBuffer buf = (HLLBuffer) agg;\n            Object value =\n                    ObjectInspectorUtils.copyToStandardJavaObject(parameters[0], origInputOI);\n            Preconditions.checkNotNull(buf.hll, HiveException.class);\n            buf.hll.offer(value);\n        }\n        @SuppressWarnings(\"deprecation\")\n        @Override\n        @Nullable\n        public byte[] terminatePartial(@Nonnull AggregationBuffer agg) throws HiveException {\n            HLLBuffer buf = (HLLBuffer) agg;\n            if (buf.hll == null) {\n                return null;\n            }\n            try {\n                return buf.hll.getBytes();\n            } catch (IOException e) {\n                throw new HiveException(e);\n            }\n        }\n        @SuppressWarnings(\"deprecation\")\n        @Override\n        public void merge(@Nonnull AggregationBuffer agg, @Nullable Object partial)\n                throws HiveException {\n            if (partial == null) {\n                return;\n            }\n            byte[] data = mergeInputOI.getPrimitiveJavaObject(partial);\n            final HyperLogLogPlus otherHLL;\n            try {\n                otherHLL = HyperLogLogPlus.Builder.build(data);\n            } catch (IOException e) {\n                throw new HiveException(\"Failed to build other HLL\");\n            }\n            final HLLBuffer buf = (HLLBuffer) agg;\n            if (buf.hll == null) {\n                buf.hll = otherHLL;\n            } else {\n                try {\n                    buf.hll.addAll(otherHLL);\n                } catch (CardinalityMergeException e) {\n                    throw new HiveException(\"Failed to merge HLL\");\n                }\n            }\n        }\n        @SuppressWarnings(\"deprecation\")\n        @Override\n        public LongWritable terminate(@Nonnull AggregationBuffer agg) throws HiveException {\n            HLLBuffer buf = (HLLBuffer) agg;\n            long cardinality = (buf.hll == null) ? 0L : buf.hll.cardinality();\n            return new LongWritable(cardinality);\n        }\n    }\n<fim_suffix>    private static void validateArguments(final int p, final int sp) throws UDFArgumentException {\n        if (p < 4 || p > sp) {\n            throw new UDFArgumentException(\"p must be between 4 and sp (inclusive)\");\n        }\n        if (sp > 32) {\n            throw new UDFArgumentException(\"sp values greater than 32 not supported\");\n        }\n    }<fim_middle>// function below has no smell\n"}