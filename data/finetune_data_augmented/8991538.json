{"text": "<fim_prefix>/*\n * Licensed to the Apache Software Foundation (ASF) under one or more\n * contributor license agreements.  See the NOTICE file distributed with\n * this work for additional information regarding copyright ownership.\n * The ASF licenses this file to You under the Apache License, Version 2.0\n * (the \"License\"); you may not use this file except in compliance with\n * the License.  You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage org.apache.lucene.analysis.icu.segmentation;\n\n\nimport java.io.IOException;\nimport java.io.Reader;\n\nimport org.apache.lucene.analysis.Tokenizer;\nimport org.apache.lucene.analysis.icu.tokenattributes.ScriptAttribute;\nimport org.apache.lucene.analysis.tokenattributes.OffsetAttribute;\nimport org.apache.lucene.analysis.tokenattributes.CharTermAttribute;\nimport org.apache.lucene.analysis.tokenattributes.TypeAttribute;\nimport org.apache.lucene.util.AttributeFactory;\n\nimport com.ibm.icu.lang.UCharacter;\nimport com.ibm.icu.text.BreakIterator;\n\n/**\n * Breaks text into words according to UAX #29: Unicode Text Segmentation\n * (http://www.unicode.org/reports/tr29/)\n * <p>\n * Words are broken across script boundaries, then segmented according to\n * the BreakIterator and typing provided by the {@link ICUTokenizerConfig}\n * </p>\n * @see ICUTokenizerConfig\n * @lucene.experimental\n */\npublic final class ICUTokenizer extends Tokenizer {\n  private static final int IOBUFFER = 4096;\n  private final char buffer[] = new char[IOBUFFER];\n  /** true length of text in the buffer */\n  private int length = 0; \n  /** length in buffer that can be evaluated safely, up to a safe end point */\n  private int usableLength = 0; \n  /** accumulated offset of previous buffers for this reader, for offsetAtt */\n  private int offset = 0; \n\n  private final CompositeBreakIterator breaker; /* tokenizes a char[] of text */\n  private final ICUTokenizerConfig config;\n  private final OffsetAttribute offsetAtt = addAttribute(OffsetAttribute.class);\n  private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n  private final TypeAttribute typeAtt = addAttribute(TypeAttribute.class);\n  private final ScriptAttribute scriptAtt = addAttribute(ScriptAttribute.class);\n\n  /**\n   * Construct a new ICUTokenizer that breaks text into words from the given\n   * Reader.\n   * <p>\n   * The default script-specific handling is used.\n   * <p>\n   * The default attribute factory is used.\n   * \n   * @see DefaultICUTokenizerConfig\n   */\n  public ICUTokenizer() {\n    this(new DefaultICUTokenizerConfig(true, true));\n  }\n\n  /**\n   * Construct a new ICUTokenizer that breaks text into words from the given\n   * Reader, using a tailored BreakIterator configuration.\n   * <p>\n   * The default attribute factory is used.\n   *\n   * @param config Tailored BreakIterator configuration\n   */\n  public ICUTokenizer(ICUTokenizerConfig config) {\n    this(DEFAULT_TOKEN_ATTRIBUTE_FACTORY, config);\n  }\n\n  /**\n   * Construct a new ICUTokenizer that breaks text into words from the given\n   * Reader, using a tailored BreakIterator configuration.\n   *\n   * @param factory AttributeFactory to use\n   * @param config Tailored BreakIterator configuration\n   */\n  public ICUTokenizer(AttributeFactory factory, ICUTokenizerConfig config) {\n    super(factory);\n    this.config = config;\n    breaker = new CompositeBreakIterator(config);\n  }\n\n  @Override\n  public boolean incrementToken() throws IOException {\n    clearAttributes();\n    if (length == 0)\n      refill();\n    while (!incrementTokenBuffer()) {\n      refill();\n      if (length <= 0) // no more bytes to read;\n        return false;\n    }\n    return true;\n  }\n  \n  @Override\n  public void reset() throws IOException {\n    super.reset();\n    breaker.setText(buffer, 0, 0);\n    length = usableLength = offset = 0;\n  }\n  \n  @Override\n  public void end() throws IOException {\n    super.end();\n    final int finalOffset = (length < 0) ? offset : offset + length;\n    offsetAtt.setOffset(correctOffset(finalOffset), correctOffset(finalOffset));\n  }  \n\n  /*\n   * This tokenizes text based upon the longest matching rule, and because of \n   * this, isn't friendly to a Reader.\n   * \n   * Text is read from the input stream in 4kB chunks. Within a 4kB chunk of\n   * text, the last unambiguous break point is found (in this implementation:\n   * white space character) Any remaining characters represent possible partial\n   * words, so are appended to the front of the next chunk.\n   * \n   * There is the possibility that there are no unambiguous break points within\n   * an entire 4kB chunk of text (binary data). So there is a maximum word limit\n   * of 4kB since it will not try to grow the buffer in this case.\n   */\n\n  /**\n   * Returns the last unambiguous break position in the text.\n   * \n   * @return position of character, or -1 if one does not exist\n   */\n  private int findSafeEnd() {\n    for (int i = length - 1; i >= 0; i--)\n      if (UCharacter.isWhitespace(buffer[i]))\n        return i + 1;\n    return -1;\n  }\n\n  /**\n   * Refill the buffer, accumulating the offset and setting usableLength to the\n   * last unambiguous break position\n   * \n   * @throws IOException If there is a low-level I/O error.\n   */\n<fim_suffix>  private void refill() throws IOException {\n    offset += usableLength;\n    int leftover = length - usableLength;\n    System.arraycopy(buffer, usableLength, buffer, 0, leftover);\n    int requested = buffer.length - leftover;\n    int returned = read(input, buffer, leftover, requested);\n    length = returned + leftover;\n    if (returned < requested) /* reader has been emptied, process the rest */\n      usableLength = length;\n    else { /* still more data to be read, find a safe-stopping place */\n      usableLength = findSafeEnd();\n      if (usableLength < 0)\n        usableLength = length; /*\n                                * more than IOBUFFER of text without space,\n                                * gonna possibly truncate tokens\n                                */\n    }\n\n    breaker.setText(buffer, 0, Math.max(0, usableLength));\n  }\n\n  // TODO: refactor to a shared readFully somewhere\n  // (NGramTokenizer does this too):\n  /** commons-io's readFully, but without bugs if offset != 0 */\n  private static int read(Reader input, char[] buffer, int offset, int length) throws IOException {\n    assert length >= 0 : \"length must not be negative: \" + length;\n \n    int remaining = length;\n    while ( remaining > 0 ) {\n      int location = length - remaining;\n      int count = input.read( buffer, offset + location, remaining );\n      if ( -1 == count ) { // EOF\n        break;\n      }\n      remaining -= count;\n    }\n    return length - remaining;\n  }\n\n  /*\n   * return true if there is a token from the buffer, or null if it is\n   * exhausted.\n   */\n  private boolean incrementTokenBuffer() {\n    int start = breaker.current();\n    assert start != BreakIterator.DONE;\n\n    // find the next set of boundaries, skipping over non-tokens (rule status 0)\n    int end = breaker.next();\n    while (end != BreakIterator.DONE && breaker.getRuleStatus() == 0) {\n      start = end;\n      end = breaker.next();\n    }\n\n    if (end == BreakIterator.DONE) {\n      return false; // BreakIterator exhausted\n    }\n\n    termAtt.copyBuffer(buffer, start, end - start);\n    offsetAtt.setOffset(correctOffset(offset + start), correctOffset(offset + end));\n    typeAtt.setType(config.getType(breaker.getScriptCode(), breaker.getRuleStatus()));\n    scriptAtt.setCode(breaker.getScriptCode());\n\n    return true;\n  }\n}<fim_middle>// function below has no smell\n"}