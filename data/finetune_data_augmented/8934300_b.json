{"text": "<fim_prefix>              add(leftRCount).\n              add(rightRCount).\n              build();\n      ImmutableBitSet.Builder streamingBuilder = ImmutableBitSet.builder();\n      switch (join.getStreamingSide()) {\n        case LEFT_RELATION:\n          streamingBuilder.set(0);\n          break;\n        case RIGHT_RELATION:\n          streamingBuilder.set(1);\n          break;\n        default:\n          return null;\n      }\n      ImmutableBitSet streaming = streamingBuilder.build();\n      final double cpuCost = algoUtils.computeMapJoinCPUCost(cardinalities, streaming);\n      // 3. IO cost = cost of transferring small tables to join node *\n      //              degree of parallelism\n      final Double leftRAverageSize = mq.getAverageRowSize(join.getLeft());\n      final Double rightRAverageSize = mq.getAverageRowSize(join.getRight());\n      if (leftRAverageSize == null || rightRAverageSize == null) {\n        return null;\n      }\n      ImmutableList<Pair<Double,Double>> relationInfos = new ImmutableList.Builder<Pair<Double,Double>>().\n              add(new Pair<Double,Double>(leftRCount,leftRAverageSize)).\n              add(new Pair<Double,Double>(rightRCount,rightRAverageSize)).\n              build();\n      JoinAlgorithm oldAlgo = join.getJoinAlgorithm();\n      join.setJoinAlgorithm(TezMapJoinAlgorithm.INSTANCE);\n      final int parallelism = mq.splitCount(join) == null\n              ? 1 : mq.splitCount(join);\n      join.setJoinAlgorithm(oldAlgo);\n      final double ioCost = algoUtils.computeMapJoinIOCost(relationInfos, streaming, parallelism);\n      // 4. Result\n      return HiveCost.FACTORY.makeCost(rCount, cpuCost, ioCost);\n    }\n    @Override\n    public ImmutableList<RelCollation> getCollation(HiveJoin join) {\n      final MapJoinStreamingRelation streamingSide = join.getStreamingSide();\n      if (streamingSide != MapJoinStreamingRelation.LEFT_RELATION\n              && streamingSide != MapJoinStreamingRelation.RIGHT_RELATION) {\n        // Error; default value\n        LOG.warn(\"Streaming side for map join not chosen\");\n        return ImmutableList.of();\n      }\n      return HiveAlgorithmsUtil.getJoinCollation(join.getJoinPredicateInfo(),\n              join.getStreamingSide());\n    }\n    @Override\n    public RelDistribution getDistribution(HiveJoin join) {\n      final MapJoinStreamingRelation streamingSide = join.getStreamingSide();\n      if (streamingSide != MapJoinStreamingRelation.LEFT_RELATION\n              && streamingSide != MapJoinStreamingRelation.RIGHT_RELATION) {\n        // Error; default value\n        LOG.warn(\"Streaming side for map join not chosen\");\n        return RelDistributions.SINGLETON;\n      }\n      return HiveAlgorithmsUtil.getJoinDistribution(join.getJoinPredicateInfo(),\n              join.getStreamingSide());\n    }\n    @Override\n    public Double getMemory(HiveJoin join) {\n      return HiveAlgorithmsUtil.getJoinMemory(join);\n    }\n    @Override\n    public Double getCumulativeMemoryWithinPhaseSplit(HiveJoin join) {\n      // Check streaming side\n      RelNode inMemoryInput;\n      if (join.getStreamingSide() == MapJoinStreamingRelation.LEFT_RELATION) {\n        inMemoryInput = join.getRight();\n      } else if (join.getStreamingSide() == MapJoinStreamingRelation.RIGHT_RELATION) {\n        inMemoryInput = join.getLeft();\n      } else {\n        return null;\n      }\n      // If simple map join, the whole relation goes in memory\n      final RelMetadataQuery mq = join.getCluster().getMetadataQuery();\n      return mq.cumulativeMemoryWithinPhase(inMemoryInput);\n    }\n    @Override\n    public Boolean isPhaseTransition(HiveJoin join) {\n      return false;\n    }\n    @Override\n    public Integer getSplitCount(HiveJoin join) {\n      return HiveAlgorithmsUtil.getSplitCountWithoutRepartition(join);\n    }\n  }\n  /**\n   * BUCKET_JOIN is a hash joins where one bucket of the non streaming tables\n   * is kept in memory at the time.\n   */\n  public static class TezBucketJoinAlgorithm implements JoinAlgorithm {\n    public static final JoinAlgorithm INSTANCE = new TezBucketJoinAlgorithm();\n    private static final String ALGORITHM_NAME = \"BucketJoin\";\n    @Override\n    public String toString() {\n      return ALGORITHM_NAME;\n    }\n    @Override\n    public boolean isExecutable(HiveJoin join) {\n      final RelMetadataQuery mq = join.getCluster().getMetadataQuery();\n      final Double maxMemory = join.getCluster().getPlanner().getContext().\n              unwrap(HiveAlgorithmsConf.class).getMaxMemory();\n      // Check streaming side\n      RelNode smallInput = join.getStreamingInput();\n      if (smallInput == null) {\n        return false;\n      }\n      // Get key columns\n      JoinPredicateInfo joinPredInfo = join.getJoinPredicateInfo();\n      List<ImmutableIntList> joinKeysInChildren = new ArrayList<ImmutableIntList>();\n      joinKeysInChildren.add(\n              ImmutableIntList.copyOf(\n                      joinPredInfo.getProjsFromLeftPartOfJoinKeysInChildSchema()));\n      joinKeysInChildren.add(\n              ImmutableIntList.copyOf(\n                      joinPredInfo.getProjsFromRightPartOfJoinKeysInChildSchema()));\n      // Requirements: for Bucket, bucketed by their keys on both sides and fitting in memory\n      // Obtain number of buckets\n      //TODO: Incase of non bucketed splits would be computed based on data size/max part size\n      // What we need is a way to get buckets not splits\n      JoinAlgorithm oldAlgo = join.getJoinAlgorithm();\n      join.setJoinAlgorithm(TezBucketJoinAlgorithm.INSTANCE);\n      Integer buckets = mq.splitCount(smallInput);\n      join.setJoinAlgorithm(oldAlgo);\n      if (buckets == null) {\n        return false;\n      }\n      if (!HiveAlgorithmsUtil.isFittingIntoMemory(maxMemory, smallInput, buckets)) {\n        return false;\n      }\n      for (int i=0; i<join.getInputs().size(); i++) {\n        RelNode input = join.getInputs().get(i);\n        // Is bucketJoin possible? We need correct bucketing\n        RelDistribution distribution = mq.distribution(input);\n        if (distribution.getType() != Type.HASH_DISTRIBUTED) {\n          return false;\n        }\n        if (!distribution.getKeys().containsAll(joinKeysInChildren.get(i))) {\n          return false;\n        }\n      }\n      return true;\n    }\n<fim_suffix>    @Override\n    public RelOptCost getCost(HiveJoin join) {\n      final RelMetadataQuery mq = join.getCluster().getMetadataQuery();\n      // 1. Sum of input cardinalities\n      final Double leftRCount = mq.getRowCount(join.getLeft());\n      final Double rightRCount = mq.getRowCount(join.getRight());\n      if (leftRCount == null || rightRCount == null) {\n        return null;\n      }\n      final double rCount = leftRCount + rightRCount;\n      // 2. CPU cost = HashTable  construction  cost  +\n      //               join cost\n      ImmutableList<Double> cardinalities = new ImmutableList.Builder<Double>().\n              add(leftRCount).\n              add(rightRCount).\n              build();\n      ImmutableBitSet.Builder streamingBuilder = ImmutableBitSet.builder();\n      switch (join.getStreamingSide()) {\n        case LEFT_RELATION:\n          streamingBuilder.set(0);\n          break;\n        case RIGHT_RELATION:\n          streamingBuilder.set(1);\n          break;\n        default:\n          return null;\n      }\n      ImmutableBitSet streaming = streamingBuilder.build();\n      final double cpuCost = algoUtils.computeBucketMapJoinCPUCost(cardinalities, streaming);\n      // 3. IO cost = cost of transferring small tables to join node *\n      //              degree of parallelism\n      final Double leftRAverageSize = mq.getAverageRowSize(join.getLeft());\n      final Double rightRAverageSize = mq.getAverageRowSize(join.getRight());\n      if (leftRAverageSize == null || rightRAverageSize == null) {\n        return null;\n      }\n      ImmutableList<Pair<Double,Double>> relationInfos = new ImmutableList.Builder<Pair<Double,Double>>().\n              add(new Pair<Double,Double>(leftRCount,leftRAverageSize)).\n              add(new Pair<Double,Double>(rightRCount,rightRAverageSize)).\n              build();\n      //TODO: No Of buckets is not same as no of splits\n      JoinAlgorithm oldAlgo = join.getJoinAlgorithm();\n      join.setJoinAlgorithm(TezBucketJoinAlgorithm.INSTANCE);\n      final int parallelism = mq.splitCount(join) == null\n              ? 1 : mq.splitCount(join);\n      join.setJoinAlgorithm(oldAlgo);\n      final double ioCost = algoUtils.computeBucketMapJoinIOCost(relationInfos, streaming, parallelism);\n      // 4. Result\n      return HiveCost.FACTORY.makeCost(rCount, cpuCost, ioCost);\n    }<fim_middle>// function below is long method and feature envy\n"}