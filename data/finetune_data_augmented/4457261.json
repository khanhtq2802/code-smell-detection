{"text": "<fim_prefix>/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage org.apache.drill.exec.planner.physical;\n\nimport java.io.IOException;\nimport java.util.Collections;\nimport java.util.Iterator;\nimport java.util.List;\n\nimport org.apache.calcite.plan.RelOptCluster;\nimport org.apache.calcite.plan.RelOptCost;\nimport org.apache.calcite.plan.RelOptPlanner;\nimport org.apache.calcite.plan.RelTraitSet;\nimport org.apache.calcite.rel.AbstractRelNode;\nimport org.apache.calcite.rel.RelNode;\nimport org.apache.calcite.rel.RelWriter;\nimport org.apache.calcite.rel.metadata.RelMetadataQuery;\nimport org.apache.calcite.rel.type.RelDataType;\nimport org.apache.drill.common.exceptions.DrillRuntimeException;\nimport org.apache.drill.common.exceptions.ExecutionSetupException;\nimport org.apache.drill.exec.physical.base.GroupScan;\nimport org.apache.drill.exec.physical.base.PhysicalOperator;\nimport org.apache.drill.exec.physical.base.ScanStats;\nimport org.apache.drill.exec.planner.fragment.DistributionAffinity;\nimport org.apache.drill.exec.planner.physical.visitor.PrelVisitor;\nimport org.apache.drill.exec.record.BatchSchema;\n\nimport org.apache.drill.exec.planner.cost.DrillCostBase.DrillCostFactory;\n\npublic class DirectScanPrel extends AbstractRelNode implements Prel, HasDistributionAffinity {\n  static final org.slf4j.Logger logger = org.slf4j.LoggerFactory.getLogger(DirectScanPrel.class);\n\n  private final GroupScan groupScan;\n  private final RelDataType rowType;\n\n<fim_suffix>  DirectScanPrel(RelOptCluster cluster, RelTraitSet traits,\n                 GroupScan groupScan, RelDataType rowType) {\n    super(cluster, traits);\n    this.groupScan = groupScan;\n    this.rowType = rowType;\n  }\n\n  @Override\n  public RelNode copy(RelTraitSet traitSet, List<RelNode> inputs) {\n    return new DirectScanPrel(this.getCluster(), traitSet, this.getGroupScan(),\n            this.rowType);\n  }\n\n  @Override\n  protected Object clone() throws CloneNotSupportedException {\n    return new DirectScanPrel(this.getCluster(), this.getTraitSet(), getCopy(this.getGroupScan()),\n            this.rowType);\n  }\n\n  private static GroupScan getCopy(GroupScan scan){\n    try {\n      return (GroupScan) scan.getNewWithChildren((List<PhysicalOperator>) (Object) Collections.emptyList());\n    } catch (ExecutionSetupException e) {\n      throw new DrillRuntimeException(\"Unexpected failure while coping node.\", e);\n    }\n  }\n\n  @Override\n  public PhysicalOperator getPhysicalOperator(PhysicalPlanCreator creator)\n          throws IOException {\n    return creator.addMetadata(this, this.getGroupScan());\n  }\n\n  public GroupScan getGroupScan() {\n    return groupScan;\n  }\n\n  @Override\n  public boolean needsFinalColumnReordering() {\n    return false;\n  }\n\n  @Override\n  public BatchSchema.SelectionVectorMode[] getSupportedEncodings() {\n    return BatchSchema.SelectionVectorMode.DEFAULT;\n  }\n\n  @Override\n  public DistributionAffinity getDistributionAffinity() {\n    return this.getGroupScan().getDistributionAffinity();\n  }\n\n  @Override\n  public BatchSchema.SelectionVectorMode getEncoding() {\n    return BatchSchema.SelectionVectorMode.NONE;\n  }\n\n  @Override\n  public <T, X, E extends Throwable> T accept(PrelVisitor<T, X, E> logicalVisitor, X value) throws E {\n    return logicalVisitor.visitPrel(this, value);\n  }\n\n  @Override\n  public Iterator<Prel> iterator() {\n    return Collections.emptyIterator();\n  }\n\n  public static DirectScanPrel create(RelNode old, RelTraitSet traitSets,\n      GroupScan scan, RelDataType rowType) {\n    return new DirectScanPrel(old.getCluster(), traitSets,\n        getCopy(scan), rowType);\n  }\n\n  @Override\n  public RelDataType deriveRowType() {\n    return this.rowType;\n  }\n\n  @Override\n  public RelWriter explainTerms(RelWriter pw) {\n    return super.explainTerms(pw).item(\"groupscan\", this.getGroupScan().getDigest());\n  }\n\n  @Override\n  public double estimateRowCount(RelMetadataQuery mq) {\n    final PlannerSettings settings = PrelUtil.getPlannerSettings(getCluster());\n\n    double rowCount = this.getGroupScan().getScanStats(settings).getRecordCount();\n    logger.debug(\"#{}.estimateRowCount get rowCount {} from  groupscan {}\",\n            this.getId(), rowCount, System.identityHashCode(this.getGroupScan()));\n    return rowCount;\n  }\n\n  @Override\n  public RelOptCost computeSelfCost(final RelOptPlanner planner, RelMetadataQuery mq) {\n    final PlannerSettings settings = PrelUtil.getPlannerSettings(planner);\n    final ScanStats stats = this.getGroupScan().getScanStats(settings);\n    final int columnCount = this.getRowType().getFieldCount();\n\n    if(PrelUtil.getSettings(getCluster()).useDefaultCosting()) {\n      return planner.getCostFactory().makeCost(stats.getRecordCount() * columnCount, stats.getCpuCost(), stats.getDiskCost());\n    }\n\n    double rowCount = stats.getRecordCount();\n\n    // As DRILL-4083 points out, when columnCount == 0, cpuCost becomes zero,\n    // which makes the costs of HiveScan and HiveDrillNativeParquetScan the same\n    // For now, assume cpu cost is proportional to row count.\n    double cpuCost = rowCount * Math.max(columnCount, 1);\n\n    // If a positive value for CPU cost is given multiply the default CPU cost by given CPU cost.\n    if (stats.getCpuCost() > 0) {\n      cpuCost *= stats.getCpuCost();\n    }\n\n    // Even though scan is reading from disk, in the currently generated plans all plans will\n    // need to read the same amount of data, so keeping the disk io cost 0 is ok for now.\n    // In the future we might consider alternative scans that go against projections or\n    // different compression schemes etc that affect the amount of data read. Such alternatives\n    // would affect both cpu and io cost.\n    //double ioCost = 0;\n    double ioCost = stats.getDiskCost();\n    DrillCostFactory costFactory = (DrillCostFactory)planner.getCostFactory();\n    return costFactory.makeCost(rowCount, cpuCost, ioCost, 0);\n  }\n\n}<fim_middle>// function below has no smell\n"}