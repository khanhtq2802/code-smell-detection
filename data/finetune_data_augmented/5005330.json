{"text": "<fim_prefix>/*\n * Licensed to the Apache Software Foundation (ASF) under one or more\n * contributor license agreements. See the NOTICE file distributed with this\n * work for additional information regarding copyright ownership. The ASF\n * licenses this file to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n * License for the specific language governing permissions and limitations under\n * the License.\n */\n\npackage org.apache.knox.examples;\n\nimport java.io.IOException;\nimport java.util.StringTokenizer;\n\nimport org.apache.hadoop.conf.Configuration;\nimport org.apache.hadoop.fs.Path;\nimport org.apache.hadoop.io.IntWritable;\nimport org.apache.hadoop.io.Text;\nimport org.apache.hadoop.mapreduce.Job;\nimport org.apache.hadoop.mapreduce.Mapper;\nimport org.apache.hadoop.mapreduce.Reducer;\nimport org.apache.hadoop.mapreduce.lib.input.FileInputFormat;\nimport org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;\nimport org.apache.hadoop.util.GenericOptionsParser;\n\npublic class WordCount {\n\n  public static class TokenizerMapper\n      extends Mapper<Object, Text, Text, IntWritable>{\n\n    private static final IntWritable one = new IntWritable(1);\n    private Text word = new Text();\n\n    @Override\n    public void map(Object key, Text value, Context context\n    ) throws IOException, InterruptedException {\n      StringTokenizer itr = new StringTokenizer(value.toString());\n      while (itr.hasMoreTokens()) {\n        word.set(itr.nextToken());\n        context.write(word, one);\n      }\n    }\n  }\n\n  public static class IntSumReducer\n      extends Reducer<Text,IntWritable,Text,IntWritable> {\n    private IntWritable result = new IntWritable();\n\n    @Override\n    public void reduce(Text key, Iterable<IntWritable> values,\n                       Context context\n    ) throws IOException, InterruptedException {\n      int sum = 0;\n      for (IntWritable val : values) {\n        sum += val.get();\n      }\n      result.set(sum);\n      context.write(key, result);\n    }\n  }\n\n<fim_suffix>  public static void main(String[] args) throws Exception {\n    Configuration conf = new Configuration();\n    String[] otherArgs = new GenericOptionsParser(conf, args).getRemainingArgs();\n    if (otherArgs.length != 2) {\n      System.err.println( \"Usage: wordcount <in> <out>\" );\n      System.exit(2);\n    }\n    Job job = Job.getInstance(conf, \"Word Count\");\n    job.setJarByClass(WordCount.class);\n    job.setMapperClass(TokenizerMapper.class);\n    job.setCombinerClass(IntSumReducer.class);\n    job.setReducerClass(IntSumReducer.class);\n    job.setOutputKeyClass(Text.class);\n    job.setOutputValueClass(IntWritable.class);\n    FileInputFormat.addInputPath(job, new Path(otherArgs[0]));\n    FileOutputFormat.setOutputPath(job, new Path(otherArgs[1]));\n    System.exit(job.waitForCompletion(true) ? 0 : 1);\n  }\n}<fim_middle>// function below has no smell\n"}