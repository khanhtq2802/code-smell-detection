{"text": "<fim_prefix> * <li>fields - The fields to highlight.  If not specified all fields will be highlighted (or at least attempted)</li>\n * </ul>\n * Example:\n * <pre>\"SearchHlgtSameRdr\" SearchTravRetHighlight(type[UH],maxFrags[3],fields[body]) &gt; : 1000\n * </pre>\n *\n * Documents must be stored in order for this task to work.  Additionally, term vector positions can be used as well,\n * and offsets in postings is another option.\n *\n * <p>Other side effects: counts additional 1 (record) for each traversed hit,\n * and 1 more for each retrieved (non null) document and 1 for each fragment returned.</p>\n */\npublic class SearchTravRetHighlightTask extends SearchTravTask {\n  private int maxDocCharsToAnalyze; // max leading content chars to highlight\n  private int maxFrags = 1; // aka passages\n  private Set<String> hlFields = Collections.singleton(\"body\");\n  private String type;\n  private HLImpl hlImpl;\n  private Analyzer analyzer;\n  public SearchTravRetHighlightTask(PerfRunData runData) {\n    super(runData);\n  }\n  @Override\n  public void setParams(String params) {\n    // can't call super because super doesn't understand our params syntax\n    this.params = params;\n    // TODO consider instead using data.getConfig().get(\"highlighter.*\")?\n    String[] splits = params.split(\",\");\n    for (String split : splits) {\n      if (split.startsWith(\"type[\") == true) {\n        type = split.substring(\"type[\".length(), split.length() - 1);\n      } else if (split.startsWith(\"maxFrags[\") == true) {\n        maxFrags = (int) Float.parseFloat(split.substring(\"maxFrags[\".length(), split.length() - 1));\n      } else if (split.startsWith(\"fields[\") == true) {\n        String fieldNames = split.substring(\"fields[\".length(), split.length() - 1);\n        String[] fieldSplits = fieldNames.split(\";\");\n        hlFields = new HashSet<>(Arrays.asList(fieldSplits));\n      }\n    }\n  }\n  @Override\n  public void setup() throws Exception {\n    super.setup();\n    //check to make sure either the doc is being stored\n    PerfRunData data = getRunData();\n    if (data.getConfig().get(\"doc.stored\", false) == false){\n      throw new Exception(\"doc.stored must be set to true\");\n    }\n    maxDocCharsToAnalyze = data.getConfig().get(\"highlighter.maxDocCharsToAnalyze\", Highlighter.DEFAULT_MAX_CHARS_TO_ANALYZE);\n    analyzer = data.getAnalyzer();\n    String type = this.type;\n    if (type == null) {\n      type = data.getConfig().get(\"highlighter\", null);\n    }\n    switch (type) {\n      case \"NONE\": hlImpl = new NoHLImpl(); break;\n      case \"SH_A\": hlImpl = new StandardHLImpl(false); break;\n      case \"SH_V\": hlImpl = new StandardHLImpl(true); break;\n      case \"FVH_V\": hlImpl = new FastVectorHLImpl(); break;\n      case \"UH\": hlImpl = new UnifiedHLImpl(null); break;\n      case \"UH_A\": hlImpl = new UnifiedHLImpl(UnifiedHighlighter.OffsetSource.ANALYSIS); break;\n      case \"UH_V\": hlImpl = new UnifiedHLImpl(UnifiedHighlighter.OffsetSource.TERM_VECTORS); break;\n      case \"UH_P\": hlImpl = new UnifiedHLImpl(UnifiedHighlighter.OffsetSource.POSTINGS); break;\n      case \"UH_PV\": hlImpl = new UnifiedHLImpl(UnifiedHighlighter.OffsetSource.POSTINGS_WITH_TERM_VECTORS); break;\n      default: throw new Exception(\"unrecognized highlighter type: \" + type + \" (try 'UH')\");\n    }\n  }\n  // here is where we intercept ReadTask's logic to do the highlighting, and nothing else (no retrieval of all field vals)\n  @Override\n  protected int withTopDocs(IndexSearcher searcher, Query q, TopDocs hits) throws Exception {\n    hlImpl.withTopDocs(searcher, q, hits);\n    // note: it'd be nice if we knew the sum kilobytes of text across these hits so we could return that. It'd be a more\n    //  useful number to gauge the amount of work. But given \"average\" document sizes and lots of queries, returning the\n    //  number of docs is reasonable.\n    return hits.scoreDocs.length; // always return # scored docs.\n  }\n  private interface HLImpl {\n    void withTopDocs(IndexSearcher searcher, Query q, TopDocs hits) throws Exception;\n  }\n  private volatile int preventOptimizeAway = 0;\n  private class StandardHLImpl implements HLImpl {\n    SimpleHTMLFormatter formatter = new SimpleHTMLFormatter(\"<em>\", \"</em>\");\n    DefaultEncoder encoder = new DefaultEncoder();\n    Highlighter highlighter = new Highlighter(formatter, encoder, null);\n    boolean termVecs;\n    StandardHLImpl(boolean termVecs) {\n      highlighter.setEncoder(new DefaultEncoder());\n      highlighter.setMaxDocCharsToAnalyze(maxDocCharsToAnalyze);\n      this.termVecs = termVecs;\n    }\n    @Override\n    public void withTopDocs(IndexSearcher searcher, Query q, TopDocs hits) throws Exception {\n      IndexReader reader = searcher.getIndexReader();\n      highlighter.setFragmentScorer(new QueryScorer(q));\n      // highlighter.setTextFragmenter();  unfortunately no sentence mechanism, not even regex. Default here is trivial\n      for (ScoreDoc scoreDoc : docIdOrder(hits.scoreDocs)) {\n        Document document = reader.document(scoreDoc.doc, hlFields);\n        Fields tvFields = termVecs ? reader.getTermVectors(scoreDoc.doc) : null;\n        for (IndexableField indexableField : document) {\n          TokenStream tokenStream;\n          if (termVecs) {\n            tokenStream = TokenSources.getTokenStream(indexableField.name(), tvFields,\n                indexableField.stringValue(), analyzer, maxDocCharsToAnalyze);\n          } else {\n            tokenStream = analyzer.tokenStream(indexableField.name(), indexableField.stringValue());\n          }\n          // will close TokenStream:\n          String[] fragments = highlighter.getBestFragments(tokenStream, indexableField.stringValue(), maxFrags);\n          preventOptimizeAway = fragments.length;\n        }\n      }\n    }\n  }\n  private class FastVectorHLImpl implements HLImpl {\n    int fragSize = 100;\n    WeightedFragListBuilder fragListBuilder = new WeightedFragListBuilder();\n    BoundaryScanner bs = new BreakIteratorBoundaryScanner(BreakIterator.getSentenceInstance(Locale.ENGLISH));\n    ScoreOrderFragmentsBuilder fragmentsBuilder = new ScoreOrderFragmentsBuilder(bs);\n    String[] preTags = {\"<em>\"};\n    String[] postTags = {\"</em>\"};\n    Encoder encoder = new DefaultEncoder();// new SimpleHTMLEncoder();\n    FastVectorHighlighter highlighter = new FastVectorHighlighter(\n        true,   // phraseHighlight\n        false); // requireFieldMatch -- not pertinent to our benchmark\n    @Override\n    public void withTopDocs(IndexSearcher searcher, Query q, TopDocs hits) throws Exception {\n      IndexReader reader = searcher.getIndexReader();\n      final FieldQuery fq = highlighter.getFieldQuery( q, reader);\n      for (ScoreDoc scoreDoc : docIdOrder(hits.scoreDocs)) {\n        for (String hlField : hlFields) {\n          String[] fragments = highlighter.getBestFragments(fq, reader, scoreDoc.doc, hlField, fragSize, maxFrags,\n              fragListBuilder, fragmentsBuilder, preTags, postTags, encoder);\n          preventOptimizeAway = fragments.length;\n        }\n      }\n    }\n  }\n  private ScoreDoc[] docIdOrder(ScoreDoc[] scoreDocs) {\n    ScoreDoc[] clone = new ScoreDoc[scoreDocs.length];\n    System.arraycopy(scoreDocs, 0, clone, 0, scoreDocs.length);\n    ArrayUtil.introSort(clone, (a, b) -> Integer.compare(a.doc, b.doc));\n    return clone;\n  }\n  private class UnifiedHLImpl implements HLImpl {\n    UnifiedHighlighter highlighter;\n    IndexSearcher lastSearcher;\n    UnifiedHighlighter.OffsetSource offsetSource; // null means auto select\n    String[] fields = hlFields.toArray(new String[hlFields.size()]);\n    int[] maxPassages;\n<fim_suffix>    UnifiedHLImpl(final UnifiedHighlighter.OffsetSource offsetSource) {\n      this.offsetSource = offsetSource;\n      maxPassages = new int[hlFields.size()];\n      Arrays.fill(maxPassages, maxFrags);\n    }<fim_middle>// function below has no smell\n"}