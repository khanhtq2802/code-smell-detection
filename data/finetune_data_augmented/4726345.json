{"text": "<fim_prefix>\n<fim_suffix>public class PlumbingStreams {\n    /**\n     * Insert a blocking delay between tuples.\n     * Returned stream is the input stream delayed by {@code delay}.\n     * <p>\n     * Delays less than 1msec are translated to a 0 delay.\n     * <p>\n     * This function always adds the {@code delay} amount after receiving\n     * a tuple before forwarding it.  \n     * <p>\n     * Downstream tuple processing delays will affect\n     * the overall delay of a subsequent tuple.\n     * <p>\n     * e.g., the input stream contains two tuples t1 and t2 and\n     * the delay is 100ms.  The forwarding of t1 is delayed by 100ms.\n     * Then if a downstream processing delay of 80ms occurs, this function\n     * receives t2 80ms after it forwarded t1 and it will delay another\n     * 100ms before forwarding t2.  Hence the overall delay between forwarding\n     * t1 and t2 is 180ms.\n     * See {@link #blockingThrottle(long, TimeUnit) blockingThrottle}.\n     *\n     * @param <T> Tuple type\n     * @param stream Stream t\n     * @param delay Amount of time to delay a tuple.\n     * @param unit Time unit for {@code delay}.\n     * \n     * @return Stream that will be delayed.\n     */\n    public static <T> TStream<T> blockingDelay(TStream<T> stream, long delay, TimeUnit unit) {\n        return stream.map(t -> {try {\n            Thread.sleep(unit.toMillis(delay));\n        } catch (InterruptedException e) {\n            Thread.currentThread().interrupt();\n            throw new RuntimeException(e);\n        } return t;}) ;\n    }\n    /**\n     * Maintain a constant blocking delay between tuples.\n     * The returned stream is the input stream throttled by {@code delay}.\n     * <p>\n     * Delays less than 1msec are translated to a 0 delay.\n     * <p>\n     * Sample use:\n     * <pre>{@code\n     * TStream<String> stream = topology.strings(\"a\", \"b, \"c\");\n     * // Create a stream with tuples throttled to 1 second intervals.\n     * TStream<String> throttledStream = blockingThrottle(stream, 1, TimeUnit.SECOND);\n     * // print out the throttled tuples as they arrive\n     * throttledStream.peek(t -> System.out.println(new Date() + \" - \" + t));\n     * }</pre>\n     * <p>\n     * The function adjusts for downstream processing delays.\n     * The first tuple is not delayed.  If {@code delay} has already\n     * elapsed since the prior tuple was forwarded, the tuple \n     * is forwarded immediately.\n     * Otherwise, forwarding the tuple is delayed to achieve\n     * a {@code delay} amount since forwarding the prior tuple.\n     * <p>\n     * e.g., the input stream contains two tuples t1 and t2 and\n     * the delay is 100ms.  The forwarding of t1 is delayed by 100ms.\n     * Then if a downstream processing delay of 80ms occurs, this function\n     * receives t2 80ms after it forwarded t1 and it will only delay another\n     * 20ms (100ms - 80ms) before forwarding t2.  \n     * Hence the overall delay between forwarding t1 and t2 remains 100ms.\n     * \n     * @param <T> tuple type\n     * @param stream the stream to throttle\n     * @param delay Amount of time to delay a tuple.\n     * @param unit Time unit for {@code delay}.\n     * @return the throttled stream\n     */\n    public static <T> TStream<T> blockingThrottle(TStream<T> stream, long delay, TimeUnit unit) {\n        return stream.map( blockingThrottle(delay, unit) );\n    }\n    private static <T> Function<T,T> blockingThrottle(long delay, TimeUnit unit) {\n        long[] nextTupleTime = { 0 };\n        return t -> {\n            long now = System.currentTimeMillis();\n            if (nextTupleTime[0] != 0) {\n                if (now < nextTupleTime[0]) {\n                    try {\n                        Thread.sleep(nextTupleTime[0] - now);\n                    } catch (InterruptedException e) {\n                        Thread.currentThread().interrupt();\n                        throw new RuntimeException(e);\n                    }\n                    now = System.currentTimeMillis();\n                }\n            }\n            nextTupleTime[0] = now + unit.toMillis(delay);\n            return t;\n        };\n    }\n    /**\n     * Insert a blocking delay before forwarding the first tuple and\n     * no delay for subsequent tuples.\n     * <p>\n     * Delays less than 1msec are translated to a 0 delay.\n     * <p>\n     * Sample use:\n     * <pre>{@code\n     * TStream<String> stream = topology.strings(\"a\", \"b, \"c\");\n     * // create a stream where the first tuple is delayed by 5 seconds. \n     * TStream<String> oneShotDelayedStream =\n     *      stream.map( blockingOneShotDelay(5, TimeUnit.SECONDS) );\n     * }</pre>\n     * \n     * @param <T> tuple type\n     * @param stream input stream\n     * @param delay Amount of time to delay a tuple.\n     * @param unit Time unit for {@code delay}.\n     * @return the delayed stream\n     */\n    public static <T> TStream<T> blockingOneShotDelay(TStream<T> stream, long delay, TimeUnit unit) {\n        return stream.map( blockingOneShotDelay(delay, unit) );\n    }\n    private static <T> Function<T,T> blockingOneShotDelay(long delay, TimeUnit unit) {\n        long[] initialDelay = { unit.toMillis(delay) };\n        return t -> {\n            if (initialDelay[0] != -1) {\n                try {\n                    Thread.sleep(initialDelay[0]);\n                } catch (InterruptedException e) {\n                    Thread.currentThread().interrupt();\n                    throw new RuntimeException(e);\n                }\n                initialDelay[0] = -1;\n            }\n            return t;\n            };\n    }\n    /**\n     * Relieve pressure on upstream processing by discarding tuples.\n     * This method ensures that upstream processing is not\n     * constrained by any delay in downstream processing,\n     * for example by a connector not being able to connect\n     * to its external system.\n     * <P>\n     * Any downstream processing of the returned stream is isolated\n     * from {@code stream} so that any slow down does not affect {@code stream}.\n     * When the downstream processing cannot keep up with rate of\n     * {@code stream} tuples will be dropped from returned stream.\n     * <BR>\n     * Up to {@code count} of the most recent tuples per key from {@code stream}\n     * are maintained when downstream processing is slow, any older tuples\n     * that have not been submitted to the returned stream will be discarded.\n     * <BR>\n     * Tuple order is maintained within a partition but is not guaranteed to\n     * be maintained across partitions.\n     * </P>\n     * \n     * @param stream Stream to be isolated from downstream processing.\n     * @param keyFunction Function defining the key of each tuple.\n     * @param count Maximum number of tuples to maintain when downstream processing is backing up.\n     * @return Stream that is isolated from and thus relieves pressure on {@code stream}.\n     * \n     * @param <T> Tuple type.\n     * @param <K> Key type.\n     * @see #isolate(TStream, int) isolate\n     */\n    public static <T,K> TStream<T> pressureReliever(TStream<T> stream, Function<T,K> keyFunction, int count) {\n        return stream.pipe(new PressureReliever<>(count, keyFunction));\n    }\n    /**\n     * Isolate upstream processing from downstream processing.\n     * <BR>\n     * Implementations may throw {@code OutOfMemoryExceptions} \n     * if the processing against returned stream cannot keep up\n     * with the arrival rate of tuples on {@code stream}.\n     *\n     * @param <T> Tuple type\n     * @param stream Stream to be isolated from downstream processing.\n     * @param ordered {@code true} to maintain arrival order on the returned stream,\n     * {@code false} to not guaranteed arrival order.\n     * @return Stream that is isolated from {@code stream}.\n     */\n    public static <T> TStream<T> isolate(TStream<T> stream, boolean ordered) {\n        return stream.pipe(\n                ordered ? new Isolate<T>() : new UnorderedIsolate<T>());\n    }\n    /**\n     * Isolate upstream processing from downstream processing.\n     * <P>\n     * If the processing against the returned stream cannot keep up\n     * with the arrival rate of tuples on {@code stream}, upstream\n     * processing will block until there is space in the queue between\n     * the streams.\n     * </P><P>\n     * Processing of tuples occurs in the order they were received.\n     * </P>\n     * \n     * @param <T> Tuple type\n     * @param stream Stream to be isolated from downstream processing.\n     * @param queueCapacity size of the queue between {@code stream} and\n     *        the returned stream.<fim_middle>// class below has no smell\n"}