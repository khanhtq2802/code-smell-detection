{"text": "<fim_prefix>/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage org.apache.pig.data;\nimport java.io.BufferedInputStream;\nimport java.io.DataInputStream;\nimport java.io.DataOutputStream;\nimport java.io.EOFException;\nimport java.io.FileInputStream;\nimport java.io.FileNotFoundException;\nimport java.io.IOException;\nimport java.util.ArrayList;\nimport java.util.Iterator;\nimport java.util.List;\nimport org.apache.commons.logging.Log;\nimport org.apache.commons.logging.LogFactory;\nimport org.apache.pig.PigCounters;\nimport org.apache.pig.PigWarning;\n/**\n * An unordered collection of Tuples (possibly) with multiples.  The tuples\n * are stored in a List, since there is no concern for order or\n * distinctness.\n */\npublic class DefaultDataBag extends DefaultAbstractBag {\n    /**\n     *\n     */\n    private static final long serialVersionUID = 2L;\n    private static final Log log = LogFactory.getLog(DefaultDataBag.class);\n    private static final InterSedes SEDES = InterSedesFactory.getInterSedesInstance();\n    public DefaultDataBag() {\n        mContents = new ArrayList<Tuple>();\n    }\n    /**\n     * This constructor creates a bag out of an existing list\n     * of tuples by taking ownership of the list and NOT\n     * copying the contents of the list.\n     * @param listOfTuples List<Tuple> containing the tuples\n     */\n    public DefaultDataBag(List<Tuple> listOfTuples) {\n        mContents = listOfTuples;\n        mSize = listOfTuples.size();\n        markSpillableIfNecessary();\n    }\n    @Override\n    public boolean isSorted() {\n        return false;\n    }\n    @Override\n    public boolean isDistinct() {\n        return false;\n    }\n    @Override\n    public Iterator<Tuple> iterator() {\n        return new DefaultDataBagIterator();\n    }\n<fim_suffix>    @Override\n    public long spill() {\n        // Make sure we have something to spill.  Don't create empty\n        // files, as that will make a mess.\n        if (mContents.size() == 0) return 0;\n        // Lock the container before I spill, so that iterators aren't\n        // trying to read while I'm mucking with the container.\n        long spilled = 0;\n        synchronized (mContents) {\n            DataOutputStream out = null;\n            try {\n                out = getSpillFile();\n            }  catch (IOException ioe) {\n                // Do not remove last file from spilled array. It was not\n                // added as File.createTmpFile threw an IOException\n                warn(\n                    \"Unable to create tmp file to spill to disk\", PigWarning.UNABLE_TO_CREATE_FILE_TO_SPILL, ioe);\n                return 0;\n            }\n            try {\n                Iterator<Tuple> i = mContents.iterator();\n                while (i.hasNext()) {\n                    SEDES.writeDatum(out, i.next(), DataType.TUPLE);\n                    spilled++;\n                    // This will spill every 16383 records.\n                    if ((spilled & 0x3fff) == 0) reportProgress();\n                }\n                out.flush();\n                out.close();\n                out = null;\n                mContents.clear();\n            } catch (Throwable e) {\n                // Remove the last file from the spilled array, since we failed to\n                // write to it.\n                mSpillFiles.remove(mSpillFiles.size() - 1);\n                warn(\n                    \"Unable to spill contents to disk\", PigWarning.UNABLE_TO_SPILL, e);\n                return 0;\n            } finally {\n                if (out != null) {\n                    try {\n                        out.close();\n                    } catch (IOException e) {\n                        warn(\"Error closing spill\", PigWarning.UNABLE_TO_CLOSE_SPILL_FILE, e);\n                    }\n                }\n            }\n        }\n        // Increment the spill count\n        incSpillCount(PigCounters.SPILLABLE_MEMORY_MANAGER_SPILL_COUNT);\n        return spilled;\n    }\n    /**\n     * An iterator that handles getting the next tuple from the bag.  This\n     * iterator has a couple of issues to deal with.  First, data can be\n     * stored in a combination of in memory and on disk.  Second, the bag\n     * may be asked to spill while the iterator is reading it.  This means\n     * that it will be pointing to someplace in memory and suddenly it\n     * will need to switch to a disk file.\n     */\n    private class DefaultDataBagIterator implements Iterator<Tuple> {\n        // We have to buffer a tuple because there's no easy way for next\n        // to tell whether or not there's another tuple available, other\n        // than to read it.\n        private Tuple mBuf = null;\n        private int mMemoryPtr = 0;\n        private int mFilePtr = 0;\n        private DataInputStream mIn = null;\n        private int mCntr = 0;\n        private boolean hasCachedTuple = false;\n        DefaultDataBagIterator() {\n        }\n        @Override\n        public boolean hasNext() {\n            // Once we call hasNext(), set the flag, so we can call hasNext() repeated without fetching next tuple\n            if (hasCachedTuple)\n                return (mBuf != null);\n            mBuf = next();\n            hasCachedTuple = true;\n            return (mBuf != null);\n        }\n        @Override\n        public Tuple next() {\n            // This will report progress every 1024 times through next.\n            // This should be much faster than using mod.\n            if ((mCntr++ & 0x3ff) == 0) reportProgress();\n            // If there's one in the buffer, use that one.\n            if (hasCachedTuple) {\n                Tuple t = mBuf;\n                hasCachedTuple = false;\n                return t;\n            }\n            // See if we've been reading from memory or not.\n            if (mMemoryPtr > 0) {\n                // If there's still data in memory, keep reading from\n                // there.\n                // Lock before we check the size, obtain a reader lock,\n                // from this point forward we can't have them spilling on\n                // us.\n                synchronized (mContents) {\n                    if (mContents.size() > 0) {\n                        return readFromMemory();\n                    }\n                }\n                // The container spilled since our last read.  Don't\n                // need to the hold the lock now, as it's already\n                // spilled on us.\n                // Our file pointer will already point to the new\n                // spill file (because it was either already 0 or had\n                // been incremented past the end of the old\n                // mSpillFiles.size()).  We need to open the new file\n                // and then fast forward past all of the tuples we've\n                // already read.  Then we need to reset mMemoryPtr so\n                // we know to read from the file next time we come\n                // through.\n                try {\n                    mIn = new DataInputStream(new BufferedInputStream(\n                        new FileInputStream(mSpillFiles.get(mFilePtr++))));\n                } catch (FileNotFoundException fnfe) {\n                    // We can't find our own spill file?  That should never\n                    // happen.\n                    String msg = \"Unable to find our spill file.\";\n                    log.fatal(msg, fnfe);\n                    throw new RuntimeException(msg, fnfe);\n                }\n                for (int i = 0; i < mMemoryPtr; i++) {\n                    try {\n                        SEDES.readDatum(mIn);\n                    } catch (EOFException eof) {\n                        // This should never happen, it means we\n                        // didn't dump all of our tuples to disk.\n                        String msg = \"Ran out of tuples to read prematurely.\";\n                        log.fatal(msg, eof);\n                        throw new RuntimeException(msg, eof);\n                    } catch (IOException ioe) {\n                        String msg = \"Unable to read our spill file.\";\n                        log.fatal(msg, ioe);\n                        throw new RuntimeException(msg, ioe);\n                    }\n                }\n                mMemoryPtr = 0;\n                return readFromFile();\n            }\n            // We haven't read from memory yet, so keep trying to read\n            // from the file\n            return readFromFile();\n        }\n        /**\n         * Not implemented.\n         */\n        @Override\n        public void remove() {}\n        private Tuple readFromFile() {\n            if (mIn != null) {\n                // We already have a file open\n                Tuple t;\n                try {<fim_middle>// function below has no smell\n"}