{"text": "<fim_prefix>import static org.apache.hadoop.hdfs.DFSConfigKeys.DFS_DATANODE_DISK_CHECK_TIMEOUT_DEFAULT;\nimport static org.apache.hadoop.hdfs.DFSConfigKeys.DFS_DATANODE_DISK_CHECK_TIMEOUT_KEY;\nimport static org.apache.hadoop.hdfs.DFSConfigKeys.DFS_DATANODE_FAILED_VOLUMES_TOLERATED_DEFAULT;\nimport static org.apache.hadoop.hdfs.DFSConfigKeys.DFS_DATANODE_FAILED_VOLUMES_TOLERATED_KEY;\n/**\n * A class that encapsulates running disk checks against each HDDS volume and\n * allows retrieving a list of failed volumes.\n */\npublic class HddsVolumeChecker {\n  public static final Logger LOG =\n      LoggerFactory.getLogger(HddsVolumeChecker.class);\n  private AsyncChecker<Boolean, VolumeCheckResult> delegateChecker;\n  private final AtomicLong numVolumeChecks = new AtomicLong(0);\n  private final AtomicLong numAllVolumeChecks = new AtomicLong(0);\n  private final AtomicLong numSkippedChecks = new AtomicLong(0);\n  /**\n   * Max allowed time for a disk check in milliseconds. If the check\n   * doesn't complete within this time we declare the disk as dead.\n   */\n  private final long maxAllowedTimeForCheckMs;\n  /**\n   * Minimum time between two successive disk checks of a volume.\n   */\n  private final long minDiskCheckGapMs;\n  /**\n   * Timestamp of the last check of all volumes.\n   */\n  private long lastAllVolumesCheck;\n  private final Timer timer;\n  private final ExecutorService checkVolumeResultHandlerExecutorService;\n  /**\n   * @param conf Configuration object.\n   * @param timer {@link Timer} object used for throttling checks.\n   */\n  public HddsVolumeChecker(Configuration conf, Timer timer)\n      throws DiskErrorException {\n    maxAllowedTimeForCheckMs = conf.getTimeDuration(\n        DFS_DATANODE_DISK_CHECK_TIMEOUT_KEY,\n        DFS_DATANODE_DISK_CHECK_TIMEOUT_DEFAULT,\n        TimeUnit.MILLISECONDS);\n    if (maxAllowedTimeForCheckMs <= 0) {\n      throw new DiskErrorException(\"Invalid value configured for \"\n          + DFS_DATANODE_DISK_CHECK_TIMEOUT_KEY + \" - \"\n          + maxAllowedTimeForCheckMs + \" (should be > 0)\");\n    }\n    this.timer = timer;\n    /**\n     * Maximum number of volume failures that can be tolerated without\n     * declaring a fatal error.\n     */\n    int maxVolumeFailuresTolerated = conf.getInt(\n        DFS_DATANODE_FAILED_VOLUMES_TOLERATED_KEY,\n        DFS_DATANODE_FAILED_VOLUMES_TOLERATED_DEFAULT);\n    minDiskCheckGapMs = conf.getTimeDuration(\n        DFSConfigKeys.DFS_DATANODE_DISK_CHECK_MIN_GAP_KEY,\n        DFSConfigKeys.DFS_DATANODE_DISK_CHECK_MIN_GAP_DEFAULT,\n        TimeUnit.MILLISECONDS);\n    if (minDiskCheckGapMs < 0) {\n      throw new DiskErrorException(\"Invalid value configured for \"\n          + DFS_DATANODE_DISK_CHECK_MIN_GAP_KEY + \" - \"\n          + minDiskCheckGapMs + \" (should be >= 0)\");\n    }\n    long diskCheckTimeout = conf.getTimeDuration(\n        DFSConfigKeys.DFS_DATANODE_DISK_CHECK_TIMEOUT_KEY,\n        DFSConfigKeys.DFS_DATANODE_DISK_CHECK_TIMEOUT_DEFAULT,\n        TimeUnit.MILLISECONDS);\n    if (diskCheckTimeout < 0) {\n      throw new DiskErrorException(\"Invalid value configured for \"\n          + DFS_DATANODE_DISK_CHECK_TIMEOUT_KEY + \" - \"\n          + diskCheckTimeout + \" (should be >= 0)\");\n    }\n    lastAllVolumesCheck = timer.monotonicNow() - minDiskCheckGapMs;\n    if (maxVolumeFailuresTolerated < MAX_VOLUME_FAILURE_TOLERATED_LIMIT) {\n      throw new DiskErrorException(\"Invalid value configured for \"\n          + DFS_DATANODE_FAILED_VOLUMES_TOLERATED_KEY + \" - \"\n          + maxVolumeFailuresTolerated + \" \"\n          + DataNode.MAX_VOLUME_FAILURES_TOLERATED_MSG);\n    }\n    delegateChecker = new ThrottledAsyncChecker<>(\n        timer, minDiskCheckGapMs, diskCheckTimeout,\n        Executors.newCachedThreadPool(\n            new ThreadFactoryBuilder()\n                .setNameFormat(\"DataNode DiskChecker thread %d\")\n                .setDaemon(true)\n                .build()));\n    checkVolumeResultHandlerExecutorService = Executors.newCachedThreadPool(\n        new ThreadFactoryBuilder()\n            .setNameFormat(\"VolumeCheck ResultHandler thread %d\")\n            .setDaemon(true)\n            .build());\n  }\n  /**\n   * Run checks against all HDDS volumes.\n   *\n   * This check may be performed at service startup and subsequently at\n   * regular intervals to detect and handle failed volumes.\n   *\n   * @param volumes - Set of volumes to be checked. This set must be immutable\n   *                for the duration of the check else the results will be\n   *                unexpected.\n   *\n   * @return set of failed volumes.\n   */\n  public Set<HddsVolume> checkAllVolumes(Collection<HddsVolume> volumes)\n      throws InterruptedException {\n    final long gap = timer.monotonicNow() - lastAllVolumesCheck;\n    if (gap < minDiskCheckGapMs) {\n      numSkippedChecks.incrementAndGet();\n      LOG.trace(\n          \"Skipped checking all volumes, time since last check {} is less \" +\n              \"than the minimum gap between checks ({} ms).\",\n          gap, minDiskCheckGapMs);\n      return Collections.emptySet();\n    }\n    lastAllVolumesCheck = timer.monotonicNow();\n    final Set<HddsVolume> healthyVolumes = new HashSet<>();\n    final Set<HddsVolume> failedVolumes = new HashSet<>();\n    final Set<HddsVolume> allVolumes = new HashSet<>();\n    final AtomicLong numVolumes = new AtomicLong(volumes.size());\n    final CountDownLatch latch = new CountDownLatch(1);\n    for (HddsVolume v : volumes) {\n      Optional<ListenableFuture<VolumeCheckResult>> olf =\n          delegateChecker.schedule(v, null);\n      LOG.info(\"Scheduled health check for volume {}\", v);\n      if (olf.isPresent()) {\n        allVolumes.add(v);\n        Futures.addCallback(olf.get(),\n            new ResultHandler(v, healthyVolumes, failedVolumes,\n                numVolumes, (ignored1, ignored2) -> latch.countDown()));\n      } else {\n        if (numVolumes.decrementAndGet() == 0) {\n          latch.countDown();\n        }\n      }\n    }\n    // Wait until our timeout elapses, after which we give up on\n    // the remaining volumes.\n    if (!latch.await(maxAllowedTimeForCheckMs, TimeUnit.MILLISECONDS)) {\n      LOG.warn(\"checkAllVolumes timed out after {} ms\" +\n          maxAllowedTimeForCheckMs);\n    }\n    numAllVolumeChecks.incrementAndGet();\n    synchronized (this) {\n      // All volumes that have not been detected as healthy should be\n      // considered failed. This is a superset of 'failedVolumes'.\n      //\n      // Make a copy under the mutex as Sets.difference() returns a view\n      // of a potentially changing set.\n      return new HashSet<>(Sets.difference(allVolumes, healthyVolumes));\n    }\n  }\n  /**\n   * A callback interface that is supplied the result of running an\n   * async disk check on multiple volumes.\n   */\n  public interface Callback {\n    /**\n     * @param healthyVolumes set of volumes that passed disk checks.\n     * @param failedVolumes set of volumes that failed disk checks.\n     */\n    void call(Set<HddsVolume> healthyVolumes,\n              Set<HddsVolume> failedVolumes);\n  }\n  /**\n   * Check a single volume asynchronously, returning a {@link ListenableFuture}\n   * that can be used to retrieve the final result.\n   *\n   * If the volume cannot be referenced then it is already closed and\n   * cannot be checked. No error is propagated to the callback.\n   *\n   * @param volume the volume that is to be checked.\n   * @param callback callback to be invoked when the volume check completes.\n   * @return true if the check was scheduled and the callback will be invoked.\n   *         false otherwise.\n   */\n<fim_suffix>  public boolean checkVolume(final HddsVolume volume, Callback callback) {\n    if (volume == null) {\n      LOG.debug(\"Cannot schedule check on null volume\");\n      return false;\n    }\n    Optional<ListenableFuture<VolumeCheckResult>> olf =\n        delegateChecker.schedule(volume, null);\n    if (olf.isPresent()) {\n      numVolumeChecks.incrementAndGet();\n      Futures.addCallback(olf.get(),\n          new ResultHandler(volume, new HashSet<>(), new HashSet<>(),\n              new AtomicLong(1), callback),\n          checkVolumeResultHandlerExecutorService\n      );\n      return true;\n    }\n    return false;\n  }<fim_middle>// function below has no smell\n"}