{"text": "<fim_prefix>  }\n  @Override\n  public Stream open() {\n    return new LogStream(\n        logFactory.get(),\n        readerFactory.get(),\n        readTimeout,\n        writerFactory,\n        writeTimeout,\n        noopEntry,\n        lifecycle);\n  }\n<fim_suffix>  @VisibleForTesting\n  static class LogStream implements org.apache.aurora.scheduler.log.Log.Stream {\n    @VisibleForTesting\n    static final class OpStats {\n      private final String opName;\n      private final SlidingStats timing;\n      private final AtomicLong timeouts;\n      private final AtomicLong failures;\n      OpStats(String opName) {\n        this.opName = MorePreconditions.checkNotBlank(opName);\n        timing = new SlidingStats(\"scheduler_log_native_\" + opName, \"nanos\");\n        timeouts = exportLongStat(\"scheduler_log_native_%s_timeouts\", opName);\n        failures = exportLongStat(\"scheduler_log_native_%s_failures\", opName);\n      }\n      private static AtomicLong exportLongStat(String template, Object... args) {\n        return Stats.exportLong(String.format(template, args));\n      }\n    }\n    private static final Function<Log.Entry, LogEntry> MESOS_ENTRY_TO_ENTRY =\n        LogEntry::new;\n    private final OpStats readStats = new OpStats(\"read\");\n    private final OpStats appendStats = new OpStats(\"append\");\n    private final OpStats truncateStats = new OpStats(\"truncate\");\n    private final AtomicLong entriesSkipped =\n        Stats.exportLong(\"scheduler_log_native_native_entries_skipped\");\n    private final LogInterface log;\n    private final ReaderInterface reader;\n    private final long readTimeout;\n    private final TimeUnit readTimeUnit;\n    private final Provider<WriterInterface> writerFactory;\n    private final long writeTimeout;\n    private final TimeUnit writeTimeUnit;\n    private final byte[] noopEntry;\n    private final Lifecycle lifecycle;\n    /**\n     * The underlying writer to use for mutation operations.  This field has three states:\n     * <ul>\n     *   <li>present: the writer is active and available for use</li>\n     *   <li>absent: the writer has not yet been initialized (initialization is lazy)</li>\n     *   <li>{@code null}: the writer has suffered a fatal error and no further operations may\n     *       be performed.</li>\n     * </ul>\n     * When {@code true}, indicates that the log has suffered a fatal error and no further\n     * operations may be performed.\n     */\n    @Nullable private Optional<WriterInterface> writer = Optional.empty();\n    LogStream(\n        LogInterface log,\n        ReaderInterface reader,\n        Amount<Long, Time> readTimeout,\n        Provider<WriterInterface> writerFactory,\n        Amount<Long, Time> writeTimeout,\n        byte[] noopEntry,\n        Lifecycle lifecycle) {\n      this.log = log;\n      this.reader = reader;\n      this.readTimeout = readTimeout.getValue();\n      this.readTimeUnit = readTimeout.getUnit().getTimeUnit();\n      this.writerFactory = writerFactory;\n      this.writeTimeout = writeTimeout.getValue();\n      this.writeTimeUnit = writeTimeout.getUnit().getTimeUnit();\n      this.noopEntry = noopEntry;\n      this.lifecycle = lifecycle;\n    }\n    @Override\n    public Iterator<Entry> readAll() throws StreamAccessException {\n      // TODO(John Sirois): Currently we must be the coordinator to ensure we get the 'full read'\n      // of log entries expected by the users of the org.apache.aurora.scheduler.log.Log interface.\n      // Switch to another method of ensuring this when it becomes available in mesos' log\n      // interface.\n      try {\n        append(noopEntry);\n      } catch (StreamAccessException e) {\n        throw new StreamAccessException(\"Error writing noop prior to a read\", e);\n      }\n      final Log.Position from = reader.beginning();\n      final Log.Position to = end().unwrap();\n      // Reading all the entries at once may cause large garbage collections. Instead, we\n      // lazily read the entries one by one as they are requested.\n      // TODO(Benjamin Hindman): Eventually replace this functionality with functionality\n      // from the Mesos Log.\n      return new UnmodifiableIterator<Entry>() {\n        private long position = Longs.fromByteArray(from.identity());\n        private final long endPosition = Longs.fromByteArray(to.identity());\n        private Entry entry = null;\n        @Override\n        public boolean hasNext() {\n          if (entry != null) {\n            return true;\n          }\n          while (position <= endPosition) {\n            long start = System.nanoTime();\n            try {\n              Log.Position p = log.position(Longs.toByteArray(position));\n              LOG.debug(\"Reading position {} from the log\", position);\n              List<Log.Entry> entries = reader.read(p, p, readTimeout, readTimeUnit);\n              // N.B. HACK! There is currently no way to \"increment\" a position. Until the Mesos\n              // Log actually provides a way to \"stream\" the log, we approximate as much by\n              // using longs via Log.Position.identity and Log.position.\n              position++;\n              // Reading positions in this way means it's possible that we get an \"invalid\" entry\n              // (e.g., in the underlying log terminology this would be anything but an append)\n              // which will be removed from the returned entries resulting in an empty list.\n              // We skip these.\n              if (entries.isEmpty()) {\n                entriesSkipped.getAndIncrement();\n              } else {\n                entry = MESOS_ENTRY_TO_ENTRY.apply(Iterables.getOnlyElement(entries));\n                return true;\n              }\n            } catch (TimeoutException e) {\n              readStats.timeouts.getAndIncrement();\n              throw new StreamAccessException(\"Timeout reading from log.\", e);\n            } catch (Log.OperationFailedException e) {\n              readStats.failures.getAndIncrement();\n              throw new StreamAccessException(\"Problem reading from log\", e);\n            } finally {\n              readStats.timing.accumulate(System.nanoTime() - start);\n            }\n          }\n          return false;\n        }\n        @Override\n        public Entry next() {\n          if (entry == null && !hasNext()) {\n            throw new NoSuchElementException();\n          }\n          Entry result = requireNonNull(entry);\n          entry = null;\n          return result;\n        }\n      };\n    }\n    @Override\n    public LogPosition append(final byte[] contents) throws StreamAccessException {\n      requireNonNull(contents);\n      Log.Position position = mutate(\n          appendStats,\n          logWriter -> logWriter.append(contents, writeTimeout, writeTimeUnit));\n      return LogPosition.wrap(position);\n    }\n    @Timed(\"scheduler_log_native_truncate_before\")\n    @Override\n    public void truncateBefore(org.apache.aurora.scheduler.log.Log.Position position)\n        throws StreamAccessException {\n      Preconditions.checkArgument(position instanceof LogPosition);\n      final Log.Position before = ((LogPosition) position).unwrap();\n      mutate(truncateStats, logWriter -> {\n        logWriter.truncate(before, writeTimeout, writeTimeUnit);\n        return null;\n      });\n    }\n    private interface Mutation<T> {\n      T apply(WriterInterface writer) throws TimeoutException, Log.WriterFailedException;\n    }\n    private StreamAccessException disableLog(AtomicLong stat, String message, Throwable cause) {\n      stat.incrementAndGet();\n      writer = null;\n      lifecycle.shutdown();\n      throw new StreamAccessException(message, cause);\n    }\n    private synchronized <T> T mutate(OpStats stats, Mutation<T> mutation) {\n      if (writer == null) {\n        throw new IllegalStateException(\"The log has encountered an error and cannot be used.\");\n      }\n      long start = System.nanoTime();\n      if (!writer.isPresent()) {\n        writer = Optional.of(writerFactory.get());\n      }\n      try {\n        return mutation.apply(writer.get());\n      } catch (TimeoutException e) {\n        throw disableLog(stats.timeouts, \"Timeout performing log \" + stats.opName, e);\n      } catch (Log.WriterFailedException e) {\n        throw disableLog(stats.failures, \"Problem performing log\" + stats.opName, e);\n      } finally {\n        stats.timing.accumulate(System.nanoTime() - start);\n      }\n    }\n    private LogPosition end() {\n      return LogPosition.wrap(reader.ending());\n    }\n    @VisibleForTesting\n    static class LogPosition implements org.apache.aurora.scheduler.log.Log.Position {\n      private final Log.Position underlying;\n      LogPosition(Log.Position underlying) {\n        this.underlying = underlying;\n      }\n      static LogPosition wrap(Log.Position position) {\n        return new LogPosition(position);\n      }\n      Log.Position unwrap() {\n        return underlying;\n      }\n    }\n    private static class LogEntry implements org.apache.aurora.scheduler.log.Log.Entry {\n      private final Log.Entry underlying;\n      LogEntry(Log.Entry entry) {\n        this.underlying = entry;\n      }\n      @Override\n      public byte[] contents() {\n        return underlying.data;\n      }\n    }\n  }<fim_middle>// class below is blob\n"}