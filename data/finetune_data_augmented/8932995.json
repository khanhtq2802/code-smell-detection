{"text": "<fim_prefix>import org.apache.hadoop.hive.ql.exec.vector.expressions.StringExpr;\nimport org.apache.hadoop.hive.ql.exec.vector.expressions.VectorExpression;\nimport org.apache.hadoop.hive.ql.metadata.HiveException;\nimport org.apache.hadoop.hive.ql.plan.BaseWork;\nimport org.apache.hadoop.hive.ql.plan.ExprNodeDesc;\nimport org.apache.hadoop.hive.ql.plan.OperatorDesc;\nimport org.apache.hadoop.hive.ql.plan.PTFDesc;\nimport org.apache.hadoop.hive.ql.plan.VectorDesc;\nimport org.apache.hadoop.hive.ql.plan.VectorPTFDesc;\nimport org.apache.hadoop.hive.ql.plan.VectorPTFInfo;\nimport org.apache.hadoop.hive.ql.plan.api.OperatorType;\nimport org.apache.hadoop.hive.ql.plan.ptf.WindowFrameDef;\nimport org.apache.hadoop.hive.serde2.io.HiveDecimalWritable;\nimport org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;\nimport org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\nimport org.apache.hadoop.hive.serde2.typeinfo.TypeInfoUtils;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n/**\n * This class is native vectorized PTF operator class.\n */\npublic class VectorPTFOperator extends Operator<PTFDesc>\n    implements VectorizationOperator, VectorizationContextRegion {\n  private static final long serialVersionUID = 1L;\n  private static final String CLASS_NAME = VectorPTFOperator.class.getName();\n  private static final Logger LOG = LoggerFactory.getLogger(CLASS_NAME);\n  private VectorizationContext vContext;\n  private VectorPTFDesc vectorDesc;\n  /**\n   * Information about our native vectorized PTF created by the Vectorizer class during\n   * it decision process and useful for execution.\n   */\n  private VectorPTFInfo vectorPTFInfo;\n  // This is the vectorized row batch description of the output of the native vectorized PTF\n  // operator.  It is based on the incoming vectorization context.  Its projection may include\n  // a mixture of input columns and new scratch columns (for the aggregation output).\n  protected VectorizationContext vOutContext;\n  private boolean isPartitionOrderBy;\n  /**\n   * PTF vector expressions.\n   */\n  private TypeInfo[] reducerBatchTypeInfos;\n  private int[] outputProjectionColumnMap;\n  private String[] outputColumnNames;\n  private TypeInfo[] outputTypeInfos;\n  private int evaluatorCount;\n  private String[] evaluatorFunctionNames;\n  private WindowFrameDef[] evaluatorWindowFrameDefs;\n  private VectorExpression[] evaluatorInputExpressions;\n  private Type[] evaluatorInputColumnVectorTypes;\n  private ExprNodeDesc[] orderExprNodeDescs;\n  private int[] orderColumnMap;\n  private Type[] orderColumnVectorTypes;\n  private VectorExpression[] orderExpressions;\n  private ExprNodeDesc[] partitionExprNodeDescs;\n  private int[] partitionColumnMap;\n  private Type[] partitionColumnVectorTypes;\n  private VectorExpression[] partitionExpressions;\n  private int[] keyInputColumnMap;\n  private int[] nonKeyInputColumnMap;\n  // The above members are initialized by the constructor and must not be\n  // transient.\n  //---------------------------------------------------------------------------\n  private transient boolean isLastGroupBatch;\n  private transient VectorizedRowBatch overflowBatch;\n  private transient VectorPTFGroupBatches groupBatches;\n  private transient VectorPTFEvaluatorBase[] evaluators;\n  private transient int[] streamingEvaluatorNums;\n  private transient boolean allEvaluatorsAreStreaming;\n  private transient boolean isFirstPartition;\n  private transient boolean[] currentPartitionIsNull;\n  private transient long[] currentPartitionLongs;\n  private transient double[] currentPartitionDoubles;\n  private transient byte[][] currentPartitionByteArrays;\n  private transient int[] currentPartitionByteLengths;\n  private transient HiveDecimalWritable[] currentPartitionDecimals;\n  private transient Timestamp[] currentPartitionTimestamps;\n  private transient HiveIntervalDayTime[] currentPartitionIntervalDayTimes;\n  // For debug tracing: the name of the map or reduce task.\n  private transient String taskName;\n  // Debug display.\n  private transient long batchCounter;\n  //---------------------------------------------------------------------------\n  /** Kryo ctor. */\n  protected VectorPTFOperator() {\n    super();\n  }\n  public VectorPTFOperator(CompilationOpContext ctx) {\n    super(ctx);\n  }\n  public VectorPTFOperator(CompilationOpContext ctx, OperatorDesc conf,\n      VectorizationContext vContext, VectorDesc vectorDesc) throws HiveException {\n    this(ctx);\n    LOG.info(\"VectorPTF constructor\");\n    PTFDesc desc = (PTFDesc) conf;\n    this.conf = desc;\n    this.vectorDesc = (VectorPTFDesc) vectorDesc;\n    vectorPTFInfo = this.vectorDesc.getVectorPTFInfo();\n    this.vContext = vContext;\n    reducerBatchTypeInfos = this.vectorDesc.getReducerBatchTypeInfos();\n    isPartitionOrderBy = this.vectorDesc.getIsPartitionOrderBy();\n    outputColumnNames = this.vectorDesc.getOutputColumnNames();\n    outputTypeInfos = this.vectorDesc.getOutputTypeInfos();\n    outputProjectionColumnMap = vectorPTFInfo.getOutputColumnMap();\n    /*\n     * Create a new vectorization context to create a new projection, but keep\n     * same output column manager must be inherited to track the scratch the columns.\n     */\n    vOutContext = new VectorizationContext(getName(), this.vContext);\n    setupVOutContext();\n    evaluatorFunctionNames = this.vectorDesc.getEvaluatorFunctionNames();\n    evaluatorCount = evaluatorFunctionNames.length;\n    evaluatorWindowFrameDefs = this.vectorDesc.getEvaluatorWindowFrameDefs();\n    evaluatorInputExpressions = vectorPTFInfo.getEvaluatorInputExpressions();\n    evaluatorInputColumnVectorTypes = vectorPTFInfo.getEvaluatorInputColumnVectorTypes();\n    orderExprNodeDescs = this.vectorDesc.getOrderExprNodeDescs();\n    orderColumnMap = vectorPTFInfo.getOrderColumnMap();\n    orderColumnVectorTypes = vectorPTFInfo.getOrderColumnVectorTypes();\n    orderExpressions = vectorPTFInfo.getOrderExpressions();\n    partitionExprNodeDescs = this.vectorDesc.getPartitionExprNodeDescs();\n    partitionColumnMap = vectorPTFInfo.getPartitionColumnMap();\n    partitionColumnVectorTypes = vectorPTFInfo.getPartitionColumnVectorTypes();\n    partitionExpressions = vectorPTFInfo.getPartitionExpressions();\n    keyInputColumnMap = vectorPTFInfo.getKeyInputColumnMap();\n    nonKeyInputColumnMap = vectorPTFInfo.getNonKeyInputColumnMap();\n  }\n  /**\n   * Setup the vectorized row batch description of the output of the native vectorized PTF\n   * operator.  Use the output projection we previously built from a mixture of input\n   * columns and new scratch columns.\n   */\n  protected void setupVOutContext() {\n    vOutContext.resetProjectionColumns();\n    final int count = outputColumnNames.length;\n    for (int i = 0; i < count; ++i) {\n      String columnName = outputColumnNames[i];\n      int outputColumn = outputProjectionColumnMap[i];\n      vOutContext.addProjectionColumn(columnName, outputColumn);\n    }\n  }\n  /*\n   * Allocate overflow batch columns by hand.\n   */\n  private void allocateOverflowBatchColumnVector(VectorizedRowBatch overflowBatch, int outputColumn,\n              String typeName) throws HiveException {\n    if (overflowBatch.cols[outputColumn] == null) {\n      typeName = VectorizationContext.mapTypeNameSynonyms(typeName);\n      TypeInfo typeInfo = TypeInfoUtils.getTypeInfoFromTypeString(typeName);\n      overflowBatch.cols[outputColumn] = VectorizedBatchUtil.createColumnVector(typeInfo);\n    }\n  }\n  /*\n   * Setup our 2nd batch with the same \"column schema\" as the output columns plus any scratch\n   * columns since the overflow batch will get forwarded to children operators.\n   */\n<fim_suffix>  protected VectorizedRowBatch setupOverflowBatch() throws HiveException {\n    int initialColumnCount = vContext.firstOutputColumnIndex();\n    VectorizedRowBatch overflowBatch;\n    int totalNumColumns = initialColumnCount + vOutContext.getScratchColumnTypeNames().length;\n    overflowBatch = new VectorizedRowBatch(totalNumColumns);\n    // First, just allocate just the output columns we will be using.\n    for (int i = 0; i < outputProjectionColumnMap.length; i++) {\n      int outputColumn = outputProjectionColumnMap[i];\n      String typeName = outputTypeInfos[i].getTypeName();\n      allocateOverflowBatchColumnVector(overflowBatch, outputColumn, typeName);\n    }\n    // Now, add any scratch columns needed for children operators.\n    int outputColumn = initialColumnCount;\n    for (String typeName : vOutContext.getScratchColumnTypeNames()) {\n      allocateOverflowBatchColumnVector(overflowBatch, outputColumn++, typeName);\n    }\n    overflowBatch.projectedColumns = outputProjectionColumnMap;\n    overflowBatch.projectionSize = outputProjectionColumnMap.length;\n    overflowBatch.reset();\n    return overflowBatch;\n  }<fim_middle>// function below is long method\n"}