{"text": "<fim_prefix>/*\n * CDDL HEADER START\n *\n * The contents of this file are subject to the terms of the\n * Common Development and Distribution License (the \"License\").\n * You may not use this file except in compliance with the License.\n *\n * See LICENSE.txt included in this distribution for the specific\n * language governing permissions and limitations under the License.\n *\n * When distributing Covered Code, include this CDDL HEADER in each\n * file and include the License file at LICENSE.txt.\n * If applicable, add the following below this CDDL HEADER, with the\n * fields enclosed by brackets \"[]\" replaced with your own identifying\n * information: Portions Copyright [yyyy] [name of copyright owner]\n *\n * CDDL HEADER END\n */\n\n/*\n * Copyright (c) 2005, 2018, Oracle and/or its affiliates. All rights reserved.\n * Portions Copyright (c) 2017-2018, Chris Fraire <cfraire@me.com>.\n */\npackage org.opengrok.indexer.analysis.document;\n\nimport java.io.IOException;\nimport java.io.Reader;\nimport java.io.Writer;\nimport org.apache.lucene.document.Document;\nimport org.opengrok.indexer.analysis.AbstractAnalyzer;\nimport org.opengrok.indexer.analysis.AnalyzerFactory;\nimport org.opengrok.indexer.analysis.JFlexTokenizer;\nimport org.opengrok.indexer.analysis.OGKTextField;\nimport org.opengrok.indexer.analysis.StreamSource;\nimport org.opengrok.indexer.analysis.TextAnalyzer;\nimport org.opengrok.indexer.analysis.WriteXrefArgs;\nimport org.opengrok.indexer.analysis.Xrefer;\nimport org.opengrok.indexer.search.QueryBuilder;\n\n/**\n * Analyzes [tn]roff files Created on September 30, 2005\n *\n * @author Chandan\n */\n<fim_suffix>public class TroffAnalyzer extends TextAnalyzer {\n\n    /**\n     * Creates a new instance of TroffAnalyzer\n     * @param factory defined instance for the analyzer\n     */\n    protected TroffAnalyzer(AnalyzerFactory factory) {\n        super(factory, new JFlexTokenizer(new TroffFullTokenizer(\n                AbstractAnalyzer.DUMMY_READER)));\n    }    \n\n    /**\n     * Gets a version number to be used to tag processed documents so that\n     * re-analysis can be re-done later if a stored version number is different\n     * from the current implementation.\n     * @return 20180112_00\n     */\n    @Override\n    protected int getSpecializedVersionNo() {\n        return 20180112_00; // Edit comment above too!\n    }\n    \n    @Override\n    public void analyze(Document doc, StreamSource src, Writer xrefOut) throws IOException {        \n        //this is to explicitly use appropriate analyzers tokenstream to workaround #1376 symbols search works like full text search \n        this.symbolTokenizer.setReader(getReader(src.getStream()));\n        OGKTextField full = new OGKTextField(QueryBuilder.FULL,\n            symbolTokenizer);\n        doc.add(full);\n\n        if (xrefOut != null) {\n            try (Reader in = getReader(src.getStream())) {\n                WriteXrefArgs args = new WriteXrefArgs(in, xrefOut);\n                args.setProject(project);\n                Xrefer xref = writeXref(args);\n\n                addNumLines(doc, xref.getLineNumber());\n                addLOC(doc, xref.getLOC());\n            }\n        }\n    }\n\n    /**\n     * Creates a wrapped {@link TroffXref} instance.\n     * @param reader the data to produce xref for\n     * @return an xref instance\n     */\n    @Override\n    protected Xrefer newXref(Reader reader) {\n        return new TroffXref(reader);\n    }\n}<fim_middle>// class below has no smell\n"}