{"text": "<fim_prefix> *\n * Term metadata consists of three parts:\n * 1. term statistics: docFreq, totalTermFreq;\n * 2. monotonic long[], e.g. the pointer to the postings list for that term;\n * 3. generic byte[], e.g. other information need by postings reader.\n *\n * <p>\n * File:\n * <ul>\n *   <li><tt>.tst</tt>: <a href=\"#Termdictionary\">Term Dictionary</a></li>\n * </ul>\n * <p>\n *\n * <a name=\"Termdictionary\"></a>\n * <h3>Term Dictionary</h3>\n * <p>\n *  The .tst contains a list of FSTs, one for each field.\n *  The FST maps a term to its corresponding statistics (e.g. docfreq) \n *  and metadata (e.g. information for postings list reader like file pointer\n *  to postings list).\n * </p>\n * <p>\n *  Typically the metadata is separated into two parts:\n *  <ul>\n *   <li>\n *    Monotonical long array: Some metadata will always be ascending in order\n *    with the corresponding term. This part is used by FST to share outputs between arcs.\n *   </li>\n *   <li>\n *    Generic byte array: Used to store non-monotonic metadata.\n *   </li>\n *  </ul>\n *\n * File format:\n * <ul>\n *  <li>TermsDict(.tst) --&gt; Header, <i>PostingsHeader</i>, FieldSummary, DirOffset</li>\n *  <li>FieldSummary --&gt; NumFields, &lt;FieldNumber, NumTerms, SumTotalTermFreq?, \n *                                      SumDocFreq, DocCount, LongsSize, TermFST &gt;<sup>NumFields</sup></li>\n *  <li>TermFST --&gt; {@link FST FST&lt;TermData&gt;}</li>\n *  <li>TermData --&gt; Flag, BytesSize?, LongDelta<sup>LongsSize</sup>?, Byte<sup>BytesSize</sup>?, \n *                      &lt; DocFreq[Same?], (TotalTermFreq-DocFreq) &gt; ? </li>\n *  <li>Header --&gt; {@link CodecUtil#writeIndexHeader IndexHeader}</li>\n *  <li>DirOffset --&gt; {@link DataOutput#writeLong Uint64}</li>\n *  <li>DocFreq, LongsSize, BytesSize, NumFields,\n *        FieldNumber, DocCount --&gt; {@link DataOutput#writeVInt VInt}</li>\n *  <li>TotalTermFreq, NumTerms, SumTotalTermFreq, SumDocFreq, LongDelta --&gt; \n *        {@link DataOutput#writeVLong VLong}</li>\n * </ul>\n * <p>Notes:</p>\n * <ul>\n *  <li>\n *   The format of PostingsHeader and generic meta bytes are customized by the specific postings implementation:\n *   they contain arbitrary per-file data (such as parameters or versioning information), and per-term data\n *   (non-monotonic ones like pulsed postings data).\n *  </li>\n *  <li>\n *   The format of TermData is determined by FST, typically monotonic metadata will be dense around shallow arcs,\n *   while in deeper arcs only generic bytes and term statistics exist.\n *  </li>\n *  <li>\n *   The byte Flag is used to indicate which part of metadata exists on current arc. Specially the monotonic part\n *   is omitted when it is an array of 0s.\n *  </li>\n *  <li>\n *   Since LongsSize is per-field fixed, it is only written once in field summary.\n *  </li>\n * </ul>\n *\n * @lucene.experimental\n */\npublic class FSTTermsWriter extends FieldsConsumer {\n  static final String TERMS_EXTENSION = \"tfp\";\n  static final String TERMS_CODEC_NAME = \"FSTTerms\";\n  public static final int TERMS_VERSION_START = 2;\n  public static final int TERMS_VERSION_CURRENT = TERMS_VERSION_START;\n  final PostingsWriterBase postingsWriter;\n  final FieldInfos fieldInfos;\n  IndexOutput out;\n  final int maxDoc;\n  final List<FieldMetaData> fields = new ArrayList<>();\n  public FSTTermsWriter(SegmentWriteState state, PostingsWriterBase postingsWriter) throws IOException {\n    final String termsFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, TERMS_EXTENSION);\n    this.postingsWriter = postingsWriter;\n    this.fieldInfos = state.fieldInfos;\n    this.out = state.directory.createOutput(termsFileName, state.context);\n    this.maxDoc = state.segmentInfo.maxDoc();\n    boolean success = false;\n    try {\n      CodecUtil.writeIndexHeader(out, TERMS_CODEC_NAME, TERMS_VERSION_CURRENT,\n                                        state.segmentInfo.getId(), state.segmentSuffix);   \n      this.postingsWriter.init(out, state); \n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(out);\n      }\n    }\n  }\n  private void writeTrailer(IndexOutput out, long dirStart) throws IOException {\n    out.writeLong(dirStart);\n  }\n  @Override\n  public void write(Fields fields, NormsProducer norms) throws IOException {\n    for(String field : fields) {\n      Terms terms = fields.terms(field);\n      if (terms == null) {\n        continue;\n      }\n      FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n      boolean hasFreq = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS) >= 0;\n      TermsEnum termsEnum = terms.iterator();\n      TermsWriter termsWriter = new TermsWriter(fieldInfo);\n      long sumTotalTermFreq = 0;\n      long sumDocFreq = 0;\n      FixedBitSet docsSeen = new FixedBitSet(maxDoc);\n      while (true) {\n        BytesRef term = termsEnum.next();\n        if (term == null) {\n          break;\n        }\n        BlockTermState termState = postingsWriter.writeTerm(term, termsEnum, docsSeen, norms);\n        if (termState != null) {\n          termsWriter.finishTerm(term, termState);\n          sumTotalTermFreq += termState.totalTermFreq;\n          sumDocFreq += termState.docFreq;\n        }\n      }\n      termsWriter.finish(hasFreq ? sumTotalTermFreq : -1, sumDocFreq, docsSeen.cardinality());\n    }\n  }\n  @Override\n  public void close() throws IOException {\n    if (out != null) {\n      boolean success = false;\n      try {\n        // write field summary\n        final long dirStart = out.getFilePointer();\n        out.writeVInt(fields.size());\n        for (FieldMetaData field : fields) {\n          out.writeVInt(field.fieldInfo.number);\n          out.writeVLong(field.numTerms);\n          if (field.fieldInfo.getIndexOptions() != IndexOptions.DOCS) {\n            out.writeVLong(field.sumTotalTermFreq);\n          }\n          out.writeVLong(field.sumDocFreq);\n          out.writeVInt(field.docCount);\n          out.writeVInt(field.longsSize);\n          field.dict.save(out);\n        }\n        writeTrailer(out, dirStart);\n        CodecUtil.writeFooter(out);\n        success = true;\n      } finally {\n        if (success) {\n          IOUtils.close(out, postingsWriter);\n        } else {\n          IOUtils.closeWhileHandlingException(out, postingsWriter);\n        }\n        out = null;\n      }\n    }\n  }\n<fim_suffix>  private static class FieldMetaData {\n    public final FieldInfo fieldInfo;\n    public final long numTerms;\n    public final long sumTotalTermFreq;\n    public final long sumDocFreq;\n    public final int docCount;\n    public final int longsSize;\n    public final FST<FSTTermOutputs.TermData> dict;\n    public FieldMetaData(FieldInfo fieldInfo, long numTerms, long sumTotalTermFreq, long sumDocFreq, int docCount, int longsSize, FST<FSTTermOutputs.TermData> fst) {\n      this.fieldInfo = fieldInfo;\n      this.numTerms = numTerms;\n      this.sumTotalTermFreq = sumTotalTermFreq;\n      this.sumDocFreq = sumDocFreq;\n      this.docCount = docCount;\n      this.longsSize = longsSize;\n      this.dict = fst;\n    }\n  }<fim_middle>// class below is data class\n"}