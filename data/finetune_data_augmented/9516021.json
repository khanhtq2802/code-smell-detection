{"text": "<fim_prefix>      return (hfs != null);\n    } catch (FileNotFoundException e) {\n      return false;\n    }\n  }\n  private void copyBlocksToLostFound(String parent, HdfsFileStatus file,\n        LocatedBlocks blocks) throws IOException {\n    final DFSClient dfs = new DFSClient(DFSUtilClient.getNNAddress(conf), conf);\n    final String fullName = file.getFullName(parent);\n    OutputStream fos = null;\n    try {\n      if (!lfInited) {\n        lostFoundInit(dfs);\n      }\n      if (!lfInitedOk) {\n        throw new IOException(\"failed to initialize lost+found\");\n      }\n      String target = lostFound + fullName;\n      if (hdfsPathExists(target)) {\n        LOG.warn(\"Fsck: can't copy the remains of \" + fullName + \" to \" +\n          \"lost+found, because \" + target + \" already exists.\");\n        return;\n      }\n      if (!namenode.getRpcServer().mkdirs(\n          target, file.getPermission(), true)) {\n        throw new IOException(\"failed to create directory \" + target);\n      }\n      // create chains\n      int chain = 0;\n      boolean copyError = false;\n      for (LocatedBlock lBlk : blocks.getLocatedBlocks()) {\n        LocatedBlock lblock = lBlk;\n        DatanodeInfo[] locs = lblock.getLocations();\n        if (locs == null || locs.length == 0) {\n          if (fos != null) {\n            fos.flush();\n            fos.close();\n            fos = null;\n          }\n          continue;\n        }\n        if (fos == null) {\n          fos = dfs.create(target + \"/\" + chain, true);\n          chain++;\n        }\n        // copy the block. It's a pity it's not abstracted from DFSInputStream ...\n        try {\n          copyBlock(dfs, lblock, fos);\n        } catch (Exception e) {\n          LOG.error(\"Fsck: could not copy block \" + lblock.getBlock() +\n              \" to \" + target, e);\n          fos.flush();\n          fos.close();\n          fos = null;\n          internalError = true;\n          copyError = true;\n        }\n      }\n      if (copyError) {\n        LOG.warn(\"Fsck: there were errors copying the remains of the \" +\n          \"corrupted file \" + fullName + \" to /lost+found\");\n      } else {\n        LOG.info(\"Fsck: copied the remains of the corrupted file \" +\n          fullName + \" to /lost+found\");\n      }\n    } catch (Exception e) {\n      LOG.error(\"copyBlocksToLostFound: error processing \" + fullName, e);\n      internalError = true;\n    } finally {\n      if (fos != null) fos.close();\n      dfs.close();\n    }\n  }\n  /*\n   * XXX (ab) Bulk of this method is copied verbatim from {@link DFSClient}, which is\n   * bad. Both places should be refactored to provide a method to copy blocks\n   * around.\n   */\n  private void copyBlock(final DFSClient dfs, LocatedBlock lblock,\n      OutputStream fos) throws Exception {\n    int failures = 0;\n    InetSocketAddress targetAddr = null;\n    Set<DatanodeInfo> deadNodes = new HashSet<DatanodeInfo>();\n    BlockReader blockReader = null;\n    ExtendedBlock block = lblock.getBlock();\n    while (blockReader == null) {\n      DatanodeInfo chosenNode;\n      try {\n        chosenNode = bestNode(dfs, lblock.getLocations(), deadNodes);\n        targetAddr = NetUtils.createSocketAddr(chosenNode.getXferAddr());\n      }  catch (IOException ie) {\n        if (failures >= HdfsClientConfigKeys.DFS_CLIENT_MAX_BLOCK_ACQUIRE_FAILURES_DEFAULT) {\n          throw new IOException(\"Could not obtain block \" + lblock, ie);\n        }\n        LOG.info(\"Could not obtain block from any node:  \" + ie);\n        try {\n          Thread.sleep(10000);\n        }  catch (InterruptedException iex) {\n        }\n        deadNodes.clear();\n        failures++;\n        continue;\n      }\n      try {\n        String file = BlockReaderFactory.getFileName(targetAddr,\n            block.getBlockPoolId(), block.getBlockId());\n        blockReader = new BlockReaderFactory(dfs.getConf()).\n            setFileName(file).\n            setBlock(block).\n            setBlockToken(lblock.getBlockToken()).\n            setStartOffset(0).\n            setLength(block.getNumBytes()).\n            setVerifyChecksum(true).\n            setClientName(\"fsck\").\n            setDatanodeInfo(chosenNode).\n            setInetSocketAddress(targetAddr).\n            setCachingStrategy(CachingStrategy.newDropBehind()).\n            setClientCacheContext(dfs.getClientContext()).\n            setConfiguration(namenode.getConf()).\n            setRemotePeerFactory(new RemotePeerFactory() {\n              @Override\n              public Peer newConnectedPeer(InetSocketAddress addr,\n                  Token<BlockTokenIdentifier> blockToken, DatanodeID datanodeId)\n                  throws IOException {\n                Peer peer = null;\n                Socket s = NetUtils.getDefaultSocketFactory(conf).createSocket();\n                try {\n                  s.connect(addr, HdfsConstants.READ_TIMEOUT);\n                  s.setSoTimeout(HdfsConstants.READ_TIMEOUT);\n                  peer = DFSUtilClient.peerFromSocketAndKey(\n                        dfs.getSaslDataTransferClient(), s, NamenodeFsck.this,\n                        blockToken, datanodeId, HdfsConstants.READ_TIMEOUT);\n                } finally {\n                  if (peer == null) {\n                    IOUtils.closeQuietly(s);\n                  }\n                }\n                return peer;\n              }\n            }).\n            build();\n      }  catch (IOException ex) {\n        // Put chosen node into dead list, continue\n        LOG.info(\"Failed to connect to \" + targetAddr + \":\" + ex);\n        deadNodes.add(chosenNode);\n      }\n    }\n    long bytesRead = 0L;\n    try {\n      bytesRead = copyBock(blockReader, fos);\n    } catch (Exception e) {\n      throw new Exception(\"Could not copy block data for \" + lblock.getBlock(),\n          e);\n    } finally {\n      blockReader.close();\n    }\n    if (bytesRead != block.getNumBytes()) {\n      throw new IOException(\"Recorded block size is \" + block.getNumBytes()\n          + \", but datanode returned \" + bytesRead + \" bytes\");\n    }\n  }\n  private long copyBock(BlockReader blockReader, OutputStream os)\n      throws IOException {\n    final byte[] buf = new byte[8192];\n    int cnt = 0;\n    long bytesRead = 0L;\n    while ((cnt = blockReader.read(buf, 0, buf.length)) > 0) {\n      os.write(buf, 0, cnt);\n      bytesRead += cnt;\n    }\n    return bytesRead;\n  }\n  @Override\n  public DataEncryptionKey newDataEncryptionKey() throws IOException {\n    return namenode.getRpcServer().getDataEncryptionKey();\n  }\n  /*\n   * XXX (ab) See comment above for copyBlock().\n   *\n   * Pick the best node from which to stream the data.\n   * That's the local one, if available.\n   */\n  private DatanodeInfo bestNode(DFSClient dfs, DatanodeInfo[] nodes,\n      Set<DatanodeInfo> deadNodes) throws IOException {\n    if ((nodes == null) || (nodes.length - deadNodes.size() < 1)) {\n      throw new IOException(\"No live nodes contain current block\");\n    }\n    DatanodeInfo chosenNode;\n    do {\n      chosenNode = nodes[ThreadLocalRandom.current().nextInt(nodes.length)];\n    } while (deadNodes.contains(chosenNode));\n    return chosenNode;\n  }\n<fim_suffix>  private void lostFoundInit(DFSClient dfs) {\n    lfInited = true;\n    try {\n      String lfName = \"/lost+found\";\n      final HdfsFileStatus lfStatus = dfs.getFileInfo(lfName);\n      if (lfStatus == null) { // not exists\n        lfInitedOk = dfs.mkdirs(lfName, null, true);\n        lostFound = lfName;\n      } else if (!lfStatus.isDirectory()) { // exists but not a directory\n        LOG.warn(\"Cannot use /lost+found : a regular file with this name exists.\");\n        lfInitedOk = false;\n      }  else { // exists and is a directory\n        lostFound = lfName;\n        lfInitedOk = true;\n      }\n    }  catch (Exception e) {\n      e.printStackTrace();\n      lfInitedOk = false;\n    }\n    if (lostFound == null) {\n      LOG.warn(\"Cannot initialize /lost+found .\");\n      lfInitedOk = false;\n      internalError = true;\n    }\n  }<fim_middle>// function below has no smell\n"}