{"text": "<fim_prefix>        }\n      }\n    }\n    sizeStore.incrementRegionSize(regionInfo, delta);\n  }\n  /**\n   * Log a very elaborate compaction completion message.\n   * @param cr Request.\n   * @param sfs Resulting files.\n   * @param compactionStartTime Start time.\n   */\n  private void logCompactionEndMessage(\n      CompactionRequestImpl cr, List<HStoreFile> sfs, long now, long compactionStartTime) {\n    StringBuilder message = new StringBuilder(\n      \"Completed\" + (cr.isMajor() ? \" major\" : \"\") + \" compaction of \"\n      + cr.getFiles().size() + (cr.isAllFiles() ? \" (all)\" : \"\") + \" file(s) in \"\n      + this + \" of \" + this.getRegionInfo().getShortNameToLog() + \" into \");\n    if (sfs.isEmpty()) {\n      message.append(\"none, \");\n    } else {\n      for (HStoreFile sf: sfs) {\n        message.append(sf.getPath().getName());\n        message.append(\"(size=\");\n        message.append(TraditionalBinaryPrefix.long2String(sf.getReader().length(), \"\", 1));\n        message.append(\"), \");\n      }\n    }\n    message.append(\"total size for store is \")\n      .append(StringUtils.TraditionalBinaryPrefix.long2String(storeSize.get(), \"\", 1))\n      .append(\". This selection was in queue for \")\n      .append(StringUtils.formatTimeDiff(compactionStartTime, cr.getSelectionTime()))\n      .append(\", and took \").append(StringUtils.formatTimeDiff(now, compactionStartTime))\n      .append(\" to execute.\");\n    LOG.info(message.toString());\n    if (LOG.isTraceEnabled()) {\n      int fileCount = storeEngine.getStoreFileManager().getStorefileCount();\n      long resultSize = getTotalSize(sfs);\n      String traceMessage = \"COMPACTION start,end,size out,files in,files out,store size,\"\n        + \"store files [\" + compactionStartTime + \",\" + now + \",\" + resultSize + \",\"\n          + cr.getFiles().size() + \",\" + sfs.size() + \",\" +  storeSize + \",\" + fileCount + \"]\";\n      LOG.trace(traceMessage);\n    }\n  }\n  /**\n   * Call to complete a compaction. Its for the case where we find in the WAL a compaction\n   * that was not finished.  We could find one recovering a WAL after a regionserver crash.\n   * See HBASE-2231.\n   * @param compaction\n   */\n  public void replayCompactionMarker(CompactionDescriptor compaction, boolean pickCompactionFiles,\n      boolean removeFiles) throws IOException {\n    LOG.debug(\"Completing compaction from the WAL marker\");\n    List<String> compactionInputs = compaction.getCompactionInputList();\n    List<String> compactionOutputs = Lists.newArrayList(compaction.getCompactionOutputList());\n    // The Compaction Marker is written after the compaction is completed,\n    // and the files moved into the region/family folder.\n    //\n    // If we crash after the entry is written, we may not have removed the\n    // input files, but the output file is present.\n    // (The unremoved input files will be removed by this function)\n    //\n    // If we scan the directory and the file is not present, it can mean that:\n    //   - The file was manually removed by the user\n    //   - The file was removed as consequence of subsequent compaction\n    // so, we can't do anything with the \"compaction output list\" because those\n    // files have already been loaded when opening the region (by virtue of\n    // being in the store's folder) or they may be missing due to a compaction.\n    String familyName = this.getColumnFamilyName();\n    Set<String> inputFiles = new HashSet<>();\n    for (String compactionInput : compactionInputs) {\n      Path inputPath = fs.getStoreFilePath(familyName, compactionInput);\n      inputFiles.add(inputPath.getName());\n    }\n    //some of the input files might already be deleted\n    List<HStoreFile> inputStoreFiles = new ArrayList<>(compactionInputs.size());\n    for (HStoreFile sf : this.getStorefiles()) {\n      if (inputFiles.contains(sf.getPath().getName())) {\n        inputStoreFiles.add(sf);\n      }\n    }\n    // check whether we need to pick up the new files\n    List<HStoreFile> outputStoreFiles = new ArrayList<>(compactionOutputs.size());\n    if (pickCompactionFiles) {\n      for (HStoreFile sf : this.getStorefiles()) {\n        compactionOutputs.remove(sf.getPath().getName());\n      }\n      for (String compactionOutput : compactionOutputs) {\n        StoreFileInfo storeFileInfo = fs.getStoreFileInfo(getColumnFamilyName(), compactionOutput);\n        HStoreFile storeFile = createStoreFileAndReader(storeFileInfo);\n        outputStoreFiles.add(storeFile);\n      }\n    }\n    if (!inputStoreFiles.isEmpty() || !outputStoreFiles.isEmpty()) {\n      LOG.info(\"Replaying compaction marker, replacing input files: \" +\n          inputStoreFiles + \" with output files : \" + outputStoreFiles);\n      this.replaceStoreFiles(inputStoreFiles, outputStoreFiles);\n      this.completeCompaction(inputStoreFiles);\n    }\n  }\n  /**\n   * This method tries to compact N recent files for testing.\n   * Note that because compacting \"recent\" files only makes sense for some policies,\n   * e.g. the default one, it assumes default policy is used. It doesn't use policy,\n   * but instead makes a compaction candidate list by itself.\n   * @param N Number of files.\n   */\n  @VisibleForTesting\n  public void compactRecentForTestingAssumingDefaultPolicy(int N) throws IOException {\n    List<HStoreFile> filesToCompact;\n    boolean isMajor;\n    this.lock.readLock().lock();\n    try {\n      synchronized (filesCompacting) {\n        filesToCompact = Lists.newArrayList(storeEngine.getStoreFileManager().getStorefiles());\n        if (!filesCompacting.isEmpty()) {\n          // exclude all files older than the newest file we're currently\n          // compacting. this allows us to preserve contiguity (HBASE-2856)\n          HStoreFile last = filesCompacting.get(filesCompacting.size() - 1);\n          int idx = filesToCompact.indexOf(last);\n          Preconditions.checkArgument(idx != -1);\n          filesToCompact.subList(0, idx + 1).clear();\n        }\n        int count = filesToCompact.size();\n        if (N > count) {\n          throw new RuntimeException(\"Not enough files\");\n        }\n        filesToCompact = filesToCompact.subList(count - N, count);\n        isMajor = (filesToCompact.size() == storeEngine.getStoreFileManager().getStorefileCount());\n        filesCompacting.addAll(filesToCompact);\n        Collections.sort(filesCompacting, storeEngine.getStoreFileManager()\n            .getStoreFileComparator());\n      }\n    } finally {\n      this.lock.readLock().unlock();\n    }\n    try {\n      // Ready to go. Have list of files to compact.\n      List<Path> newFiles = ((DefaultCompactor)this.storeEngine.getCompactor())\n          .compactForTesting(filesToCompact, isMajor);\n      for (Path newFile: newFiles) {\n        // Move the compaction into place.\n        HStoreFile sf = moveFileIntoPlace(newFile);\n        if (this.getCoprocessorHost() != null) {\n          this.getCoprocessorHost().postCompact(this, sf, null, null, null);\n        }\n        replaceStoreFiles(filesToCompact, Collections.singletonList(sf));\n        completeCompaction(filesToCompact);\n      }\n    } finally {\n      synchronized (filesCompacting) {\n        filesCompacting.removeAll(filesToCompact);\n      }\n    }\n  }\n<fim_suffix>  @Override\n  public boolean hasReferences() {\n    // Grab the read lock here, because we need to ensure that: only when the atomic\n    // replaceStoreFiles(..) finished, we can get all the complete store file list.\n    this.lock.readLock().lock();\n    try {\n      // Merge the current store files with compacted files here due to HBASE-20940.\n      Collection<HStoreFile> allStoreFiles = new ArrayList<>(getStorefiles());\n      allStoreFiles.addAll(getCompactedFiles());\n      return StoreUtils.hasReferences(allStoreFiles);\n    } finally {\n      this.lock.readLock().unlock();\n    }\n  }<fim_middle>// function below has no smell\n"}