{"text": "<fim_prefix>    return columnPrecInfo;\n  }\n  /** Reads a data sample to evaluate this column's precision (variable or fixed); this is best effort, caller\n   * should be ready to handle false positives.\n   *\n   * @param columnPrecInfo input/output precision info container\n   * @throws IOException\n   */\n  private final void guessColumnPrecision(ColumnPrecisionInfo columnPrecInfo) throws IOException {\n    columnPrecInfo.columnPrecisionType = ColumnPrecisionType.DT_PRECISION_IS_VARIABLE;\n    loadPageIfNeeed();\n    // Minimum number of values within a data size to consider bulk processing\n    final int minNumVals = VarLenBulkPageReader.BUFF_SZ / BULK_PROCESSING_MAX_PREC_LEN;\n    final int maxDataToProcess =\n      Math.min(VarLenBulkPageReader.BUFF_SZ + 4 * minNumVals,\n        (int) (parentInst.pageReader.byteLength-parentInst.pageReader.readyToReadPosInBytes));\n    if (parentInst.usingDictionary || maxDataToProcess == 0) {\n      // The number of values is small, there are lot of null values, or dictionary encoding is used. Bulk\n      // processing should work fine for these use-cases\n      columnPrecInfo.bulkProcess = true;\n      return;\n    }\n    ByteBuffer buffer = ByteBuffer.allocate(maxDataToProcess);\n    buffer.order(ByteOrder.nativeOrder());\n    parentInst.pageReader.pageData.getBytes((int) parentInst.pageReader.readyToReadPosInBytes, buffer.array(), 0, maxDataToProcess);\n    buffer.limit(maxDataToProcess);\n    int numValues = 0;\n    int fixedDataLen = -1;\n    boolean isFixedPrecision = false;\n    do {\n      if (buffer.remaining() < 4) {\n        break;\n      }\n      int data_len = buffer.getInt();\n      if (fixedDataLen < 0) {\n        fixedDataLen = data_len;\n        isFixedPrecision = true;\n      }\n      if (isFixedPrecision && fixedDataLen != data_len) {\n        isFixedPrecision = false;\n      }\n      if (buffer.remaining() < data_len) {\n        break;\n      }\n      buffer.position(buffer.position() + data_len);\n      ++numValues;\n    } while (true);\n    // We need to have encountered at least a couple of values with the same length; if the values\n    // have long length, then fixed vs VL is not a big deal with regard to performance.\n    if (isFixedPrecision && fixedDataLen >= 0) {\n      columnPrecInfo.columnPrecisionType = ColumnPrecisionType.DT_PRECISION_IS_FIXED;\n      columnPrecInfo.precision = fixedDataLen;\n      if (fixedDataLen <= BULK_PROCESSING_MAX_PREC_LEN) {\n        columnPrecInfo.bulkProcess = true;\n      } else {\n        columnPrecInfo.columnPrecisionType = ColumnPrecisionType.DT_PRECISION_IS_VARIABLE;\n        columnPrecInfo.bulkProcess = false;\n      }\n    } else {\n      // At this point we know this column is variable length; we need to figure out whether it is worth\n      // processing it in a bulk-manner or not.\n      if (numValues >= minNumVals) {\n        columnPrecInfo.bulkProcess = true;\n      } else {\n        columnPrecInfo.bulkProcess = false;\n      }\n    }\n  }\n  private void loadPageIfNeeed() throws IOException {\n    if (!parentInst.pageReader.hasPage()) {\n      // load a page\n      parentInst.pageReader.next();\n      // update the definition level information\n      setValuesReadersOnNewPage();\n    }\n  }\n  private boolean batchConstraintsReached() {\n    // Let's update this column's memory quota\n    columnMemoryQuota = batchSizerMgr.getCurrentFieldBatchMemory(parentInst.valueVec.getField().getName());\n    assert columnMemoryQuota.getMaxMemoryUsage() > 0;\n    // Now try to figure out whether the next chunk will take us beyond the memory quota\n    final int maxNumRecordsInChunk = VarLenBulkPageReader.BUFF_SZ / BatchSizingMemoryUtil.INT_VALUE_WIDTH;\n    if (this.parentInst.valueVec.getField().isNullable()) {\n      return batchConstraintsReached(\n        maxNumRecordsInChunk * BatchSizingMemoryUtil.BYTE_VALUE_WIDTH, // max \"bits\"    space within a chunk\n        maxNumRecordsInChunk * BatchSizingMemoryUtil.INT_VALUE_WIDTH,  // max \"offsets\" space within a chunk\n        VarLenBulkPageReader.BUFF_SZ                                   // max \"data\"    space within a chunk\n      );\n    } else {\n      return batchConstraintsReached(\n        0,\n        maxNumRecordsInChunk * BatchSizingMemoryUtil.INT_VALUE_WIDTH,  // max \"offsets\" space within a chunk\n        VarLenBulkPageReader.BUFF_SZ                                   // max \"data\"    space within a chunk\n      );\n    }\n  }\n  private boolean batchConstraintsReached(int newBitsMemory, int newOffsetsMemory, int newDataMemory) {\n    assert oprReadState.batchFieldIndex <= recordsToRead; // cannot read beyond the batch size\n    // Did we reach the batch size limit?\n    if (oprReadState.batchFieldIndex == recordsToRead) {\n      return true; // batch size reached\n    }\n    // Memory constraint check logic:\n    // - if this is the first chunk to process, then let it proceed as we need to at least return\n    //   one row; this also means the minimum batch memory shouldn't be lower than 2 chunks (please refer\n    //   to getMinVLColumnMemorySize() method for more information).\n    //\n    // - Otherwise, we make sure that the memory growth after processing a chunk cannot go beyond the maximum\n    //   batch memory for this column\n    // - There is also a caveat that needs to be handled during processing:\n    //   o The page-bulk-reader will stop loading entries if it encounters a large value (doesn't fit within\n    //     the chunk)\n    //   o There is an exception though, which is if the entry is the first one within the batch (this is to\n    //     ensure that we always make progress)\n    //   o In this situation a callback to this object is made to assess whether this large entry can be loaded\n    //     into the ValueVector.\n    // Is this the first chunk to be processed?\n    if (oprReadState.batchFieldIndex == 0) {\n      return false; // we should process at least one chunk\n    }\n    // Is the next processed chunk going to cause memory to overflow beyond the allowed limit?\n    columnMemoryUsage.vector = parentInst.valueVec;\n    columnMemoryUsage.memoryQuota = columnMemoryQuota;\n    columnMemoryUsage.currValueCount = oprReadState.batchFieldIndex;\n    // Return true if we cannot add this new payload\n    return !BatchSizingMemoryUtil.canAddNewData(columnMemoryUsage, newBitsMemory, newOffsetsMemory, newDataMemory);\n  }\n  private int getRemainingRecords() {\n    // remaining records to return within this batch\n    final int toReadRemaining       = recordsToRead - oprReadState.batchFieldIndex;\n    final int remainingOverflowData = getRemainingOverflowData();\n    final int remaining;\n    // This method remainder semantic depends on whether we are dealing with page data or\n    // overflow data; now that overflow data is behaving like a source of input\n    if (remainingOverflowData == 0) {\n      final int pageRemaining = parentInst.pageReader.currentPageCount - oprReadState.numPageFieldsProcessed;\n      remaining               = Math.min(toReadRemaining, pageRemaining);\n    } else {\n      remaining = Math.min(toReadRemaining, remainingOverflowData);\n    }\n    return remaining;\n  }\n  private boolean overflowDataAvailable() {\n    return getRemainingOverflowData() > 0;\n  }\n  private int getRemainingOverflowData() {\n    if (fieldOverflowStateContainer != null) {\n      FieldOverflowStateImpl overflowState =\n        (FieldOverflowStateImpl) fieldOverflowStateContainer.overflowState;\n      if (overflowState != null) {\n        return overflowState.getRemainingOverflowData();\n      } else {\n        // This can happen if this is the first time we are accessing this container as\n        // the overflow reader didn't have the chance consume any overflow data yet.\n        return fieldOverflowStateContainer.overflowDef.numValues;\n      }\n    }\n    return 0;\n  }\n  private void deinitOverflowData() {\n    batchSizerMgr.releaseFieldOverflowContainer(parentInst.valueVec.getField().getName());\n    fieldOverflowStateContainer = null;\n  }\n  // --------------------------------------------------------------------------\n  // Inner Classes\n  // --------------------------------------------------------------------------\n  /** Enumeration which indicates whether a column's type precision is unknown, variable, or fixed. */\n  enum ColumnPrecisionType {\n    DT_PRECISION_UNKNOWN,\n    DT_PRECISION_IS_FIXED,\n    DT_PRECISION_IS_VARIABLE;\n    static boolean isPrecTypeUnknown(ColumnPrecisionType type) {\n      return DT_PRECISION_UNKNOWN.equals(type);\n    }\n<fim_suffix>    static boolean isPrecTypeFixed(ColumnPrecisionType type) {\n      return DT_PRECISION_IS_FIXED.equals(type);\n    }<fim_middle>// function below has no smell\n"}