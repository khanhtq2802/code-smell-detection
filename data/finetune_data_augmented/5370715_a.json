{"text": "<fim_prefix>        }\n    }\n    private class ServerSelectDeleteMutationPlan implements MutationPlan {\n        private final StatementContext context;\n        private final QueryPlan dataPlan;\n        private final PhoenixConnection connection;\n        private final QueryPlan aggPlan;\n        private final RowProjector projector;\n        private final int maxSize;\n        private final int maxSizeBytes;\n        public ServerSelectDeleteMutationPlan(QueryPlan dataPlan, PhoenixConnection connection, QueryPlan aggPlan,\n                                              RowProjector projector, int maxSize, int maxSizeBytes) {\n            this.context = dataPlan.getContext();\n            this.dataPlan = dataPlan;\n            this.connection = connection;\n            this.aggPlan = aggPlan;\n            this.projector = projector;\n            this.maxSize = maxSize;\n            this.maxSizeBytes = maxSizeBytes;\n        }\n        @Override\n        public ParameterMetaData getParameterMetaData() {\n            return context.getBindManager().getParameterMetaData();\n        }\n        @Override\n        public StatementContext getContext() {\n            return context;\n        }\n        @Override\n        public TableRef getTargetRef() {\n            return dataPlan.getTableRef();\n        }\n        @Override\n        public Set<TableRef> getSourceRefs() {\n            return dataPlan.getSourceRefs();\n        }\n        @Override\n        public Operation getOperation() {\n          return operation;\n        }\n        @Override\n        public MutationState execute() throws SQLException {\n            // TODO: share this block of code with UPSERT SELECT\n            ImmutableBytesWritable ptr = context.getTempPtr();\n            PTable table = dataPlan.getTableRef().getTable();\n            table.getIndexMaintainers(ptr, context.getConnection());\n            byte[] txState = table.isTransactional() ? connection.getMutationState().encodeTransaction() : ByteUtil.EMPTY_BYTE_ARRAY;\n            ServerCache cache = null;\n            try {\n                if (ptr.getLength() > 0) {\n                    byte[] uuidValue = ServerCacheClient.generateId();\n                    context.getScan().setAttribute(PhoenixIndexCodec.INDEX_UUID, uuidValue);\n                    context.getScan().setAttribute(PhoenixIndexCodec.INDEX_PROTO_MD, ptr.get());\n                    context.getScan().setAttribute(BaseScannerRegionObserver.TX_STATE, txState);\n                    ScanUtil.setClientVersion(context.getScan(), MetaDataProtocol.PHOENIX_VERSION);\n                }\n                ResultIterator iterator = aggPlan.iterator();\n                try {\n                    Tuple row = iterator.next();\n                    final long mutationCount = (Long) projector.getColumnProjector(0).getValue(row, PLong.INSTANCE, ptr);\n                    return new MutationState(maxSize, maxSizeBytes, connection) {\n                        @Override\n                        public long getUpdateCount() {\n                            return mutationCount;\n                        }\n                    };\n                } finally {\n                    iterator.close();\n                }\n            } finally {\n                if (cache != null) {\n                    cache.close();\n                }\n            }\n        }\n        @Override\n        public ExplainPlan getExplainPlan() throws SQLException {\n            List<String> queryPlanSteps =  aggPlan.getExplainPlan().getPlanSteps();\n            List<String> planSteps = Lists.newArrayListWithExpectedSize(queryPlanSteps.size()+1);\n            planSteps.add(\"DELETE ROWS\");\n            planSteps.addAll(queryPlanSteps);\n            return new ExplainPlan(planSteps);\n        }\n        @Override\n        public Long getEstimatedRowsToScan() throws SQLException {\n            return aggPlan.getEstimatedRowsToScan();\n        }\n        @Override\n        public Long getEstimatedBytesToScan() throws SQLException {\n            return aggPlan.getEstimatedBytesToScan();\n        }\n        @Override\n        public Long getEstimateInfoTimestamp() throws SQLException {\n            return aggPlan.getEstimateInfoTimestamp();\n        }\n        @Override\n        public QueryPlan getQueryPlan() {\n            return aggPlan;\n        }\n    }\n<fim_suffix>    private class ClientSelectDeleteMutationPlan implements MutationPlan {\n        private final StatementContext context;\n        private final TableRef targetTableRef;\n        private final QueryPlan dataPlan;\n        private final QueryPlan bestPlan;\n        private final boolean hasPreOrPostProcessing;\n        private final DeletingParallelIteratorFactory parallelIteratorFactory;\n        private final List<TableRef> otherTableRefs;\n        private final TableRef projectedTableRef;\n        private final int maxSize;\n        private final int maxSizeBytes;\n        private final PhoenixConnection connection;\n        public ClientSelectDeleteMutationPlan(TableRef targetTableRef, QueryPlan dataPlan, QueryPlan bestPlan,\n                                              boolean hasPreOrPostProcessing,\n                                              DeletingParallelIteratorFactory parallelIteratorFactory,\n                                              List<TableRef> otherTableRefs, TableRef projectedTableRef, int maxSize,\n                                              int maxSizeBytes, PhoenixConnection connection) {\n            this.context = bestPlan.getContext();\n            this.targetTableRef = targetTableRef;\n            this.dataPlan = dataPlan;\n            this.bestPlan = bestPlan;\n            this.hasPreOrPostProcessing = hasPreOrPostProcessing;\n            this.parallelIteratorFactory = parallelIteratorFactory;\n            this.otherTableRefs = otherTableRefs;\n            this.projectedTableRef = projectedTableRef;\n            this.maxSize = maxSize;\n            this.maxSizeBytes = maxSizeBytes;\n            this.connection = connection;\n        }\n        @Override\n        public ParameterMetaData getParameterMetaData() {\n            return context.getBindManager().getParameterMetaData();\n        }\n        @Override\n        public StatementContext getContext() {\n            return context;\n        }\n        @Override\n        public TableRef getTargetRef() {\n            return targetTableRef;\n        }\n        @Override\n        public Set<TableRef> getSourceRefs() {\n            return dataPlan.getSourceRefs();\n        }\n        @Override\n        public Operation getOperation() {\n          return operation;\n        }\n        @Override\n        public MutationState execute() throws SQLException {\n            ResultIterator iterator = bestPlan.iterator();\n            try {\n                // If we're not doing any pre or post processing, we can produce the delete mutations directly\n                // in the parallel threads executed for the scan\n                if (!hasPreOrPostProcessing) {\n                    Tuple tuple;\n                    long totalRowCount = 0;\n                    if (parallelIteratorFactory != null) {\n                        parallelIteratorFactory.setQueryPlan(bestPlan);\n                        parallelIteratorFactory.setOtherTableRefs(otherTableRefs);\n                        parallelIteratorFactory.setProjectedTableRef(projectedTableRef);\n                    }\n                    while ((tuple=iterator.next()) != null) {// Runs query\n                        Cell kv = tuple.getValue(0);\n                        totalRowCount += PLong.INSTANCE.getCodec().decodeLong(kv.getValueArray(), kv.getValueOffset(), SortOrder.getDefault());\n                    }\n                    // Return total number of rows that have been deleted from the table. In the case of auto commit being off\n                    // the mutations will all be in the mutation state of the current connection. We need to divide by the\n                    // total number of tables we updated as otherwise the client will get an inflated result.\n                    int totalTablesUpdateClientSide = 1; // data table is always updated\n                    PTable bestTable = bestPlan.getTableRef().getTable();\n                    // global immutable tables are also updated client side (but don't double count the data table)\n                    if (bestPlan != dataPlan && isMaintainedOnClient(bestTable)) {\n                        totalTablesUpdateClientSide++;\n                    }\n                    for (TableRef otherTableRef : otherTableRefs) {\n                        PTable otherTable = otherTableRef.getTable();\n                        // Don't double count the data table here (which morphs when it becomes a projected table, hence this check)\n                        if (projectedTableRef != otherTableRef && isMaintainedOnClient(otherTable)) {\n                            totalTablesUpdateClientSide++;\n                        }\n                    }\n                    MutationState state = new MutationState(maxSize, maxSizeBytes, connection, totalRowCount/totalTablesUpdateClientSide);\n                    // set the read metrics accumulated in the parent context so that it can be published when the mutations are committed.\n                    state.setReadMetricQueue(context.getReadMetricsQueue());\n                    return state;\n                } else {\n                    // Otherwise, we have to execute the query and produce the delete mutations in the single thread\n                    // producing the query results.\n                    return deleteRows(context, iterator, bestPlan, projectedTableRef, otherTableRefs);\n                }\n            } finally {\n                iterator.close();\n            }\n        }\n        @Override\n        public ExplainPlan getExplainPlan() throws SQLException {\n            List<String> queryPlanSteps =  bestPlan.getExplainPlan().getPlanSteps();\n            List<String> planSteps = Lists.newArrayListWithExpectedSize(queryPlanSteps.size()+1);\n            planSteps.add(\"DELETE ROWS\");\n            planSteps.addAll(queryPlanSteps);\n            return new ExplainPlan(planSteps);\n        }\n        @Override\n        public Long getEstimatedRowsToScan() throws SQLException {\n            return bestPlan.getEstimatedRowsToScan();\n        }\n        @Override\n        public Long getEstimatedBytesToScan() throws SQLException {\n            return bestPlan.getEstimatedBytesToScan();\n        }\n        @Override\n        public Long getEstimateInfoTimestamp() throws SQLException {\n            return bestPlan.getEstimateInfoTimestamp();\n        }\n        @Override\n        public QueryPlan getQueryPlan() {\n            return bestPlan;\n        }\n    }<fim_middle>// class below is blob and data class\n"}