{"text": "<fim_prefix>/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage org.apache.hadoop.util;\n\nimport java.util.AbstractList;\nimport java.util.Iterator;\nimport java.util.List;\n\nimport org.apache.hadoop.classification.InterfaceAudience;\n\nimport com.google.common.annotations.VisibleForTesting;\nimport com.google.common.base.Preconditions;\nimport com.google.common.collect.Iterables;\nimport com.google.common.collect.Lists;\n\n/**\n * Simplified List implementation which stores elements as a list\n * of chunks, each chunk having a maximum size. This improves over\n * using an ArrayList in that creating a large list will never require\n * a large amount of contiguous heap space -- thus reducing the likelihood\n * of triggering a CMS compaction pause due to heap fragmentation.\n * \n * The first chunks allocated are small, but each additional chunk is\n * 50% larger than the previous, ramping up to a configurable maximum\n * chunk size. Reasonable defaults are provided which should be a good\n * balance between not making any large allocations while still retaining\n * decent performance.\n *\n * This currently only supports a small subset of List operations --\n * namely addition and iteration.\n */\n<fim_suffix>@InterfaceAudience.Private\npublic class ChunkedArrayList<T> extends AbstractList<T> {\n\n  /**\n   * The chunks which make up the full list.\n   */\n  private final List<List<T>> chunks = Lists.newArrayList();\n  \n  /**\n   * Cache of the last element in the 'chunks' array above.\n   * This speeds up the add operation measurably.\n   */\n  private List<T> lastChunk = null;\n\n  /**\n   * The capacity with which the last chunk was allocated.\n   */\n  private int lastChunkCapacity;\n  \n  /**\n   * The capacity of the first chunk to allocate in a cleared list.\n   */\n  private final int initialChunkCapacity;\n  \n  /**\n   * The maximum number of elements for any chunk.\n   */\n  private final int maxChunkSize;\n\n  /**\n   * Total number of elements in the list.\n   */\n  private int size;\n  \n  /**\n   * Default initial size is 6 elements, since typical minimum object\n   * size is 64 bytes, and this leaves enough space for the object\n   * header.\n   */\n  private static final int DEFAULT_INITIAL_CHUNK_CAPACITY = 6;\n  \n  /**\n   * Default max size is 8K elements - which, at 8 bytes per element\n   * should be about 64KB -- small enough to easily fit in contiguous\n   * free heap space even with a fair amount of fragmentation.\n   */\n  private static final int DEFAULT_MAX_CHUNK_SIZE = 8*1024;\n  \n\n  public ChunkedArrayList() {\n    this(DEFAULT_INITIAL_CHUNK_CAPACITY, DEFAULT_MAX_CHUNK_SIZE);\n  }\n\n  /**\n   * @param initialChunkCapacity the capacity of the first chunk to be\n   * allocated\n   * @param maxChunkSize the maximum size of any chunk allocated\n   */\n  public ChunkedArrayList(int initialChunkCapacity, int maxChunkSize) {\n    Preconditions.checkArgument(maxChunkSize >= initialChunkCapacity);\n    this.initialChunkCapacity = initialChunkCapacity;\n    this.maxChunkSize = maxChunkSize;\n  }\n\n  @Override\n  public Iterator<T> iterator() {\n    final Iterator<T> it = Iterables.concat(chunks).iterator();\n\n    return new Iterator<T>() {\n      @Override\n      public boolean hasNext() {\n        return it.hasNext();\n      }\n\n      @Override\n      public T next() {\n        return it.next();\n      }\n\n      @Override\n      public void remove() {\n        it.remove();\n        size--;\n      }\n    };\n  }\n\n  @Override\n  public boolean add(T e) {\n    if (size == Integer.MAX_VALUE) {\n      throw new RuntimeException(\"Can't add an additional element to the \" +\n          \"list; list already has INT_MAX elements.\");\n    }\n    if (lastChunk == null) {\n      addChunk(initialChunkCapacity);\n    } else if (lastChunk.size() >= lastChunkCapacity) {\n      int newCapacity = lastChunkCapacity + (lastChunkCapacity >> 1);\n      addChunk(Math.min(newCapacity, maxChunkSize));\n    }\n    size++;\n    return lastChunk.add(e);\n  }\n\n  @Override\n  public void clear() {\n    chunks.clear();\n    lastChunk = null;\n    lastChunkCapacity = 0;\n    size = 0;\n  }\n  \n  private void addChunk(int capacity) {\n    lastChunk = Lists.newArrayListWithCapacity(capacity);\n    chunks.add(lastChunk);\n    lastChunkCapacity = capacity;\n  }\n\n  @Override\n  public boolean isEmpty() {\n    return size == 0;\n  }\n\n  @Override\n  public int size() {\n    return size;\n  }\n  \n  @VisibleForTesting\n  int getNumChunks() {\n    return chunks.size();\n  }\n  \n  @VisibleForTesting\n  int getMaxChunkSize() {\n    int size = 0;\n    for (List<T> chunk : chunks) {\n      size = Math.max(size, chunk.size());\n    }\n    return size;\n  }\n\n  @Override\n  public T get(int idx) {\n    if (idx < 0) {\n      throw new IndexOutOfBoundsException();\n    }\n    int base = 0;\n    Iterator<List<T>> it = chunks.iterator();\n    while (it.hasNext()) {\n      List<T> list = it.next();\n      int size = list.size();\n      if (idx < base + size) {\n        return list.get(idx - base);\n      }\n      base += size;\n    }\n    throw new IndexOutOfBoundsException();\n  }\n}<fim_middle>// class below has no smell\n"}