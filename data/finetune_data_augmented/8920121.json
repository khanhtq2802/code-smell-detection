{"text": "<fim_prefix>  private int batchNumForwards = 0; // whether current batch has any forwarded keys\n  private int[] indexToBatchIndex; // mapping of index (lined up w/keys) to index in the batch\n  protected int[] batchIndexToResult; // mapping of index in the batch (linear) to hash result\n  protected int batchSize; // Size of the current batch.\n  protected boolean isEnabled = false;\n  private final Comparator<Integer> C = new Comparator<Integer>() {\n    public int compare(Integer o1, Integer o2) {\n      byte[] key1 = keys[o1];\n      byte[] key2 = keys[o2];\n      int length1 = distKeyLengths[o1];\n      int length2 = distKeyLengths[o2];\n      return WritableComparator.compareBytes(key1, 0, length1, key2, 0, length2);\n    }\n  };\n  public void initialize(\n    int topN, float memUsage, boolean isMapGroupBy, BinaryCollector collector, final OperatorDesc conf,\n    final Configuration hconf) {\n    assert topN >= 0 && memUsage > 0;\n    assert !this.isEnabled;\n    this.isEnabled = false;\n    this.topN = topN;\n    this.collector = collector;\n    if (topN == 0) {\n      isEnabled = true;\n      return; // topN == 0 will cause a short-circuit, don't need any initialization\n    }\n    final boolean isTez = HiveConf.getVar(hconf, HiveConf.ConfVars.HIVE_EXECUTION_ENGINE).equals(\"tez\");\n    final boolean isLlap = LlapDaemonInfo.INSTANCE.isLlap();\n    final int numExecutors = isLlap ? LlapDaemonInfo.INSTANCE.getNumExecutors() : 1;\n    // Used Memory = totalMemory() - freeMemory();\n    // Total Free Memory = maxMemory() - Used Memory;\n    long totalFreeMemory = Runtime.getRuntime().maxMemory() -\n      Runtime.getRuntime().totalMemory() + Runtime.getRuntime().freeMemory();\n    if (isTez) {\n      MemoryMXBean memoryMXBean = ManagementFactory.getMemoryMXBean();\n      // TODO: For LLAP, assumption is off-heap cache.\n      final long memoryUsedPerExecutor = (memoryMXBean.getHeapMemoryUsage().getUsed() / numExecutors);\n      // this is total free memory available per executor in case of LLAP\n      totalFreeMemory = conf.getMaxMemoryAvailable() - memoryUsedPerExecutor;\n    }\n    // limit * 64 : compensation of arrays for key/value/hashcodes\n    this.threshold = (long) (memUsage * totalFreeMemory) - topN * 64L;\n    if (threshold < 0) {\n      return;\n    }\n    this.indexes = isMapGroupBy ? new HashForGroup() : new HashForRow();\n    this.keys = new byte[topN + 1][];\n    this.values = new byte[topN + 1][];\n    this.hashes = new int[topN + 1];\n    this.distKeyLengths = new int[topN + 1];\n    this.evicted = topN;\n    this.isEnabled = true;\n  }\n  /**\n   * Try store the non-vectorized key.\n   * @param key Serialized key.\n   * @return TopNHash.FORWARD if the row should be forwarded;\n   *         TopNHash.EXCLUDED if the row should be discarded;\n   *         any other number if the row is to be stored; the index should be passed to storeValue.\n   */\n  public int tryStoreKey(HiveKey key, boolean partColsIsNull) throws HiveException, IOException {\n    if (!isEnabled) {\n      return FORWARD; // short-circuit quickly - forward all rows\n    }\n    if (topN == 0) {\n      return EXCLUDE; // short-circuit quickly - eat all rows\n    }\n    int index = insertKeyIntoHeap(key);\n    if (index >= 0) {\n      usage += key.getLength();\n      return index;\n    }\n    // IndexStore is trying to tell us something.\n    switch (index) {\n      case FORWARD:  return FORWARD;\n      case EXCLUDE: return EXCLUDE; // skip the row.\n      default: {\n        assert false;\n        throw new HiveException(\"Invalid result trying to store the key: \" + index);\n      }\n    }\n  }\n  /**\n   * Perform basic checks and initialize TopNHash for the new vectorized row batch.\n   * @param size batch size\n   * @return TopNHash.FORWARD if all rows should be forwarded w/o trying to call TopN;\n   *         TopNHash.EXCLUDED if all rows should be discarded w/o trying to call TopN;\n   *         any other result means the batch has been started.\n   */\n  public int startVectorizedBatch(int size) throws IOException, HiveException {\n    if (!isEnabled) {\n      return FORWARD; // short-circuit quickly - forward all rows\n    } else if (topN == 0) {\n      return EXCLUDE; // short-circuit quickly - eat all rows\n    }\n    // Flush here if the memory usage is too high. After that, we have the entire\n    // batch already in memory anyway so we will bypass the memory checks.\n    if (usage > threshold) {\n      int excluded = this.excluded;\n      LOG.info(\"Top-N hash is flushing rows\");\n      flushInternal();\n      if (excluded == 0) {\n        LOG.info(\"Top-N hash has been disabled\");\n        isEnabled = false;\n        return FORWARD; // Hash is ineffective, disable.\n      }\n    }\n    // Started ok; initialize context for new batch.\n    batchSize = size;\n    if (batchIndexToResult == null || batchIndexToResult.length < batchSize) {\n      batchIndexToResult = new int[Math.max(batchSize, VectorizedRowBatch.DEFAULT_SIZE)];\n    }\n    if (indexToBatchIndex == null) {\n      indexToBatchIndex = new int[topN + 1];\n    }\n    Arrays.fill(indexToBatchIndex, -1);\n    batchNumForwards = 0;\n    return 0;\n  }\n  /**\n   * Try to put the key from the current vectorized batch into the heap.\n   * @param key the key.\n   * @param batchIndex The index of the key in the vectorized batch (sequential, not .selected).\n   */\n<fim_suffix>  public void tryStoreVectorizedKey(HiveKey key, boolean partColsIsNull, int batchIndex)\n      throws HiveException, IOException {\n    // Assumption - batchIndex is increasing; startVectorizedBatch was called\n    int size = indexes.size();\n    int index = size < topN ? size : evicted;\n    keys[index] = Arrays.copyOf(key.getBytes(), key.getLength());\n    distKeyLengths[index] = key.getDistKeyLength();\n    hashes[index] = key.hashCode();\n    Integer collisionIndex = indexes.store(index);\n    if (null != collisionIndex) {\n      /*\n       * since there is a collision index will be used for the next value \n       * so have the map point back to original index.\n       */\n      if ( indexes instanceof HashForGroup ) {\n        indexes.store(collisionIndex);\n      }\n      // forward conditional on the survival of the corresponding key currently in indexes.\n      ++batchNumForwards;\n      batchIndexToResult[batchIndex] = MAY_FORWARD - collisionIndex;\n      return;\n    }\n    indexToBatchIndex[index] = batchIndex;\n    batchIndexToResult[batchIndex] = index;\n    if (size != topN) return;\n    evicted = indexes.removeBiggest();  // remove the biggest key\n    if (index == evicted) {\n      excluded++;\n      batchIndexToResult[batchIndex] = EXCLUDE;\n      indexToBatchIndex[index] = -1;\n      return; // input key is bigger than any of keys in hash\n    }\n    removed(evicted);\n    int evictedBatchIndex = indexToBatchIndex[evicted];\n    if (evictedBatchIndex >= 0) {\n      // reset the result for the evicted index\n      batchIndexToResult[evictedBatchIndex] = EXCLUDE;\n      indexToBatchIndex[evicted] = -1;\n    }\n    // Evict all results grouped with this index; it cannot be any key further in the batch.\n    // If we evict a key from this batch, the keys grouped with it cannot be earlier that that key.\n    // If we evict a key that is not from this batch, initial i = (-1) + 1 = 0, as intended.\n    int evictedForward = (MAY_FORWARD - evicted);\n    for (int i = evictedBatchIndex + 1; i < batchIndex && (batchNumForwards > 0); ++i) {\n      if (batchIndexToResult[i] == evictedForward) {\n        batchIndexToResult[i] = EXCLUDE;\n        --batchNumForwards;\n      }\n    }\n  }<fim_middle>// function below is long method\n"}