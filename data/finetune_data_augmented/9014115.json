{"text": "<fim_prefix>    Iterable<Map.Entry<String,String>> iter = indexWriter.getLiveCommitData();\n    if (iter != null) {\n      for(Map.Entry<String,String> ent : iter) {\n        data.put(ent.getKey(), ent.getValue());\n      }\n    }\n    String epochStr = data.get(INDEX_EPOCH);\n    if (epochStr == null || Long.parseLong(epochStr, 16) != indexEpoch) {\n      indexWriter.setLiveCommitData(combinedCommitData(indexWriter.getLiveCommitData()));\n    }\n    return indexWriter.prepareCommit();\n  }\n  @Override\n  public int getSize() {\n    ensureOpen();\n    return nextID;\n  }\n  /**\n   * Set the number of cache misses before an attempt is made to read the entire\n   * taxonomy into the in-memory cache.\n   * <p>\n   * This taxonomy writer holds an in-memory cache of recently seen categories\n   * to speed up operation. On each cache-miss, the on-disk index needs to be\n   * consulted. When an existing taxonomy is opened, a lot of slow disk reads\n   * like that are needed until the cache is filled, so it is more efficient to\n   * read the entire taxonomy into memory at once. We do this complete read\n   * after a certain number (defined by this method) of cache misses.\n   * <p>\n   * If the number is set to {@code 0}, the entire taxonomy is read into the\n   * cache on first use, without fetching individual categories first.\n   * <p>\n   * NOTE: it is assumed that this method is called immediately after the\n   * taxonomy writer has been created.\n   */\n  public void setCacheMissesUntilFill(int i) {\n    ensureOpen();\n    cacheMissesUntilFill = i;\n  }\n  // we need to guarantee that if several threads call this concurrently, only\n  // one executes it, and after it returns, the cache is updated and is either\n  // complete or not.\n  private synchronized void perhapsFillCache() throws IOException {\n    if (cacheMisses.get() < cacheMissesUntilFill) {\n      return;\n    }\n    if (!shouldFillCache) {\n      // we already filled the cache once, there's no need to re-fill it\n      return;\n    }\n    shouldFillCache = false;\n    initReaderManager();\n    boolean aborted = false;\n    DirectoryReader reader = readerManager.acquire();\n    try {\n      PostingsEnum postingsEnum = null;\n      for (LeafReaderContext ctx : reader.leaves()) {\n        Terms terms = ctx.reader().terms(Consts.FULL);\n        if (terms != null) { // cannot really happen, but be on the safe side\n          // TODO: share per-segment TermsEnum here!\n          TermsEnum termsEnum = terms.iterator();\n          while (termsEnum.next() != null) {\n            if (!cache.isFull()) {\n              BytesRef t = termsEnum.term();\n              // Since we guarantee uniqueness of categories, each term has exactly\n              // one document. Also, since we do not allow removing categories (and\n              // hence documents), there are no deletions in the index. Therefore, it\n              // is sufficient to call next(), and then doc(), exactly once with no\n              // 'validation' checks.\n              FacetLabel cp = new FacetLabel(FacetsConfig.stringToPath(t.utf8ToString()));\n              postingsEnum = termsEnum.postings(postingsEnum, PostingsEnum.NONE);\n              boolean res = cache.put(cp, postingsEnum.nextDoc() + ctx.docBase);\n              assert !res : \"entries should not have been evicted from the cache\";\n            } else {\n              // the cache is full and the next put() will evict entries from it, therefore abort the iteration.\n              aborted = true;\n              break;\n            }\n          }\n        }\n        if (aborted) {\n          break;\n        }\n      }\n    } finally {\n      readerManager.release(reader);\n    }\n    cacheIsComplete = !aborted;\n    if (cacheIsComplete) {\n      synchronized (this) {\n        // everything is in the cache, so no need to keep readerManager open.\n        // this block is executed in a sync block so that it works well with\n        // initReaderManager called in parallel.\n        readerManager.close();\n        readerManager = null;\n        initializedReaderManager = false;\n      }\n    }\n  }\n  private TaxonomyIndexArrays getTaxoArrays() throws IOException {\n    if (taxoArrays == null) {\n      synchronized (this) {\n        if (taxoArrays == null) {\n          initReaderManager();\n          DirectoryReader reader = readerManager.acquire();\n          try {\n            // according to Java Concurrency, this might perform better on some\n            // JVMs, since the object initialization doesn't happen on the\n            // volatile member.\n            TaxonomyIndexArrays tmpArrays = new TaxonomyIndexArrays(reader);\n            taxoArrays = tmpArrays;\n          } finally {\n            readerManager.release(reader);\n          }\n        }\n      }\n    }\n    return taxoArrays;\n  }\n  @Override\n  public int getParent(int ordinal) throws IOException {\n    ensureOpen();\n    // Note: the following if() just enforces that a user can never ask\n    // for the parent of a nonexistant category - even if the parent array\n    // was allocated bigger than it really needs to be.\n    FutureObjects.checkIndex(ordinal, nextID);\n    int[] parents = getTaxoArrays().parents();\n    assert ordinal < parents.length : \"requested ordinal (\" + ordinal + \"); parents.length (\" + parents.length + \") !\";\n    return parents[ordinal];\n  }\n  /**\n   * Takes the categories from the given taxonomy directory, and adds the\n   * missing ones to this taxonomy. Additionally, it fills the given\n   * {@link OrdinalMap} with a mapping from the original ordinal to the new\n   * ordinal.\n   */\n  public void addTaxonomy(Directory taxoDir, OrdinalMap map) throws IOException {\n    ensureOpen();\n    DirectoryReader r = DirectoryReader.open(taxoDir);\n    try {\n      final int size = r.numDocs();\n      final OrdinalMap ordinalMap = map;\n      ordinalMap.setSize(size);\n      int base = 0;\n      PostingsEnum docs = null;\n      for (final LeafReaderContext ctx : r.leaves()) {\n        final LeafReader ar = ctx.reader();\n        final Terms terms = ar.terms(Consts.FULL);\n        // TODO: share per-segment TermsEnum here!\n        TermsEnum te = terms.iterator();\n        while (te.next() != null) {\n          FacetLabel cp = new FacetLabel(FacetsConfig.stringToPath(te.term().utf8ToString()));\n          final int ordinal = addCategory(cp);\n          docs = te.postings(docs, PostingsEnum.NONE);\n          ordinalMap.addMapping(docs.nextDoc() + base, ordinal);\n        }\n        base += ar.maxDoc(); // no deletions, so we're ok\n      }\n      ordinalMap.addDone();\n    } finally {\n      r.close();\n    }\n  }\n  /**\n   * Mapping from old ordinal to new ordinals, used when merging indexes \n   * with separate taxonomies.\n   * <p> \n   * addToTaxonomies() merges one or more taxonomies into the given taxonomy\n   * (this). An OrdinalMap is filled for each of the added taxonomies,\n   * containing the new ordinal (in the merged taxonomy) of each of the\n   * categories in the old taxonomy.\n   * <P>  \n   * There exist two implementations of OrdinalMap: MemoryOrdinalMap and\n   * DiskOrdinalMap. As their names suggest, the former keeps the map in\n   * memory and the latter in a temporary disk file. Because these maps will\n   * later be needed one by one (to remap the counting lists), not all at the\n   * same time, it is recommended to put the first taxonomy's map in memory,\n   * and all the rest on disk (later to be automatically read into memory one\n   * by one, when needed).\n   */\n<fim_suffix>  public static interface OrdinalMap {\n    /**\n     * Set the size of the map. This MUST be called before addMapping().\n     * It is assumed (but not verified) that addMapping() will then be\n     * called exactly 'size' times, with different origOrdinals between 0\n     * and size-1.  \n     */\n    public void setSize(int size) throws IOException;\n    /** Record a mapping. */\n    public void addMapping(int origOrdinal, int newOrdinal) throws IOException;\n    /**\n     * Call addDone() to say that all addMapping() have been done.\n     * In some implementations this might free some resources. \n     */\n    public void addDone() throws IOException;\n    /**\n     * Return the map from the taxonomy's original (consecutive) ordinals\n     * to the new taxonomy's ordinals. If the map has to be read from disk\n     * and ordered appropriately, it is done when getMap() is called.\n     * getMap() should only be called once, and only when the map is actually\n     * needed. Calling it will also free all resources that the map might\n     * be holding (such as temporary disk space), other than the returned int[].\n     */\n    public int[] getMap() throws IOException;\n  }<fim_middle>// class below has no smell\n"}