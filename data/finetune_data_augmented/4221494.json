{"text": "<fim_prefix>/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage org.apache.cassandra.hadoop.cql3;\n\n\nimport java.io.IOException;\nimport java.nio.ByteBuffer;\nimport java.util.List;\nimport java.util.Map;\n\nimport org.apache.cassandra.hadoop.*;\nimport org.apache.hadoop.conf.*;\nimport org.apache.hadoop.mapreduce.*;\n\n/**\n * The <code>CqlOutputFormat</code> acts as a Hadoop-specific\n * OutputFormat that allows reduce tasks to store keys (and corresponding\n * bound variable values) as CQL rows (and respective columns) in a given\n * table.\n *\n * <p>\n * As is the case with the {@link org.apache.cassandra.hadoop.ColumnFamilyInputFormat}, \n * you need to set the prepared statement in your\n * Hadoop job Configuration. The {@link CqlConfigHelper} class, through its\n * {@link CqlConfigHelper#setOutputCql} method, is provided to make this\n * simple.\n * you need to set the Keyspace. The {@link ConfigHelper} class, through its\n * {@link ConfigHelper#setOutputColumnFamily} method, is provided to make this\n * simple.\n * </p>\n * \n * <p>\n * For the sake of performance, this class employs a lazy write-back caching\n * mechanism, where its record writer prepared statement binded variable values\n * created based on the reduce's inputs (in a task-specific map), and periodically \n * makes the changes official by sending a execution of prepared statement request \n * to Cassandra.\n * </p>\n */\n<fim_suffix>public class CqlOutputFormat extends OutputFormat<Map<String, ByteBuffer>, List<ByteBuffer>>\n        implements org.apache.hadoop.mapred.OutputFormat<Map<String, ByteBuffer>, List<ByteBuffer>>\n{\n    public static final String BATCH_THRESHOLD = \"mapreduce.output.columnfamilyoutputformat.batch.threshold\";\n    public static final String QUEUE_SIZE = \"mapreduce.output.columnfamilyoutputformat.queue.size\";\n\n    /**\n     * Check for validity of the output-specification for the job.\n     *\n     * @param context\n     *            information about the job\n     */\n    public void checkOutputSpecs(JobContext context)\n    {\n        checkOutputSpecs(HadoopCompat.getConfiguration(context));\n    }\n\n    protected void checkOutputSpecs(Configuration conf)\n    {\n        if (ConfigHelper.getOutputKeyspace(conf) == null)\n            throw new UnsupportedOperationException(\"You must set the keyspace with setOutputKeyspace()\");\n        if (ConfigHelper.getOutputPartitioner(conf) == null)\n            throw new UnsupportedOperationException(\"You must set the output partitioner to the one used by your Cassandra cluster\");\n        if (ConfigHelper.getOutputInitialAddress(conf) == null)\n            throw new UnsupportedOperationException(\"You must set the initial output address to a Cassandra node\");\n    }\n\n    /** Fills the deprecated OutputFormat interface for streaming. */\n    @Deprecated\n    public void checkOutputSpecs(org.apache.hadoop.fs.FileSystem filesystem, org.apache.hadoop.mapred.JobConf job) throws IOException\n    {\n        checkOutputSpecs(job);\n    }\n\n    /**\n     * The OutputCommitter for this format does not write any data to the DFS.\n     *\n     * @param context\n     *            the task context\n     * @return an output committer\n     * @throws IOException\n     * @throws InterruptedException\n     */\n    public OutputCommitter getOutputCommitter(TaskAttemptContext context) throws IOException, InterruptedException\n    {\n        return new NullOutputCommitter();\n    }\n\n    /** Fills the deprecated OutputFormat interface for streaming. */\n    @Deprecated\n    public CqlRecordWriter getRecordWriter(org.apache.hadoop.fs.FileSystem filesystem, org.apache.hadoop.mapred.JobConf job, String name, org.apache.hadoop.util.Progressable progress) throws IOException\n    {\n        return new CqlRecordWriter(job, progress);\n    }\n\n    /**\n     * Get the {@link RecordWriter} for the given task.\n     *\n     * @param context\n     *            the information about the current task.\n     * @return a {@link RecordWriter} to write the output for the job.\n     * @throws IOException\n     */\n    public CqlRecordWriter getRecordWriter(final TaskAttemptContext context) throws IOException, InterruptedException\n    {\n        return new CqlRecordWriter(context);\n    }\n\n    /**\n     * An {@link OutputCommitter} that does nothing.\n     */\n    private static class NullOutputCommitter extends OutputCommitter\n    {\n        public void abortTask(TaskAttemptContext taskContext) { }\n\n        public void cleanupJob(JobContext jobContext) { }\n\n        public void commitTask(TaskAttemptContext taskContext) { }\n\n        public boolean needsTaskCommit(TaskAttemptContext taskContext)\n        {\n            return false;\n        }\n\n        public void setupJob(JobContext jobContext) { }\n\n        public void setupTask(TaskAttemptContext taskContext) { }\n    }\n}<fim_middle>// class below has no smell\n"}