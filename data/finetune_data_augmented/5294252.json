{"text": "<fim_prefix>/* \n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n * \n *   http://www.apache.org/licenses/LICENSE-2.0\n * \n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.parquet.hadoop;\nimport static org.apache.parquet.Preconditions.checkNotNull;\nimport java.io.Closeable;\nimport java.io.IOException;\nimport java.util.ArrayList;\nimport java.util.Collections;\nimport java.util.Iterator;\nimport java.util.List;\nimport org.apache.hadoop.conf.Configuration;\nimport org.apache.hadoop.fs.FileStatus;\nimport org.apache.hadoop.fs.FileSystem;\nimport org.apache.hadoop.fs.Path;\nimport org.apache.parquet.ParquetReadOptions;\nimport org.apache.parquet.Preconditions;\nimport org.apache.parquet.compression.CompressionCodecFactory;\nimport org.apache.parquet.filter.UnboundRecordFilter;\nimport org.apache.parquet.filter2.compat.FilterCompat;\nimport org.apache.parquet.filter2.compat.FilterCompat.Filter;\nimport org.apache.parquet.hadoop.api.ReadSupport;\nimport org.apache.parquet.hadoop.util.HadoopInputFile;\nimport org.apache.parquet.HadoopReadOptions;\nimport org.apache.parquet.hadoop.util.HiddenFileFilter;\nimport org.apache.parquet.io.InputFile;\n/**\n * Read records from a Parquet file.\n * TODO: too many constructors (https://issues.apache.org/jira/browse/PARQUET-39)\n */\npublic class ParquetReader<T> implements Closeable {\n  private final ReadSupport<T> readSupport;\n  private final Iterator<InputFile> filesIterator;\n  private final ParquetReadOptions options;\n  private InternalParquetRecordReader<T> reader;\n  /**\n   * @param file the file to read\n   * @param readSupport to materialize records\n   * @throws IOException if there is an error while reading\n   * @deprecated use {@link #builder(ReadSupport, Path)}\n   */\n  @Deprecated\n  public ParquetReader(Path file, ReadSupport<T> readSupport) throws IOException {\n    this(new Configuration(), file, readSupport, FilterCompat.NOOP);\n  }\n  /**\n   * @param conf the configuration\n   * @param file the file to read\n   * @param readSupport to materialize records\n   * @throws IOException if there is an error while reading\n   * @deprecated use {@link #builder(ReadSupport, Path)}\n   */\n  @Deprecated\n  public ParquetReader(Configuration conf, Path file, ReadSupport<T> readSupport) throws IOException {\n    this(conf, file, readSupport, FilterCompat.NOOP);\n  }\n  /**\n   * @param file the file to read\n   * @param readSupport to materialize records\n   * @param unboundRecordFilter the filter to use to filter records\n   * @throws IOException if there is an error while reading\n   * @deprecated use {@link #builder(ReadSupport, Path)}\n   */\n  @Deprecated\n  public ParquetReader(Path file, ReadSupport<T> readSupport, UnboundRecordFilter unboundRecordFilter) throws IOException {\n    this(new Configuration(), file, readSupport, FilterCompat.get(unboundRecordFilter));\n  }\n  /**\n   * @param conf the configuration\n   * @param file the file to read\n   * @param readSupport to materialize records\n   * @param unboundRecordFilter the filter to use to filter records\n   * @throws IOException if there is an error while reading\n   * @deprecated use {@link #builder(ReadSupport, Path)}\n   */\n  @Deprecated\n  public ParquetReader(Configuration conf, Path file, ReadSupport<T> readSupport, UnboundRecordFilter unboundRecordFilter) throws IOException {\n    this(conf, file, readSupport, FilterCompat.get(unboundRecordFilter));\n  }\n  private ParquetReader(Configuration conf,\n                        Path file,\n                        ReadSupport<T> readSupport,\n                        FilterCompat.Filter filter) throws IOException {\n    this(Collections.singletonList((InputFile) HadoopInputFile.fromPath(file, conf)),\n        HadoopReadOptions.builder(conf)\n            .withRecordFilter(checkNotNull(filter, \"filter\"))\n            .build(),\n        readSupport);\n  }\n  private ParquetReader(List<InputFile> files,\n                        ParquetReadOptions options,\n                        ReadSupport<T> readSupport) throws IOException {\n    this.readSupport = readSupport;\n    this.options = options;\n    this.filesIterator = files.iterator();\n  }\n  /**\n   * @return the next record or null if finished\n   * @throws IOException if there is an error while reading\n   */\n  public T read() throws IOException {\n    try {\n      if (reader != null && reader.nextKeyValue()) {\n        return reader.getCurrentValue();\n      } else {\n        initReader();\n        return reader == null ? null : read();\n      }\n    } catch (InterruptedException e) {\n      throw new IOException(e);\n    }\n  }\n  private void initReader() throws IOException {\n    if (reader != null) {\n      reader.close();\n      reader = null;\n    }\n    if (filesIterator.hasNext()) {\n      InputFile file = filesIterator.next();\n      ParquetFileReader fileReader = ParquetFileReader.open(file, options);\n      reader = new InternalParquetRecordReader<>(readSupport, options.getRecordFilter());\n      reader.initialize(fileReader, options);\n    }\n  }\n  @Override\n  public void close() throws IOException {\n    if (reader != null) {\n      reader.close();\n    }\n  }\n  public static <T> Builder<T> read(InputFile file) throws IOException {\n    return new Builder<>(file);\n  }\n  public static <T> Builder<T> builder(ReadSupport<T> readSupport, Path path) {\n    return new Builder<>(readSupport, path);\n  }\n  public static class Builder<T> {\n    private final ReadSupport<T> readSupport;\n    private final InputFile file;\n    private final Path path;\n    private Filter filter = null;\n    protected Configuration conf;\n    private ParquetReadOptions.Builder optionsBuilder;\n    @Deprecated\n    private Builder(ReadSupport<T> readSupport, Path path) {\n      this.readSupport = checkNotNull(readSupport, \"readSupport\");\n      this.file = null;\n      this.path = checkNotNull(path, \"path\");\n      this.conf = new Configuration();\n      this.optionsBuilder = HadoopReadOptions.builder(conf);\n    }\n    @Deprecated\n    protected Builder(Path path) {\n      this.readSupport = null;\n      this.file = null;\n      this.path = checkNotNull(path, \"path\");\n      this.conf = new Configuration();\n      this.optionsBuilder = HadoopReadOptions.builder(conf);\n    }\n<fim_suffix>    protected Builder(InputFile file) {\n      this.readSupport = null;\n      this.file = checkNotNull(file, \"file\");\n      this.path = null;\n      if (file instanceof HadoopInputFile) {\n        this.conf = ((HadoopInputFile) file).getConfiguration();\n      } else {\n        this.conf = new Configuration();\n      }\n      optionsBuilder = HadoopReadOptions.builder(conf);\n    }\n    // when called, resets options to the defaults from conf\n    public Builder<T> withConf(Configuration conf) {\n      this.conf = checkNotNull(conf, \"conf\");\n      // previous versions didn't use the builder, so may set filter before conf. this maintains\n      // compatibility for filter. other options are reset by a new conf.\n      this.optionsBuilder = HadoopReadOptions.builder(conf);\n      if (filter != null) {\n        optionsBuilder.withRecordFilter(filter);\n      }\n      return this;\n    }\n    public Builder<T> withFilter(Filter filter) {\n      this.filter = filter;\n      optionsBuilder.withRecordFilter(filter);\n      return this;\n    }\n    public Builder<T> useSignedStringMinMax(boolean useSignedStringMinMax) {\n      optionsBuilder.useSignedStringMinMax(useSignedStringMinMax);\n      return this;\n    }\n    public Builder<T> useSignedStringMinMax() {\n      optionsBuilder.useSignedStringMinMax();\n      return this;\n    }\n    public Builder<T> useStatsFilter(boolean useStatsFilter) {\n      optionsBuilder.useStatsFilter(useStatsFilter);\n      return this;\n    }\n    public Builder<T> useStatsFilter() {\n      optionsBuilder.useStatsFilter();\n      return this;\n    }\n    public Builder<T> useDictionaryFilter(boolean useDictionaryFilter) {\n      optionsBuilder.useDictionaryFilter(useDictionaryFilter);\n      return this;\n    }<fim_middle>// function below has no smell\n"}