{"text": "<fim_prefix>            for (int pendingTx = inProgressTxRange[0].getDataFileId(); pendingTx <= inProgressTxRange[1].getDataFileId(); pendingTx++) {\n                if (journalToAdvance == pendingTx) {\n                    LOG.trace(\"Compaction target:{} blocked by inflight transaction records: {}\", journalToAdvance, inProgressTxRange);\n                    return true;\n                }\n            }\n        }\n        return false;\n    }\n    private void forwardAllAcks(Integer journalToRead, Set<Integer> journalLogsReferenced) throws IllegalStateException, IOException {\n        LOG.trace(\"Attempting to move all acks in journal:{} to the front. Referenced files:{}\", journalToRead, journalLogsReferenced);\n        DataFile forwardsFile = journal.reserveDataFile();\n        forwardsFile.setTypeCode(COMPACTED_JOURNAL_FILE);\n        LOG.trace(\"Reserved file for forwarded acks: {}\", forwardsFile);\n        Map<Integer, Set<Integer>> updatedAckLocations = new HashMap<>();\n        try (TargetedDataFileAppender appender = new TargetedDataFileAppender(journal, forwardsFile);) {\n            KahaRewrittenDataFileCommand compactionMarker = new KahaRewrittenDataFileCommand();\n            compactionMarker.setSourceDataFileId(journalToRead);\n            compactionMarker.setRewriteType(forwardsFile.getTypeCode());\n            ByteSequence payload = toByteSequence(compactionMarker);\n            appender.storeItem(payload, Journal.USER_RECORD_TYPE, false);\n            LOG.trace(\"Marked ack rewrites file as replacing file: {}\", journalToRead);\n            final Location limit = new Location(journalToRead + 1, 0);\n            Location nextLocation = getNextLocationForAckForward(new Location(journalToRead, 0), limit);\n            while (nextLocation != null) {\n                JournalCommand<?> command = null;\n                try {\n                    command = load(nextLocation);\n                } catch (IOException ex) {\n                    LOG.trace(\"Error loading command during ack forward: {}\", nextLocation);\n                }\n                if (shouldForward(command)) {\n                    payload = toByteSequence(command);\n                    Location location = appender.storeItem(payload, Journal.USER_RECORD_TYPE, false);\n                    updatedAckLocations.put(location.getDataFileId(), journalLogsReferenced);\n                }\n                nextLocation = getNextLocationForAckForward(nextLocation, limit);\n            }\n        }\n        LOG.trace(\"ACKS forwarded, updates for ack locations: {}\", updatedAckLocations);\n        // Lock index while we update the ackMessageFileMap.\n        indexLock.writeLock().lock();\n        // Update the ack map with the new locations of the acks\n        for (Entry<Integer, Set<Integer>> entry : updatedAckLocations.entrySet()) {\n            Set<Integer> referenceFileIds = metadata.ackMessageFileMap.get(entry.getKey());\n            if (referenceFileIds == null) {\n                referenceFileIds = new HashSet<>();\n                referenceFileIds.addAll(entry.getValue());\n                metadata.ackMessageFileMap.put(entry.getKey(), referenceFileIds);\n                metadata.ackMessageFileMapDirtyFlag.lazySet(true);\n            } else {\n                referenceFileIds.addAll(entry.getValue());\n            }\n        }\n        // remove the old location data from the ack map so that the old journal log file can\n        // be removed on next GC.\n        metadata.ackMessageFileMap.remove(journalToRead);\n        metadata.ackMessageFileMapDirtyFlag.lazySet(true);\n        indexLock.writeLock().unlock();\n        LOG.trace(\"ACK File Map following updates: {}\", metadata.ackMessageFileMap);\n    }\n    private boolean shouldForward(JournalCommand<?> command) {\n        boolean result = false;\n        if (command != null) {\n            if (command instanceof KahaRemoveMessageCommand) {\n                result = true;\n            } else if (command instanceof KahaCommitCommand) {\n                KahaCommitCommand kahaCommitCommand = (KahaCommitCommand) command;\n                if (kahaCommitCommand.hasTransactionInfo() && kahaCommitCommand.getTransactionInfo().hasXaTransactionId()) {\n                    result = true;\n                }\n            }\n        }\n        return result;\n    }\n    private Location getNextLocationForAckForward(final Location nextLocation, final Location limit) {\n        //getNextLocation() can throw an IOException, we should handle it and set\n        //nextLocation to null and abort gracefully\n        //Should not happen in the normal case\n        Location location = null;\n        try {\n            location = journal.getNextLocation(nextLocation, limit);\n        } catch (IOException e) {\n            LOG.warn(\"Failed to load next journal location after: {}, reason: {}\", nextLocation, e);\n            if (LOG.isDebugEnabled()) {\n                LOG.debug(\"Failed to load next journal location after: {}\", nextLocation, e);\n            }\n        }\n        return location;\n    }\n    final Runnable nullCompletionCallback = new Runnable() {\n        @Override\n        public void run() {\n        }\n    };\n    private Location checkpointProducerAudit() throws IOException {\n        if (metadata.producerSequenceIdTracker == null || metadata.producerSequenceIdTracker.modified()) {\n            ByteArrayOutputStream baos = new ByteArrayOutputStream();\n            ObjectOutputStream oout = new ObjectOutputStream(baos);\n            oout.writeObject(metadata.producerSequenceIdTracker);\n            oout.flush();\n            oout.close();\n            // using completion callback allows a disk sync to be avoided when enableJournalDiskSyncs = false\n            Location location = store(new KahaProducerAuditCommand().setAudit(new Buffer(baos.toByteArray())), nullCompletionCallback);\n            try {\n                location.getLatch().await();\n                if (location.getException().get() != null) {\n                    throw location.getException().get();\n                }\n            } catch (InterruptedException e) {\n                throw new InterruptedIOException(e.toString());\n            }\n            return location;\n        }\n        return metadata.producerSequenceIdTrackerLocation;\n    }\n    private Location checkpointAckMessageFileMap() throws IOException {\n        ByteArrayOutputStream baos = new ByteArrayOutputStream();\n        ObjectOutputStream oout = new ObjectOutputStream(baos);\n        oout.writeObject(metadata.ackMessageFileMap);\n        oout.flush();\n        oout.close();\n        // using completion callback allows a disk sync to be avoided when enableJournalDiskSyncs = false\n        Location location = store(new KahaAckMessageFileMapCommand().setAckMessageFileMap(new Buffer(baos.toByteArray())), nullCompletionCallback);\n        try {\n            location.getLatch().await();\n        } catch (InterruptedException e) {\n            throw new InterruptedIOException(e.toString());\n        }\n        return location;\n    }\n    private Location checkpointSubscriptionCommand(KahaSubscriptionCommand subscription) throws IOException {\n        ByteSequence sequence = toByteSequence(subscription);\n        Location location = journal.write(sequence, nullCompletionCallback) ;\n        try {\n            location.getLatch().await();\n        } catch (InterruptedException e) {\n            throw new InterruptedIOException(e.toString());\n        }\n        return location;\n    }\n    public HashSet<Integer> getJournalFilesBeingReplicated() {\n        return journalFilesBeingReplicated;\n    }\n    // /////////////////////////////////////////////////////////////////\n    // StoredDestination related implementation methods.\n    // /////////////////////////////////////////////////////////////////\n    protected final HashMap<String, StoredDestination> storedDestinations = new HashMap<>();\n    static class MessageKeys {\n        final String messageId;\n        final Location location;\n        public MessageKeys(String messageId, Location location) {\n            this.messageId=messageId;\n            this.location=location;\n        }\n        @Override\n        public String toString() {\n            return \"[\"+messageId+\",\"+location+\"]\";\n        }\n    }\n    protected class MessageKeysMarshaller extends VariableMarshaller<MessageKeys> {\n        final LocationSizeMarshaller locationSizeMarshaller = new LocationSizeMarshaller();\n        @Override\n        public MessageKeys readPayload(DataInput dataIn) throws IOException {\n            return new MessageKeys(dataIn.readUTF(), locationSizeMarshaller.readPayload(dataIn));\n        }\n        @Override\n        public void writePayload(MessageKeys object, DataOutput dataOut) throws IOException {\n            dataOut.writeUTF(object.messageId);\n            locationSizeMarshaller.writePayload(object.location, dataOut);\n        }\n    }\n<fim_suffix>    class LastAck {\n        long lastAckedSequence;\n        byte priority;\n        public LastAck(LastAck source) {\n            this.lastAckedSequence = source.lastAckedSequence;\n            this.priority = source.priority;\n        }\n        public LastAck() {\n            this.priority = MessageOrderIndex.HI;\n        }\n        public LastAck(long ackLocation) {\n            this.lastAckedSequence = ackLocation;\n            this.priority = MessageOrderIndex.LO;\n        }\n        public LastAck(long ackLocation, byte priority) {\n            this.lastAckedSequence = ackLocation;\n            this.priority = priority;\n        }\n        @Override\n        public String toString() {\n            return \"[\" + lastAckedSequence + \":\" + priority + \"]\";\n        }\n    }<fim_middle>// class below is data class\n"}