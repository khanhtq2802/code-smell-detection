{"text": "<fim_prefix>              shufflingReduceTasks++;\n              break;\n            }\n          }\n        }\n      }\n      JobTaskAttemptFetchFailureEvent fetchfailureEvent = \n        (JobTaskAttemptFetchFailureEvent) event;\n      for (org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId mapId : \n            fetchfailureEvent.getMaps()) {\n        Integer fetchFailures = job.fetchFailuresMapping.get(mapId);\n        fetchFailures = (fetchFailures == null) ? 1 : (fetchFailures+1);\n        job.fetchFailuresMapping.put(mapId, fetchFailures);\n        float failureRate = shufflingReduceTasks == 0 ? 1.0f : \n          (float) fetchFailures / shufflingReduceTasks;\n        // declare faulty if fetch-failures >= max-allowed-failures\n        if (fetchFailures >= job.getMaxFetchFailuresNotifications()\n            && failureRate >= job.getMaxAllowedFetchFailuresFraction()) {\n          LOG.info(\"Too many fetch-failures for output of task attempt: \" + \n              mapId + \" ... raising fetch failure to map\");\n          job.eventHandler.handle(new TaskAttemptEvent(mapId, \n              TaskAttemptEventType.TA_TOO_MANY_FETCH_FAILURE));\n          job.fetchFailuresMapping.remove(mapId);\n        }\n      }\n    }\n  }\n  private static class TaskCompletedTransition implements\n      MultipleArcTransition<JobImpl, JobEvent, JobStateInternal> {\n    @Override\n    public JobStateInternal transition(JobImpl job, JobEvent event) {\n      job.completedTaskCount++;\n      LOG.info(\"Num completed Tasks: \" + job.completedTaskCount);\n      JobTaskEvent taskEvent = (JobTaskEvent) event;\n      Task task = job.tasks.get(taskEvent.getTaskID());\n      if (taskEvent.getState() == TaskState.SUCCEEDED) {\n        taskSucceeded(job, task);\n      } else if (taskEvent.getState() == TaskState.FAILED) {\n        taskFailed(job, task);\n      } else if (taskEvent.getState() == TaskState.KILLED) {\n        taskKilled(job, task);\n      }\n      return checkJobAfterTaskCompletion(job);\n    }\n    //This class is used to queue a ScheduledFuture to send an event to a job\n    //after some delay. This can be used to wait for maximum amount of time\n    //before proceeding anyway. e.g. When a job is waiting in FAIL_WAIT for\n    //all tasks to be killed.\n    static class TriggerScheduledFuture implements Runnable {\n      JobEvent toSend;\n      JobImpl job;\n      TriggerScheduledFuture(JobImpl job, JobEvent toSend) {\n        this.toSend = toSend;\n        this.job = job;\n      }\n      public void run() {\n        LOG.info(\"Sending event \" + toSend + \" to \" + job.getID());\n        job.getEventHandler().handle(toSend);\n      }\n    }\n    protected JobStateInternal checkJobAfterTaskCompletion(JobImpl job) {\n      //check for Job failure\n      if (job.failedMapTaskCount*100 > \n        job.allowedMapFailuresPercent*job.numMapTasks ||\n        job.failedReduceTaskCount*100 > \n        job.allowedReduceFailuresPercent*job.numReduceTasks) {\n        job.setFinishTime();\n        String diagnosticMsg = \"Job failed as tasks failed. \" +\n            \"failedMaps:\" + job.failedMapTaskCount + \n            \" failedReduces:\" + job.failedReduceTaskCount;\n        LOG.info(diagnosticMsg);\n        job.addDiagnostic(diagnosticMsg);\n        //Send kill signal to all unfinished tasks here.\n        boolean allDone = true;\n        for (Task task : job.tasks.values()) {\n          if(!task.isFinished()) {\n            allDone = false;\n            job.eventHandler.handle(\n              new TaskEvent(task.getID(), TaskEventType.T_KILL));\n          }\n        }\n        //If all tasks are already done, we should go directly to FAIL_ABORT\n        if(allDone) {\n          job.eventHandler.handle(new CommitterJobAbortEvent(job.jobId,\n            job.jobContext, org.apache.hadoop.mapreduce.JobStatus.State.FAILED)\n          );\n          return JobStateInternal.FAIL_ABORT;\n        }\n        //Set max timeout to wait for the tasks to get killed\n        job.failWaitTriggerScheduledFuture = job.executor.schedule(\n          new TriggerScheduledFuture(job, new JobEvent(job.getID(),\n            JobEventType.JOB_FAIL_WAIT_TIMEDOUT)), job.conf.getInt(\n                MRJobConfig.MR_AM_COMMITTER_CANCEL_TIMEOUT_MS,\n                MRJobConfig.DEFAULT_MR_AM_COMMITTER_CANCEL_TIMEOUT_MS),\n                TimeUnit.MILLISECONDS);\n        return JobStateInternal.FAIL_WAIT;\n      }\n      return job.checkReadyForCommit();\n    }\n    private void taskSucceeded(JobImpl job, Task task) {\n      if (task.getType() == TaskType.MAP) {\n        job.succeededMapTaskCount++;\n      } else {\n        job.succeededReduceTaskCount++;\n      }\n      job.metrics.completedTask(task);\n    }\n    private void taskFailed(JobImpl job, Task task) {\n      if (task.getType() == TaskType.MAP) {\n        job.failedMapTaskCount++;\n      } else if (task.getType() == TaskType.REDUCE) {\n        job.failedReduceTaskCount++;\n      }\n      job.addDiagnostic(\"Task failed \" + task.getID());\n      job.metrics.failedTask(task);\n    }\n    private void taskKilled(JobImpl job, Task task) {\n      if (task.getType() == TaskType.MAP) {\n        job.killedMapTaskCount++;\n      } else if (task.getType() == TaskType.REDUCE) {\n        job.killedReduceTaskCount++;\n      }\n      job.metrics.killedTask(task);\n    }\n  }\n  // Transition class for handling jobs with no tasks\n  private static class JobNoTasksCompletedTransition implements\n  MultipleArcTransition<JobImpl, JobEvent, JobStateInternal> {\n    @Override\n    public JobStateInternal transition(JobImpl job, JobEvent event) {\n      return job.checkReadyForCommit();\n    }\n  }\n  private static class CommitSucceededTransition implements\n      SingleArcTransition<JobImpl, JobEvent> {\n    @Override\n    public void transition(JobImpl job, JobEvent event) {\n      job.logJobHistoryFinishedEvent();\n      job.finished(JobStateInternal.SUCCEEDED);\n    }\n  }\n  private static class CommitFailedTransition implements\n      SingleArcTransition<JobImpl, JobEvent> {\n    @Override\n    public void transition(JobImpl job, JobEvent event) {\n      JobCommitFailedEvent jcfe = (JobCommitFailedEvent)event;\n      job.addDiagnostic(\"Job commit failed: \" + jcfe.getMessage());\n      job.eventHandler.handle(new CommitterJobAbortEvent(job.jobId,\n          job.jobContext,\n          org.apache.hadoop.mapreduce.JobStatus.State.FAILED));\n    }\n  }\n  private static class KilledDuringCommitTransition implements\n      SingleArcTransition<JobImpl, JobEvent> {\n    @Override\n    public void transition(JobImpl job, JobEvent event) {\n      job.setFinishTime();\n      job.eventHandler.handle(new CommitterJobAbortEvent(job.jobId,\n          job.jobContext,\n          org.apache.hadoop.mapreduce.JobStatus.State.KILLED));\n    }\n  }\n  private static class KilledDuringAbortTransition implements\n      SingleArcTransition<JobImpl, JobEvent> {\n    @Override\n    public void transition(JobImpl job, JobEvent event) {\n      job.unsuccessfulFinish(JobStateInternal.KILLED);\n    }\n  }\n  private static class MapTaskRescheduledTransition implements\n      SingleArcTransition<JobImpl, JobEvent> {\n    @Override\n    public void transition(JobImpl job, JobEvent event) {\n      //succeeded map task is restarted back\n      job.completedTaskCount--;\n      job.succeededMapTaskCount--;\n    }\n  }\n  private static class KillWaitTaskCompletedTransition extends  \n      TaskCompletedTransition {\n    @Override\n    protected JobStateInternal checkJobAfterTaskCompletion(JobImpl job) {\n      if (job.completedTaskCount == job.tasks.size()) {\n        job.setFinishTime();\n        job.eventHandler.handle(new CommitterJobAbortEvent(job.jobId,\n            job.jobContext,\n            org.apache.hadoop.mapreduce.JobStatus.State.KILLED));\n        return JobStateInternal.KILL_ABORT;\n      }\n      //return the current state, Job not finished yet\n      return job.getInternalState();\n    }\n  }\n  protected void addDiagnostic(String diag) {\n    diagnostics.add(diag);\n  }\n  private static class DiagnosticsUpdateTransition implements\n      SingleArcTransition<JobImpl, JobEvent> {\n<fim_suffix>    @Override\n    public void transition(JobImpl job, JobEvent event) {\n      job.addDiagnostic(((JobDiagnosticsUpdateEvent) event)\n          .getDiagnosticUpdate());\n    }<fim_middle>// function below has no smell\n"}