{"text": "<fim_prefix>/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n*/\npackage org.apache.kylin.job.impl.threadpool;\nimport java.io.Closeable;\nimport java.io.IOException;\nimport java.util.Locale;\nimport java.util.Set;\nimport java.util.concurrent.CopyOnWriteArraySet;\nimport java.util.concurrent.ExecutorService;\nimport java.util.concurrent.Executors;\nimport java.util.concurrent.ScheduledExecutorService;\nimport java.util.concurrent.SynchronousQueue;\nimport java.util.concurrent.ThreadPoolExecutor;\nimport java.util.concurrent.TimeUnit;\nimport org.apache.kylin.common.KylinConfig;\nimport org.apache.kylin.common.lock.DistributedLock;\nimport org.apache.kylin.common.util.SetThreadName;\nimport org.apache.kylin.common.util.StringUtil;\nimport org.apache.kylin.job.Scheduler;\nimport org.apache.kylin.job.engine.JobEngineConfig;\nimport org.apache.kylin.job.exception.ExecuteException;\nimport org.apache.kylin.job.exception.PersistentException;\nimport org.apache.kylin.job.exception.SchedulerException;\nimport org.apache.kylin.job.execution.AbstractExecutable;\nimport org.apache.kylin.job.execution.DefaultChainedExecutable;\nimport org.apache.kylin.job.execution.Executable;\nimport org.apache.kylin.job.execution.ExecutableManager;\nimport org.apache.kylin.job.execution.ExecutableState;\nimport org.apache.kylin.job.execution.Output;\nimport org.apache.kylin.job.lock.JobLock;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport com.google.common.collect.Maps;\n/**\n * schedule the cubing jobs when several job server running with the same metadata.\n *\n * to enable the distributed job server, you need to set and update three configs in the kylin.properties:\n *  1. kylin.job.scheduler.default=2\n *  2. add all the job servers and query servers to the kylin.server.cluster-servers\n */\npublic class DistributedScheduler implements Scheduler<AbstractExecutable> {\n    private static final Logger logger = LoggerFactory.getLogger(DistributedScheduler.class);\n    public static final String ZOOKEEPER_LOCK_PATH = \"/job_engine/lock\"; // note ZookeeperDistributedLock will ensure zk path prefix: /${kylin.env.zookeeper-base-path}/metadata\n    public static DistributedScheduler getInstance(KylinConfig config) {\n        return config.getManager(DistributedScheduler.class);\n    }\n    // called by reflection\n    static DistributedScheduler newInstance(KylinConfig config) throws IOException {\n        return new DistributedScheduler();\n    }\n    // ============================================================================\n    private ExecutableManager executableManager;\n    private FetcherRunner fetcher;\n    private ScheduledExecutorService fetcherPool;\n    private ExecutorService watchPool;\n    private ExecutorService jobPool;\n    private DefaultContext context;\n    private DistributedLock jobLock;\n    private Closeable lockWatch;\n    //keep all running job\n    private final Set<String> jobWithLocks = new CopyOnWriteArraySet<>();\n    private volatile boolean initialized = false;\n    private volatile boolean hasStarted = false;\n    private JobEngineConfig jobEngineConfig;\n    private String serverName;\n<fim_suffix>    private class JobRunner implements Runnable {\n        private final AbstractExecutable executable;\n        public JobRunner(AbstractExecutable executable) {\n            this.executable = executable;\n        }\n        @Override\n        public void run() {\n            try (SetThreadName ignored = new SetThreadName(\"Scheduler %s Job %s\",\n                    System.identityHashCode(DistributedScheduler.this), executable.getId())) {\n                if (jobLock.lock(getLockPath(executable.getId()))) {\n                    logger.info(executable.toString() + \" scheduled in server: \" + serverName);\n                    context.addRunningJob(executable);\n                    jobWithLocks.add(executable.getId());\n                    executable.execute(context);\n                }\n            } catch (ExecuteException e) {\n                logger.error(\"ExecuteException job:\" + executable.getId() + \" in server: \" + serverName, e);\n            } catch (Exception e) {\n                logger.error(\"unknown error execute job:\" + executable.getId() + \" in server: \" + serverName, e);\n            } finally {\n                context.removeRunningJob(executable);\n                releaseJobLock(executable);\n                // trigger the next step asap\n                fetcherPool.schedule(fetcher, 0, TimeUnit.SECONDS);\n            }\n        }\n        //release job lock when job state is ready or running and the job server keep the cube lock.\n        private void releaseJobLock(AbstractExecutable executable) {\n            if (executable instanceof DefaultChainedExecutable) {\n                ExecutableState state = executable.getStatus();\n                if (state != ExecutableState.READY && state != ExecutableState.RUNNING) {\n                    if (jobWithLocks.contains(executable.getId())) {\n                        logger.info(\n                                executable.toString() + \" will release the lock for the job: \" + executable.getId());\n                        jobLock.unlock(getLockPath(executable.getId()));\n                        jobWithLocks.remove(executable.getId());\n                    }\n                }\n            }\n        }\n    }\n    //when the job lock released but the related job still running, resume the job.\n    private class WatcherProcessImpl implements DistributedLock.Watcher {\n        private String serverName;\n        public WatcherProcessImpl(String serverName) {\n            this.serverName = serverName;\n        }\n        @Override\n        public void onUnlock(String path, String nodeData) {\n            String[] paths = StringUtil.split(path, \"/\");\n            String jobId = paths[paths.length - 1];\n            // Sync execute cache in case broadcast not available\n            try {\n                executableManager.syncDigestsOfJob(jobId);\n            } catch (PersistentException e) {\n                logger.error(\"Failed to sync cache of job: \" + jobId + \", at server: \" + serverName);\n            }\n            final Output output = executableManager.getOutput(jobId);\n            if (output.getState() == ExecutableState.RUNNING) {\n                AbstractExecutable executable = executableManager.getJob(jobId);\n                if (executable instanceof DefaultChainedExecutable && !nodeData.equalsIgnoreCase(serverName)) {\n                    try {\n                        logger.warn(nodeData + \" has released the lock for: \" + jobId\n                                + \" but the job still running. so \" + serverName + \" resume the job\");\n                        if (!jobLock.isLocked(getLockPath(jobId))) {\n                            executableManager.resumeRunningJobForce(executable.getId());\n                            fetcherPool.schedule(fetcher, 0, TimeUnit.SECONDS);\n                        }\n                    } catch (Exception e) {\n                        logger.error(\"resume the job but fail in server: \" + serverName, e);\n                    }\n                }\n            }\n        }\n        @Override\n        public void onLock(String lockPath, String client) {\n        }\n    }\n    @Override\n    public synchronized void init(JobEngineConfig jobEngineConfig, JobLock jobLock) throws SchedulerException {\n        String serverMode = jobEngineConfig.getConfig().getServerMode();\n        if (!(\"job\".equals(serverMode.toLowerCase(Locale.ROOT)) || \"all\".equals(serverMode.toLowerCase(Locale.ROOT)))) {\n            logger.info(\"server mode: \" + serverMode + \", no need to run job scheduler\");\n            return;\n        }\n        logger.info(\"Initializing Job Engine ....\");\n        if (!initialized) {\n            initialized = true;\n        } else {\n            return;\n        }\n        this.jobEngineConfig = jobEngineConfig;\n        this.jobLock = (DistributedLock) jobLock;\n        this.serverName = this.jobLock.getClient(); // the lock's client string contains node name of this server\n        executableManager = ExecutableManager.getInstance(jobEngineConfig.getConfig());\n        //load all executable, set them to a consistent status\n        fetcherPool = Executors.newScheduledThreadPool(1);\n        //watch the zookeeper node change, so that when one job server is down, other job servers can take over.\n        watchPool = Executors.newFixedThreadPool(1);\n        WatcherProcessImpl watcherProcess = new WatcherProcessImpl(this.serverName);\n        lockWatch = this.jobLock.watchLocks(getWatchPath(), watchPool, watcherProcess);\n        int corePoolSize = jobEngineConfig.getMaxConcurrentJobLimit();<fim_middle>// class below has no smell\n"}