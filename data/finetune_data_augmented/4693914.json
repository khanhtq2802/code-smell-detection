{"text": "<fim_prefix>import org.apache.helix.controller.LogUtil;\nimport org.apache.helix.model.ResourceAssignment;\nimport org.apache.helix.model.ResourceConfig;\nimport org.apache.helix.task.AssignableInstanceManager;\nimport org.apache.helix.task.JobConfig;\nimport org.apache.helix.task.JobContext;\nimport org.apache.helix.task.RuntimeJobDag;\nimport org.apache.helix.task.Task;\nimport org.apache.helix.task.TaskConstants;\nimport org.apache.helix.task.WorkflowConfig;\nimport org.apache.helix.task.WorkflowContext;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n/**\n * Cache for holding all task related cluster data, such as WorkflowConfig, JobConfig and Contexts.\n */\npublic class TaskDataCache extends AbstractDataCache {\n  private static final Logger LOG = LoggerFactory.getLogger(TaskDataCache.class.getName());\n  private static final String NAME = \"NAME\";\n  private Map<String, JobConfig> _jobConfigMap = new HashMap<>();\n  private Map<String, RuntimeJobDag> _runtimeJobDagMap = new HashMap<>();\n  private Map<String, WorkflowConfig> _workflowConfigMap = new ConcurrentHashMap<>();\n  // TODO: context and previous assignment should be wrapped into a class. Otherwise, int the future,\n  // concurrency will be hard to handle.\n  private Map<String, ZNRecord> _contextMap = new HashMap<>();\n  private Map<String, ZNRecord> _prevAssignmentMap = new HashMap<>();\n  private Set<String> _prevAssignmentToUpdate = new HashSet<>();\n  private Set<String> _prevAssignmentToRemove = new HashSet<>();\n  private Set<String> _contextToUpdate = new HashSet<>();\n  private Set<String> _contextToRemove = new HashSet<>();\n  // The following fields have been added for quota-based task scheduling\n  private final AssignableInstanceManager _assignableInstanceManager =\n      new AssignableInstanceManager();\n  // Current usage for this scheduled jobs is used for differentiate the jobs has been processed in\n  // JobDispatcher from RESOURCE_TO_BALANCE to reduce the redundant computation.\n  private Set<String> _dispatchedJobs = new HashSet<>();\n  private enum TaskDataType {\n    CONTEXT,\n    PREV_ASSIGNMENT\n  }\n  public TaskDataCache(ControlContextProvider contextProvider) {\n    super(contextProvider);\n  }\n  /**\n   * Original constructor for TaskDataCache.\n   *\n   * @param clusterName\n   */\n  public TaskDataCache(String clusterName) {\n    this(createDefaultControlContextProvider(clusterName));\n  }\n  /**\n   * This refreshes the cluster data by re-fetching the data from zookeeper in an efficient way\n   *\n   * @param accessor\n   *\n   * @return\n   */\n  public synchronized boolean refresh(HelixDataAccessor accessor,\n      Map<String, ResourceConfig> resourceConfigMap) {\n    refreshContextsAndPreviousAssignments(accessor);\n    // update workflow and job configs.\n    _workflowConfigMap.clear();\n    Map<String, JobConfig> newJobConfigs = new HashMap<>();\n    Set<String> workflowsUpdated = new HashSet<>();\n    for (Map.Entry<String, ResourceConfig> entry : resourceConfigMap.entrySet()) {\n      if (entry.getValue().getRecord().getSimpleFields()\n          .containsKey(WorkflowConfig.WorkflowConfigProperty.Dag.name())) {\n        _workflowConfigMap.put(entry.getKey(), new WorkflowConfig(entry.getValue()));\n        if (!_runtimeJobDagMap.containsKey(entry.getKey())) {\n          WorkflowConfig workflowConfig = _workflowConfigMap.get(entry.getKey());\n          _runtimeJobDagMap.put(entry.getKey(), new RuntimeJobDag(workflowConfig.getJobDag(),\n              workflowConfig.isJobQueue() || !workflowConfig.isTerminable(),\n              workflowConfig.getParallelJobs()));\n        }\n      } else if (entry.getValue().getRecord().getSimpleFields()\n          .containsKey(WorkflowConfig.WorkflowConfigProperty.WorkflowID.name())) {\n        newJobConfigs.put(entry.getKey(), new JobConfig(entry.getValue()));\n      }\n    }\n    // The following 3 blocks is for finding a list of workflows whose JobDAGs have been changed\n    // because their RuntimeJobDags would need to be re-built\n    // newly added jobs\n    for (String jobName : newJobConfigs.keySet()) {\n      if (!_jobConfigMap.containsKey(jobName) && newJobConfigs.get(jobName).getWorkflow() != null) {\n        workflowsUpdated.add(newJobConfigs.get(jobName).getWorkflow());\n      }\n    }\n    // Removed jobs\n    for (String jobName : _jobConfigMap.keySet()) {\n      if (!newJobConfigs.containsKey(jobName) && _jobConfigMap.get(jobName).getWorkflow() != null) {\n        workflowsUpdated.add(_jobConfigMap.get(jobName).getWorkflow());\n      }\n    }\n    // Combine all the workflows' job dag which need update\n    for (String changedWorkflow : workflowsUpdated) {\n      if (_workflowConfigMap.containsKey(changedWorkflow)) {\n        WorkflowConfig workflowConfig = _workflowConfigMap.get(changedWorkflow);\n        _runtimeJobDagMap.put(changedWorkflow, new RuntimeJobDag(workflowConfig.getJobDag(),\n            workflowConfig.isJobQueue() || !workflowConfig.isTerminable(),\n            workflowConfig.getParallelJobs()));\n      }\n    }\n    _dispatchedJobs.clear();\n    _runtimeJobDagMap.keySet().retainAll(_workflowConfigMap.keySet());\n    _jobConfigMap = newJobConfigs;\n    return true;\n  }\n  private void refreshContextsAndPreviousAssignments(HelixDataAccessor accessor) {\n    // TODO: Need an optimize for reading context only if the refresh is needed.\n    long start = System.currentTimeMillis();\n    _contextMap.clear();\n    _prevAssignmentMap.clear();\n    if (_controlContextProvider.getClusterName() == null || _controlContextProvider.getClusterName()\n        .equalsIgnoreCase(UNKNOWN_CLUSTER)) {\n      return;\n    }\n    String path = String.format(\"/%s/%s%s\", _controlContextProvider.getClusterName(),\n        PropertyType.PROPERTYSTORE.name(), TaskConstants.REBALANCER_CONTEXT_ROOT);\n    List<String> contextPaths = new ArrayList<>();\n    List<String> prevAssignmentPaths = new ArrayList<>();\n    List<String> childNames = accessor.getBaseDataAccessor().getChildNames(path, 0);\n    if (childNames == null) {\n      return;\n    }\n    for (String resourceName : childNames) {\n      contextPaths.add(getTaskDataPath(resourceName, TaskDataType.CONTEXT));\n      prevAssignmentPaths.add(getTaskDataPath(resourceName, TaskDataType.PREV_ASSIGNMENT));\n    }\n    List<ZNRecord> contexts = accessor.getBaseDataAccessor().get(contextPaths, null, 0);\n    List<ZNRecord> prevAssignments =\n        accessor.getBaseDataAccessor().get(prevAssignmentPaths, null, 0);\n    for (int i = 0; i < contexts.size(); i++) {\n      ZNRecord context = contexts.get(i);\n      if (context != null && context.getSimpleField(NAME) != null) {\n        _contextMap.put(context.getSimpleField(NAME), context);\n      } else {\n        _contextMap.put(childNames.get(i), context);\n        LogUtil.logDebug(LOG, genEventInfo(),\n            String.format(\"Context for %s is null or miss the context NAME!\", childNames.get((i))));\n      }\n    }\n    for (ZNRecord prevAssignment : prevAssignments) {\n      if (prevAssignment != null) {\n        _prevAssignmentMap.put(prevAssignment.getId(), prevAssignment);\n      }\n    }\n    if (LOG.isDebugEnabled()) {\n      LogUtil.logDebug(LOG, genEventInfo(),\n          \"# of workflow/job context read from zk: \" + _contextMap.size() + \". Take \" + (\n              System.currentTimeMillis() - start) + \" ms\");\n    }\n  }\n  /**\n   * Returns job config map\n   *\n   * @return\n   */\n  public Map<String, JobConfig> getJobConfigMap() {\n    return _jobConfigMap;\n  }\n  /**\n   * Returns job config\n   *\n   * @param resource\n   *\n   * @return\n   */\n  public JobConfig getJobConfig(String resource) {\n    return _jobConfigMap.get(resource);\n  }\n  /**\n   * Returns workflow config map\n   *\n   * @return\n   */\n  public Map<String, WorkflowConfig> getWorkflowConfigMap() {\n    return _workflowConfigMap;\n  }\n  /**\n   * Returns workflow config\n   *\n   * @param resource\n   *\n   * @return\n   */\n  public WorkflowConfig getWorkflowConfig(String resource) {\n    return _workflowConfigMap.get(resource);\n  }\n  /**\n   * Return the JobContext by resource name\n   *\n   * @param resourceName\n   *\n   * @return\n   */\n<fim_suffix>  public JobContext getJobContext(String resourceName) {\n    if (_contextMap.containsKey(resourceName) && _contextMap.get(resourceName) != null) {\n      return new JobContext(_contextMap.get(resourceName));\n    }\n    return null;\n  }<fim_middle>// function below has no smell\n"}