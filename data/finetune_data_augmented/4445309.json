{"text": "<fim_prefix>  private String lastDirectory = null;\n  private Configuration fsConf = null;\n  private FormatPlugin formatPlugin = null;\n  private String nextField = null;\n  private DrillStatsTable.TableStatistics statistics;\n  private List<DrillStatsTable.ColumnStatistics> columnStatisticsList = new ArrayList<DrillStatsTable.ColumnStatistics>();\n  private DrillStatsTable.ColumnStatistics columnStatistics;\n  private LocalDate dirComputedTime = null;\n  private Path fileName = null;\n  private String queryId = null;\n  private long recordsWritten = -1;\n  private boolean errStatus = false;\n  public JsonStatisticsRecordWriter(Configuration fsConf, FormatPlugin formatPlugin){\n    this.fsConf = fsConf;\n    this.formatPlugin = formatPlugin;\n  }\n  @Override\n  public void init(Map<String, String> writerOptions) throws IOException {\n    this.location = writerOptions.get(\"location\");\n    this.prefix = writerOptions.get(\"prefix\");\n    this.fieldDelimiter = writerOptions.get(\"separator\");\n    this.extension = writerOptions.get(\"extension\");\n    this.useExtendedOutput = Boolean.parseBoolean(writerOptions.get(\"extended\"));\n    this.skipNullFields = Boolean.parseBoolean(writerOptions.get(\"skipnulls\"));\n    this.statisticsVersion = DrillStatsTable.CURRENT_VERSION;\n    this.queryId = writerOptions.get(\"queryid\");\n     //Write as DRILL process user\n    this.fs = ImpersonationUtil.createFileSystem(ImpersonationUtil.getProcessUserName(), fsConf);\n    fileName = new Path(location, prefix + \".\" + extension + \".tmp.\" + queryId);\n    // Delete .tmp file if exists. Unexpected error in cleanup during last ANALYZE\n    try {\n      if (fs.exists(fileName)) {\n        fs.delete(fileName, false);\n      }\n    } catch (IOException ex) {\n      logger.error(\"Unable to delete tmp file (corrupt): \" + fileName, ex);\n      throw ex;\n    }\n    try {\n      // Delete the tmp file and .stats.drill on exit. After writing out the permanent file\n      // we cancel the deleteOnExit. This ensures that if prior to writing out the stats\n      // file the process is killed, we perform the cleanup.\n      fs.deleteOnExit(fileName);\n      fs.deleteOnExit(new Path(location));\n      logger.debug(\"Created file: {}\", fileName);\n    } catch (IOException ex) {\n      logger.error(\"Unable to create file: \" + fileName, ex);\n      throw ex;\n    }\n  }\n  @Override\n  public void updateSchema(VectorAccessible batch) throws IOException {\n    // no op\n  }\n  @Override\n  public boolean isBlockingWriter() {\n    return true;\n  }\n  @Override\n  public void checkForNewPartition(int index) {\n    // no op\n  }\n  @Override\n  public FieldConverter getNewBigIntConverter(int fieldId, String fieldName, FieldReader reader) {\n    return new BigIntJsonConverter(fieldId, fieldName, reader);\n  }\n  public class BigIntJsonConverter extends FieldConverter {\n    public BigIntJsonConverter(int fieldId, String fieldName, FieldReader reader) {\n      super(fieldId, fieldName, reader);\n    }\n    @Override\n    public void startField() throws IOException {\n      if (fieldName.equals(Statistic.SCHEMA)) {\n        nextField = fieldName;\n      } else if (fieldName.equals(Statistic.ROWCOUNT)\n            || fieldName.equals(Statistic.NNROWCOUNT)\n            || fieldName.equals(Statistic.NDV)\n            || fieldName.equals(Statistic.AVG_WIDTH)\n            || fieldName.equals(Statistic.SUM_DUPS)) {\n        nextField = fieldName;\n      }\n    }\n    @Override\n    public void writeField() throws IOException {\n      if (nextField == null) {\n        errStatus = true;\n        throw new IOException(\"Statistics writer encountered unexpected field\");\n      }\n      if (nextField.equals(Statistic.SCHEMA)) {\n        ((DrillStatsTable.ColumnStatistics_v1) columnStatistics).setSchema(reader.readLong());\n      } else if (nextField.equals(Statistic.ROWCOUNT)) {\n        ((DrillStatsTable.ColumnStatistics_v1) columnStatistics).setCount(reader.readLong());\n      } else if (nextField.equals(Statistic.NNROWCOUNT)) {\n        ((DrillStatsTable.ColumnStatistics_v1) columnStatistics).setNonNullCount(reader.readLong());\n      } else if (nextField.equals(Statistic.NDV)) {\n        ((DrillStatsTable.ColumnStatistics_v1) columnStatistics).setNdv(reader.readLong());\n      } else if (nextField.equals(Statistic.AVG_WIDTH)) {\n        ((DrillStatsTable.ColumnStatistics_v1) columnStatistics).setAvgWidth(reader.readLong());\n      } else if (nextField.equals(Statistic.SUM_DUPS)) {\n        // Ignore Count_Approx_Dups statistic\n      }\n    }\n    @Override\n    public void endField() throws IOException {\n      nextField = null;\n    }\n  }\n  @Override\n  public FieldConverter getNewIntConverter(int fieldId, String fieldName, FieldReader reader) {\n    return new IntJsonConverter(fieldId, fieldName, reader);\n  }\n  public class IntJsonConverter extends FieldConverter {\n    public IntJsonConverter(int fieldId, String fieldName, FieldReader reader) {\n      super(fieldId, fieldName, reader);\n    }\n    @Override\n    public void startField() throws IOException {\n      if (fieldName.equals(Statistic.COLTYPE)) {\n        nextField = fieldName;\n      }\n    }\n    @Override\n    public void writeField() throws IOException {\n      if (nextField == null) {\n        errStatus = true;\n        throw new IOException(\"Statistics writer encountered unexpected field\");\n      }\n      if (nextField.equals(Statistic.COLTYPE)) {\n        // Do not write out the type\n      }\n    }\n    @Override\n    public void endField() throws IOException {\n      nextField = null;\n    }\n  }\n  @Override\n  public FieldConverter getNewDateConverter(int fieldId, String fieldName, FieldReader reader) {\n    return new DateJsonConverter(fieldId, fieldName, reader);\n  }\n  public class DateJsonConverter extends FieldConverter {\n    public DateJsonConverter(int fieldId, String fieldName, FieldReader reader) {\n      super(fieldId, fieldName, reader);\n    }\n    @Override\n    public void startField() throws IOException {\n      if (fieldName.equals(Statistic.COMPUTED)) {\n        nextField = fieldName;\n      }\n    }\n    @Override\n    public void writeField() throws IOException {\n      if (nextField == null) {\n        errStatus = true;\n        throw new IOException(\"Statistics writer encountered unexpected field\");\n      }\n      if (nextField.equals((Statistic.COMPUTED))) {\n        LocalDate computedTime = reader.readLocalDate();\n        if (dirComputedTime == null\n               || computedTime.compareTo(dirComputedTime) > 0) {\n          dirComputedTime = computedTime;\n        }\n      }\n    }\n    @Override\n    public void endField() throws IOException {\n      nextField = null;\n    }\n  }\n  @Override\n  public FieldConverter getNewVarCharConverter(int fieldId, String fieldName, FieldReader reader) {\n    return new VarCharJsonConverter(fieldId, fieldName, reader);\n  }\n  public class VarCharJsonConverter extends FieldConverter {\n    public VarCharJsonConverter(int fieldId, String fieldName, FieldReader reader) {\n      super(fieldId, fieldName, reader);\n    }\n    @Override\n    public void startField() throws IOException {\n      if (fieldName.equals(Statistic.COLNAME)) {\n        nextField = fieldName;\n      } else if (fieldName.equals(Statistic.COLTYPE)) {\n        nextField = fieldName;\n      }\n    }\n    @Override\n    public void writeField() throws IOException {\n      if (nextField == null) {\n        errStatus = true;\n        throw new IOException(\"Statistics writer encountered unexpected field\");\n      }\n      if (nextField.equals(Statistic.COLNAME)) {\n        ((DrillStatsTable.ColumnStatistics_v1) columnStatistics).setName(reader.readText().toString());\n      } else if (nextField.equals(Statistic.COLTYPE)) {\n        MajorType fieldType = DrillStatsTable.getMapper().readValue(reader.readText().toString(), MajorType.class);\n        ((DrillStatsTable.ColumnStatistics_v1) columnStatistics).setType(fieldType);\n      }\n    }\n    @Override\n    public void endField() throws IOException {\n      nextField = null;\n    }\n  }\n  @Override\n  public FieldConverter getNewNullableBigIntConverter(int fieldId, String fieldName, FieldReader reader) {\n    return new NullableBigIntJsonConverter(fieldId, fieldName, reader);\n  }\n  public class NullableBigIntJsonConverter extends FieldConverter {\n    public NullableBigIntJsonConverter(int fieldId, String fieldName, FieldReader reader) {\n      super(fieldId, fieldName, reader);\n    }\n<fim_suffix>    @Override\n    public void startField() throws IOException {\n      if (!skipNullFields || this.reader.isSet()) {\n        if (fieldName.equals(Statistic.ROWCOUNT)\n            || fieldName.equals(Statistic.NNROWCOUNT)\n            || fieldName.equals(Statistic.NDV)\n            || fieldName.equals(Statistic.SUM_DUPS)) {\n          nextField = fieldName;\n        }\n      }\n    }<fim_middle>// function below has no smell\n"}