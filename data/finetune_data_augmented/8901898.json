{"text": "<fim_prefix>/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n *    http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage org.apache.hadoop.hive.llap.io.encoded;\nimport java.io.IOException;\nimport java.nio.ByteBuffer;\nimport java.security.PrivilegedExceptionAction;\nimport java.util.ArrayList;\nimport java.util.Arrays;\nimport java.util.List;\nimport java.util.concurrent.atomic.AtomicBoolean;\nimport org.apache.hadoop.conf.Configuration;\nimport org.apache.hadoop.fs.FileSystem;\nimport org.apache.hadoop.fs.Path;\nimport org.apache.hadoop.hive.common.Pool;\nimport org.apache.hadoop.hive.common.Pool.PoolObjectHelper;\nimport org.apache.hadoop.hive.common.io.Allocator;\nimport org.apache.hadoop.hive.common.io.Allocator.BufferObjectFactory;\nimport org.apache.hadoop.hive.common.io.DataCache;\nimport org.apache.hadoop.hive.common.io.DiskRange;\nimport org.apache.hadoop.hive.common.io.DiskRangeList;\nimport org.apache.hadoop.hive.common.io.encoded.EncodedColumnBatch.ColumnStreamData;\nimport org.apache.hadoop.hive.common.io.encoded.MemoryBuffer;\nimport org.apache.hadoop.hive.conf.HiveConf;\nimport org.apache.hadoop.hive.conf.HiveConf.ConfVars;\nimport org.apache.hadoop.hive.llap.ConsumerFeedback;\nimport org.apache.hadoop.hive.llap.DebugUtils;\nimport org.apache.hadoop.hive.llap.LlapUtil;\nimport org.apache.hadoop.hive.llap.cache.BufferUsageManager;\nimport org.apache.hadoop.hive.llap.cache.LlapDataBuffer;\nimport org.apache.hadoop.hive.llap.cache.LowLevelCache;\nimport org.apache.hadoop.hive.llap.cache.LowLevelCache.Priority;\nimport org.apache.hadoop.hive.llap.counters.LlapIOCounters;\nimport org.apache.hadoop.hive.llap.counters.QueryFragmentCounters;\nimport org.apache.hadoop.hive.llap.io.api.impl.LlapIoImpl;\nimport org.apache.hadoop.hive.llap.io.decode.ColumnVectorProducer.Includes;\nimport org.apache.hadoop.hive.llap.io.decode.ColumnVectorProducer.SchemaEvolutionFactory;\nimport org.apache.hadoop.hive.llap.io.decode.OrcEncodedDataConsumer;\nimport org.apache.hadoop.hive.llap.io.metadata.MetadataCache;\nimport org.apache.hadoop.hive.llap.io.metadata.MetadataCache.LlapBufferOrBuffers;\nimport org.apache.hadoop.hive.llap.io.metadata.OrcFileMetadata;\nimport org.apache.hadoop.hive.llap.io.metadata.OrcStripeMetadata;\nimport org.apache.hadoop.hive.ql.exec.Utilities;\nimport org.apache.hadoop.hive.ql.io.HdfsUtils;\nimport org.apache.hadoop.hive.ql.io.orc.OrcFile;\nimport org.apache.hadoop.hive.ql.io.orc.OrcFile.ReaderOptions;\nimport org.apache.hadoop.hive.ql.io.orc.OrcSplit;\nimport org.apache.hadoop.hive.ql.io.orc.RecordReaderImpl;\nimport org.apache.hadoop.hive.ql.io.orc.encoded.EncodedOrcFile;\nimport org.apache.hadoop.hive.ql.io.orc.encoded.EncodedReader;\nimport org.apache.hadoop.hive.ql.io.orc.encoded.IoTrace;\nimport org.apache.hadoop.hive.ql.io.orc.encoded.OrcBatchKey;\nimport org.apache.hadoop.hive.ql.io.orc.encoded.Reader;\nimport org.apache.hadoop.hive.ql.io.orc.encoded.Reader.OrcEncodedColumnBatch;\nimport org.apache.hadoop.hive.ql.io.orc.encoded.Reader.PoolFactory;\nimport org.apache.hadoop.hive.ql.io.sarg.SearchArgument;\nimport org.apache.hadoop.mapred.FileSplit;\nimport org.apache.hadoop.security.UserGroupInformation;\nimport org.apache.hive.common.util.FixedSizedObjectPool;\nimport org.apache.orc.CompressionCodec;\nimport org.apache.orc.CompressionKind;\nimport org.apache.orc.DataReader;\nimport org.apache.orc.OrcConf;\nimport org.apache.orc.OrcProto;\nimport org.apache.orc.OrcProto.BloomFilterIndex;\nimport org.apache.orc.OrcProto.FileTail;\nimport org.apache.orc.OrcProto.RowIndex;\nimport org.apache.orc.OrcProto.Stream;\nimport org.apache.orc.OrcProto.StripeStatistics;\nimport org.apache.orc.StripeInformation;\nimport org.apache.orc.TypeDescription;\nimport org.apache.orc.impl.BufferChunk;\nimport org.apache.orc.impl.DataReaderProperties;\nimport org.apache.orc.impl.InStream;\nimport org.apache.orc.impl.OrcCodecPool;\nimport org.apache.orc.impl.OrcIndex;\nimport org.apache.orc.impl.OrcTail;\nimport org.apache.orc.impl.ReaderImpl;\nimport org.apache.orc.impl.RecordReaderUtils;\nimport org.apache.orc.impl.SchemaEvolution;\nimport org.apache.orc.impl.WriterImpl;\nimport org.apache.tez.common.CallableWithNdc;\nimport org.apache.tez.common.counters.TezCounters;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport com.google.common.collect.Lists;\n/**\n * This produces EncodedColumnBatch via ORC EncodedDataImpl.\n * It serves as Consumer for EncodedColumnBatch too, for the high-level cache scenario where\n * it inserts itself into the pipeline to put the data in cache, before passing it to the real\n * consumer. It also serves as ConsumerFeedback that receives processed EncodedColumnBatch-es.\n */\npublic class OrcEncodedDataReader extends CallableWithNdc<Void>\n    implements ConsumerFeedback<OrcEncodedColumnBatch>, TezCounterSource {\n  private static final Logger LOG = LoggerFactory.getLogger(OrcEncodedDataReader.class);\n  public static final FixedSizedObjectPool<ColumnStreamData> CSD_POOL =\n      new FixedSizedObjectPool<>(8192, new PoolObjectHelper<ColumnStreamData>() {\n        @Override\n        public ColumnStreamData create() {\n          return new ColumnStreamData();\n        }\n        @Override\n        public void resetBeforeOffer(ColumnStreamData t) {\n          t.reset();\n        }\n      });\n  public static final FixedSizedObjectPool<OrcEncodedColumnBatch> ECB_POOL =\n      new FixedSizedObjectPool<>(1024, new PoolObjectHelper<OrcEncodedColumnBatch>() {\n        @Override\n        public OrcEncodedColumnBatch create() {\n          return new OrcEncodedColumnBatch();\n        }\n        @Override\n        public void resetBeforeOffer(OrcEncodedColumnBatch t) {\n          t.reset();\n        }\n      });\n  private static final PoolFactory POOL_FACTORY = new PoolFactory() {\n    @Override\n    public Pool<ColumnStreamData> createColumnStreamDataPool() {\n      return CSD_POOL;\n    }\n<fim_suffix>    @Override\n    public Pool<OrcEncodedColumnBatch> createEncodedColumnBatchPool() {\n      return ECB_POOL;\n    }\n  };\n  private final MetadataCache metadataCache;\n  private final LowLevelCache lowLevelCache;\n  private final BufferUsageManager bufferManager;\n  private final Configuration daemonConf, jobConf;\n  private final FileSplit split;\n  private final SearchArgument sarg;\n  private final OrcEncodedDataConsumer consumer;\n  private final QueryFragmentCounters counters;\n  private final UserGroupInformation ugi;\n  private final SchemaEvolution evolution;\n  private final boolean useCodecPool, useObjectPools;\n  // Read state.<fim_middle>// function below has no smell\n"}