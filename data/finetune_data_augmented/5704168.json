{"text": "<fim_prefix>/**\n * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with\n * this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version\n * 2.0 (the \"License\"); you may not use this file except in compliance with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions\n * and limitations under the License.\n */\n\npackage org.apache.storm.starter;\n\nimport java.util.Iterator;\nimport java.util.Map;\nimport java.util.Map.Entry;\nimport java.util.concurrent.ConcurrentHashMap;\nimport org.apache.storm.Config;\nimport org.apache.storm.StormSubmitter;\nimport org.apache.storm.task.OutputCollector;\nimport org.apache.storm.task.TopologyContext;\nimport org.apache.storm.testing.TestWordSpout;\nimport org.apache.storm.topology.OutputFieldsDeclarer;\nimport org.apache.storm.topology.SharedOffHeapWithinNode;\nimport org.apache.storm.topology.SharedOnHeap;\nimport org.apache.storm.topology.SpoutDeclarer;\nimport org.apache.storm.topology.TopologyBuilder;\nimport org.apache.storm.topology.base.BaseRichBolt;\nimport org.apache.storm.tuple.Fields;\nimport org.apache.storm.tuple.Tuple;\nimport org.apache.storm.tuple.Values;\n\npublic class ResourceAwareExampleTopology {\n    public static void main(String[] args) throws Exception {\n        TopologyBuilder builder = new TopologyBuilder();\n\n        //A topology can set resources in terms of CPU and Memory for each component\n        // These can be chained (like with setting the CPU requirement)\n        SpoutDeclarer spout = builder.setSpout(\"word\", new TestWordSpout(), 10).setCPULoad(20);\n        // Or done separately like with setting the\n        // onheap and offheap memory requirement\n        spout.setMemoryLoad(64, 16);\n        //On heap memory is used to help calculate the heap of the java process for the worker\n        // off heap memory is for things like JNI memory allocated off heap, or when using the\n        // ShellBolt or ShellSpout.  In this case the 16 MB of off heap is just as an example\n        // as we are not using it.\n\n        // Some times a Bolt or Spout will have some memory that is shared between the instances\n        // These are typically caches, but could be anything like a static database that is memory\n        // mapped into the processes. These can be declared separately and added to the bolts and\n        // spouts that use them.  Or if only one uses it they can be created inline with the add\n        SharedOnHeap exclaimCache = new SharedOnHeap(100, \"exclaim-cache\");\n        SharedOffHeapWithinNode notImplementedButJustAnExample =\n            new SharedOffHeapWithinNode(500, \"not-implemented-node-level-cache\");\n\n        //If CPU or memory is not set the values stored in topology.component.resources.onheap.memory.mb,\n        // topology.component.resources.offheap.memory.mb and topology.component.cpu.pcore.percent\n        // will be used instead\n        builder\n            .setBolt(\"exclaim1\", new ExclamationBolt(), 3)\n            .shuffleGrouping(\"word\")\n            .addSharedMemory(exclaimCache);\n\n        builder\n            .setBolt(\"exclaim2\", new ExclamationBolt(), 2)\n            .shuffleGrouping(\"exclaim1\")\n            .setMemoryLoad(100)\n            .addSharedMemory(exclaimCache)\n            .addSharedMemory(notImplementedButJustAnExample);\n\n        Config conf = new Config();\n        conf.setDebug(true);\n\n        //Under RAS the number of workers is determined by the scheduler and the settings in the conf are ignored\n        //conf.setNumWorkers(3);\n\n        //Instead the scheduler lets you set the maximum heap size for any worker.\n        conf.setTopologyWorkerMaxHeapSize(1024.0);\n        //The scheduler generally will try to pack executors into workers until the max heap size is met, but\n        // this can vary depending on the specific scheduling strategy selected.\n        // The reason for this is to try and balance the maximum pause time GC might take (which is larger for larger heaps)\n        // against better performance because of not needing to serialize/deserialize tuples.\n\n        //The priority of a topology describes the importance of the topology in decreasing importance\n        // starting from 0 (i.e. 0 is the highest priority and the priority importance decreases as the priority number increases).\n        //Recommended range of 0-29 but no hard limit set.\n        // If there are not enough resources in a cluster the priority in combination with how far over a guarantees\n        // a user is will decide which topologies are run and which ones are not.\n        conf.setTopologyPriority(29);\n\n        //set to use the default resource aware strategy when using the MultitenantResourceAwareBridgeScheduler\n        conf.setTopologyStrategy(\n            \"org.apache.storm.scheduler.resource.strategies.scheduling.DefaultResourceAwareStrategy\");\n\n        String topoName = \"test\";\n        if (args != null && args.length > 0) {\n            topoName = args[0];\n        }\n\n        StormSubmitter.submitTopologyWithProgressBar(topoName, conf, builder.createTopology());\n    }\n\n<fim_suffix>    public static class ExclamationBolt extends BaseRichBolt {\n        //Have a crummy cache to show off shared memory accounting\n        private static final ConcurrentHashMap<String, String> myCrummyCache =\n            new ConcurrentHashMap<>();\n        private static final int CACHE_SIZE = 100_000;\n        OutputCollector _collector;\n\n        protected static String getFromCache(String key) {\n            return myCrummyCache.get(key);\n        }\n\n        protected static void addToCache(String key, String value) {\n            myCrummyCache.putIfAbsent(key, value);\n            int numToRemove = myCrummyCache.size() - CACHE_SIZE;\n            if (numToRemove > 0) {\n                //Remove something randomly...\n                Iterator<Entry<String, String>> it = myCrummyCache.entrySet().iterator();\n                for (; numToRemove > 0 && it.hasNext(); numToRemove--) {\n                    it.next();\n                    it.remove();\n                }\n            }\n        }\n\n        @Override\n        public void prepare(Map<String, Object> conf, TopologyContext context, OutputCollector collector) {\n            _collector = collector;\n        }\n\n        @Override\n        public void execute(Tuple tuple) {\n            String orig = tuple.getString(0);\n            String ret = getFromCache(orig);\n            if (ret == null) {\n                ret = orig + \"!!!\";\n                addToCache(orig, ret);\n            }\n            _collector.emit(tuple, new Values(ret));\n            _collector.ack(tuple);\n        }\n\n        @Override\n        public void declareOutputFields(OutputFieldsDeclarer declarer) {\n            declarer.declare(new Fields(\"word\"));\n        }\n    }\n}<fim_middle>// class below has no smell\n"}